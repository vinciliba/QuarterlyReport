{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e002fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\vinci\\Projects\\QuarterlyReport\\reporting\\quarterly_report\\report_utils\\payments_m_builder.py:6501: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
      "  if 'table_colors' is None:\n",
      "f:\\vinci\\Projects\\QuarterlyReport\\reporting\\quarterly_report\\report_utils\\payments_m_builder.py:6515: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
      "  if 'db_path' is None:\n"
     ]
    }
   ],
   "source": [
    "# reporting/quarterly_report/modules/granting.py\n",
    "from __future__ import annotations\n",
    "\n",
    "import logging, sqlite3, datetime\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import calendar\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from typing import List, Tuple,Union\n",
    "import numpy as np\n",
    "from great_tables import GT, loc, style, html\n",
    "import re\n",
    "import logging\n",
    "\n",
    "from ingestion.db_utils import (\n",
    "    fetch_latest_table_data,\n",
    "    insert_variable,\n",
    "    load_report_params,\n",
    "    fetch_vars_for_report\n",
    ")\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('amendments_report.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(\"Payments\")\n",
    "\n",
    "\n",
    "\n",
    "# our project\n",
    "from ingestion.db_utils import (\n",
    "    init_db,                                 # create tables if missing\n",
    "    fetch_latest_table_data,                 # new version!\n",
    "    get_alias_last_load,\n",
    "    get_variable_status, \n",
    "    load_report_params                   # to inspect results\n",
    ")\n",
    "\n",
    "from reporting.quarterly_report.utils import RenderContext, BaseModule\n",
    "from reporting.quarterly_report.report_utils.granting_utils import enrich_grants, _ensure_timedelta_cols, _coerce_date_columns\n",
    "from reporting.quarterly_report.utils import Database, RenderContext\n",
    "\n",
    "\n",
    "import altair as alt\n",
    "from altair_saver import save\n",
    "import selenium.webdriver\n",
    "\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 2) open DB – change path if you work on a copy\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "db_path = \"database/reporting.db\"\n",
    "DB_PATH = Path(\"database/reporting.db\")\n",
    "\n",
    "init_db(db_path=DB_PATH)            # no-op if tables already exist\n",
    "\n",
    "db = Database(str(DB_PATH))         # thin sqlite3 wrapper\n",
    "conn = db.conn\n",
    "report = 'Quarterly_Report'\n",
    "\n",
    "CALLS_TYPES_LIST = ['STG', 'ADG', 'POC', 'COG', 'SYG', 'StG', 'CoG', 'AdG', 'SyG', 'PoC', 'CSA']\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# HELPERS\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "def determine_epoch_year(cutoff_date: pd.Timestamp) -> int:\n",
    "    \"\"\"\n",
    "    Returns the correct reporting year.\n",
    "    If the cutoff is in January, then we are reporting for the *previous* year.\n",
    "    \"\"\"\n",
    "    return cutoff_date.year - 1 if cutoff_date.month == 1 else cutoff_date.year\n",
    "\n",
    "\n",
    "\n",
    "def get_scope_start_end(cutoff: pd.Timestamp) -> Tuple[pd.Timestamp, pd.Timestamp]:\n",
    "    \"\"\"\n",
    "    Unified scope logic with year transition:\n",
    "    • If cutoff is in January → report full previous year\n",
    "    • Otherwise → return start of year to quarter-end\n",
    "    \"\"\"\n",
    "    if cutoff.month == 1:\n",
    "        year = cutoff.year - 1\n",
    "        return pd.Timestamp(year=year, month=1, day=1), pd.Timestamp(year=year, month=12, day=31)\n",
    "\n",
    "    def quarter_end(cutoff: pd.Timestamp) -> pd.Timestamp:\n",
    "        first_day = cutoff.replace(day=1)\n",
    "        last_month = first_day - pd.offsets.MonthBegin()\n",
    "        m = last_month.month\n",
    "\n",
    "        if m <= 3:\n",
    "            return pd.Timestamp(year=cutoff.year, month=3, day=31)\n",
    "        elif m <= 6:\n",
    "            return pd.Timestamp(year=cutoff.year, month=6, day=30)\n",
    "        elif m <= 9:\n",
    "            return pd.Timestamp(year=cutoff.year, month=9, day=30)\n",
    "        else:\n",
    "            return pd.Timestamp(year=cutoff.year, month=12, day=31)\n",
    "\n",
    "    return pd.Timestamp(year=cutoff.year, month=1, day=1), quarter_end(cutoff)\n",
    "\n",
    "\n",
    "\n",
    "def months_in_scope(cutoff: pd.Timestamp) -> list[str]:\n",
    "    \"\"\"\n",
    "    Returns list of month names from January to last *full* month before cutoff.\n",
    "    Handles year rollover if cutoff is in January.\n",
    "    \"\"\"\n",
    "    if cutoff.month == 1:\n",
    "        year = cutoff.year - 1\n",
    "        end_month = 12\n",
    "    else:\n",
    "        year = cutoff.year\n",
    "        end_month = cutoff.month - 1\n",
    "\n",
    "    months = pd.date_range(\n",
    "        start=pd.Timestamp(year=year, month=1, day=1),\n",
    "        end=pd.Timestamp(year=year, month=end_month, day=1),\n",
    "        freq=\"MS\"\n",
    "    ).strftime(\"%B\").tolist()\n",
    "\n",
    "    return months\n",
    "\n",
    "def determine_po_category(row):\n",
    "\n",
    "    instrument = str(row.get('Instrument', '')).strip()\n",
    "    topic = str(row.get('Topic', '')).strip()\n",
    "\n",
    "    try:\n",
    "        if topic and any(call_type in topic for call_type in CALLS_TYPES_LIST):\n",
    "            category = next(call_type for call_type in CALLS_TYPES_LIST if call_type in topic).upper()\n",
    "            return category\n",
    "        elif instrument and any(call_type in instrument for call_type in CALLS_TYPES_LIST):\n",
    "            category = next(call_type for call_type in CALLS_TYPES_LIST if call_type in instrument).upper()\n",
    "            return category\n",
    "        return ''\n",
    "    except Exception as e:\n",
    "        raise\n",
    "\n",
    "def determine_po_category_po_list(row):\n",
    "\n",
    "    summa = str(row.get('PO Purchase Order Item Desc', '')).strip()\n",
    "    abac = str(row.get('PO ABAC SAP Reference', '')).strip()\n",
    "\n",
    "    try:\n",
    "        if summa and any(call_type in summa for call_type in CALLS_TYPES_LIST):\n",
    "            category = next(call_type for call_type in CALLS_TYPES_LIST if call_type in summa).upper()\n",
    "            return category\n",
    "        elif abac and any(call_type in abac for call_type in CALLS_TYPES_LIST):\n",
    "            category = next(call_type for call_type in CALLS_TYPES_LIST if call_type in abac).upper()\n",
    "            return category\n",
    "        return ''\n",
    "    except Exception as e:\n",
    "        raise\n",
    "\n",
    "def extract_project_number(row):\n",
    "    \"\"\"\n",
    "    Extract project number from 'Inv Text' if 'v_check_payment_type' contains RP patterns,\n",
    "    otherwise return original 'v_check_payment_type' value\n",
    "    \"\"\"\n",
    "    payment_type = row['v_check_payment_type']\n",
    "    inv_text = row['Inv Text']\n",
    "    \n",
    "    # Handle NaN values\n",
    "    if pd.isna(payment_type):\n",
    "        return payment_type\n",
    "    \n",
    "    # Convert to string to handle any data type\n",
    "    payment_type_str = str(payment_type)\n",
    "    \n",
    "    # Check if the payment_type contains RP patterns:\n",
    "    # - Original pattern: RP + number + = + FP/IP (e.g., RP4=FP, RP2=IP)\n",
    "    # - New pattern: RP + number + - + FP/IP (e.g., RP4-FP, RP2-IP)\n",
    "    rp_patterns = [\n",
    "        r'RP\\d+=(?:FP|IP)',  # Original pattern: RP4=FP, RP2=IP, etc.\n",
    "        r'RP\\d+-(?:FP|IP)'   # New pattern: RP4-FP, RP2-IP, etc.\n",
    "    ]\n",
    "    \n",
    "    # Check if any of the RP patterns match\n",
    "    has_rp_pattern = any(re.search(pattern, payment_type_str) for pattern in rp_patterns)\n",
    "    \n",
    "    if has_rp_pattern:\n",
    "        # Extract the numerical part from Inv Text column\n",
    "        if pd.notna(inv_text):\n",
    "            inv_text_str = str(inv_text).strip()\n",
    "            # Extract leading digits from Inv Text\n",
    "            number_match = re.match(r'^(\\d+)', inv_text_str)\n",
    "            if number_match:\n",
    "                return number_match.group(1)\n",
    "        \n",
    "        # If no number found in Inv Text, return original payment_type\n",
    "        return payment_type\n",
    "    \n",
    "    # Return original v_check_payment_type if no RP pattern found\n",
    "    return payment_type\n",
    "\n",
    "\n",
    "def map_project_to_call_type(project_num, mapping_dict):\n",
    "    # If it's a numeric string, try to convert and lookup\n",
    "    try:\n",
    "        # Try to convert to int for lookup\n",
    "        numeric_key = int(project_num)\n",
    "        if numeric_key in mapping_dict:\n",
    "            return mapping_dict[numeric_key]\n",
    "    except (ValueError, TypeError):\n",
    "        # If conversion fails, it's a non-numeric string like 'EXPERTS'\n",
    "        pass\n",
    "    \n",
    "    # Return original value if no match found\n",
    "    return project_num\n",
    "\n",
    "def map_call_type_with_experts(row, grant_map):\n",
    "    \"\"\"\n",
    "    Map call_type based on project_number and Inv Parking Person Id\n",
    "    \"\"\"\n",
    "    project_num = row['project_number']\n",
    "    contract_type = row['v_payment_type']\n",
    "    \n",
    "    # First, try to map using grant_map (convert project_num to int if possible)\n",
    "    try:\n",
    "        numeric_key = int(project_num)\n",
    "        if numeric_key in grant_map:\n",
    "            return grant_map[numeric_key]\n",
    "    except (ValueError, TypeError):\n",
    "        pass\n",
    "    \n",
    "    # If project_number is 'EXPERTS', keep it as 'EXPERTS'\n",
    "    if str(project_num).upper() == 'EXPERTS' or str(contract_type).upper() == 'EXPERTS':\n",
    "        return 'EXPERTS'\n",
    "    \n",
    "    # Return original project_number if no conditions are met\n",
    "    return project_num\n",
    "\n",
    "def map_payment_type(row):\n",
    "    if row['v_payment_type'] == 'Other' and row['Pay Workflow Last AOS Person Id'] == 'WALASOU':\n",
    "        return 'EXPERTS'\n",
    "    return row['v_payment_type']\n",
    "\n",
    "# Instead, handle conversion in the mapping function\n",
    "def safe_map_project_to_call_type(project_num, mapping_dict):\n",
    "    \"\"\"\n",
    "    Maps project number to call type, handles all data type issues internally\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Handle NaN values\n",
    "        if pd.isna(project_num):\n",
    "            return None\n",
    "            \n",
    "        # Convert whatever format to integer for lookup\n",
    "        if isinstance(project_num, str):\n",
    "            # Handle strings like '4500053782.0'\n",
    "            if project_num.endswith('.0'):\n",
    "                numeric_key = int(project_num[:-2])\n",
    "            else:\n",
    "                numeric_key = int(float(project_num))\n",
    "        else:\n",
    "            # Handle numeric values (float/int)\n",
    "            numeric_key = int(float(project_num))\n",
    "            \n",
    "        # Lookup in mapping dictionary\n",
    "        if numeric_key in mapping_dict:\n",
    "            result = mapping_dict[numeric_key]\n",
    "            if pd.notna(result) and result != '':\n",
    "                return result\n",
    "                \n",
    "    except (ValueError, TypeError, OverflowError):\n",
    "        # Any conversion error, return None\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Apply mapping without converting the whole column\n",
    "def apply_conditional_mapping(row):\n",
    "    current_call_type = row['call_type']\n",
    "    po_key = row['PO Purchase Order Key']  # Use as-is, no conversion\n",
    "    \n",
    "    should_map = (\n",
    "        pd.isna(current_call_type) or \n",
    "        current_call_type == '' or \n",
    "        current_call_type not in CALLS_TYPES_LIST or \n",
    "        current_call_type in ['EXPERTS', 'CSA']\n",
    "    )\n",
    "    \n",
    "    if should_map:\n",
    "        mapped_value = safe_map_project_to_call_type(po_key, po_map)\n",
    "        return mapped_value if mapped_value is not None else current_call_type\n",
    "    else:\n",
    "        return current_call_type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7118e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAYMENTS_ALIAS = \"payments_summa\"\n",
    "CALLS_ALIAS = 'call_overview'\n",
    "PAYMENTS_TIMES_ALIAS = 'payments_summa_time'\n",
    "PO_ALIAS = 'c0_po_summa'\n",
    "FORECAST_ALIAS = 'forecast'\n",
    "\n",
    "cutoff = pd.to_datetime(\"2025-06-01\")\n",
    "report_params = load_report_params(report_name=report, db_path=db_path)\n",
    "\n",
    "\n",
    "table_colors = report_params.get('TABLE_COLORS', {})\n",
    "BLUE = table_colors.get(\"BLUE\", \"#004A99\")\n",
    "LIGHT_BLUE = table_colors.get(\"LIGHT_BLUE\", \"#d6e6f4\")\n",
    "DARK_BLUE = table_colors.get(\"DARK_BLUE\", \"#01244B\")\n",
    "SUB_TOTAL_BACKGROUND = table_colors.get(\"subtotal_background_color\", \"#E6E6FA\")\n",
    "\n",
    "df_paym = fetch_latest_table_data(conn, PAYMENTS_ALIAS, cutoff)\n",
    "df_paym_times = fetch_latest_table_data(conn, PAYMENTS_TIMES_ALIAS, cutoff)\n",
    "df_calls =  fetch_latest_table_data(conn, CALLS_ALIAS , cutoff)\n",
    "df_po = fetch_latest_table_data(conn, PO_ALIAS, cutoff)\n",
    "df_forecast = fetch_latest_table_data(conn, FORECAST_ALIAS, cutoff)\n",
    "\n",
    "df_paym['v_payment_type'] = df_paym.apply(map_payment_type, axis=1)\n",
    "# Filter the dataframe\n",
    "df_paym = df_paym[df_paym['Pay Document Type Desc'].isin(['Payment Directive', 'Exp Pre-financing'])]\n",
    "# Keep all rows where v_payment_type is not 'Other'\n",
    "df_paym = df_paym[df_paym['v_payment_type'] != 'Other']\n",
    "df_paym = df_paym[df_paym['Pay Payment Key'].notnull()]\n",
    "\n",
    "df_paym['project_number'] = df_paym.apply(extract_project_number, axis=1)\n",
    "\n",
    "# Assuming your DataFrame is called 'df'\n",
    "df_calls['CALL_TYPE'] = df_calls.apply(determine_po_category, axis=1)\n",
    "grant_map = df_calls.set_index('Grant Number')['CALL_TYPE'].to_dict()\n",
    "\n",
    "#PO ORDERS MAP\n",
    "df_po['CALL_TYPE']  = df_po.apply(determine_po_category_po_list, axis=1)\n",
    "\n",
    "po_map = df_po[\n",
    "    df_po['CALL_TYPE'].notna() & \n",
    "    (df_po['CALL_TYPE'].str.strip() != '')\n",
    "].set_index('PO Purchase Order Key')['CALL_TYPE'].to_dict()\n",
    "\n",
    "# Apply the mapping\n",
    "df_paym['call_type'] = df_paym['project_number'].apply(lambda x: map_project_to_call_type(x, grant_map))\n",
    "df_paym['call_type'] = df_paym.apply(lambda row: map_call_type_with_experts(row, grant_map), axis=1)\n",
    "\n",
    "\n",
    "# Clean call_type column only (not PO keys)\n",
    "df_paym['call_type'] = df_paym['call_type'].astype(str).str.strip().replace(['nan', ''], np.nan)\n",
    "# Apply the mapping\n",
    "df_paym['call_type'] = df_paym.apply(apply_conditional_mapping, axis=1)\n",
    "# This preserves NaN values as NaN instead of causing errors\n",
    "df_paym['PO Purchase Order Key'] = pd.to_numeric(df_paym['PO Purchase Order Key'], errors='coerce').astype('Int64')\n",
    "\n",
    "df_paym['Pay Document Date (dd/mm/yyyy)'] = pd.to_datetime(\n",
    "    df_paym['Pay Document Date (dd/mm/yyyy)'], \n",
    "    format='%Y-%m-%d %H:%M:%S',\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "last_valid_date = quarter_dates[1]\n",
    "\n",
    "df_paym = df_paym[\n",
    "    df_paym['Pay Document Date (dd/mm/yyyy)'] <= last_valid_date\n",
    "].copy()\n",
    "\n",
    "df_paym = df_paym[df_paym['call_type'] != 'CSA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create v_payment_in_time column in df_paym_times\n",
    "print(\"=== STEP 1: Creating v_payment_in_time column ===\")\n",
    "\n",
    "# Convert Pay Delay Late Payment Flag (Y/N) to 1/0\n",
    "df_paym_times['v_payment_in_time'] = df_paym_times['Pay Delay Late Payment Flag (Y/N)'].apply(\n",
    "    lambda x: 1 if x == 'N' else 0\n",
    ")\n",
    "\n",
    "print(\"v_payment_in_time value counts:\")\n",
    "print(df_paym_times['v_payment_in_time'].value_counts())\n",
    "print(\"\\nOriginal flag vs new column:\")\n",
    "print(df_paym_times[['Pay Delay Late Payment Flag (Y/N)', 'v_payment_in_time']].value_counts())\n",
    "\n",
    "# Step 2: Clean Pay Payment Key and create mappings\n",
    "print(\"\\n=== STEP 2: Creating payment mappings ===\")\n",
    "\n",
    "# Filter df_paym_times to only include rows we need for mapping\n",
    "df_times_clean = df_paym_times.dropna(subset=['Pay Payment Key']).copy()\n",
    "\n",
    "# Clean Pay Payment Key for mapping (convert to integers)\n",
    "def safe_convert_to_int(value):\n",
    "    \"\"\"Safely convert payment key to integer\"\"\"\n",
    "    try:\n",
    "        if pd.isna(value):\n",
    "            return None\n",
    "        if isinstance(value, str):\n",
    "            # Handle strings like '2551003294.0'\n",
    "            if value.endswith('.0'):\n",
    "                return int(value[:-2])\n",
    "            else:\n",
    "                return int(float(value))\n",
    "        else:\n",
    "            return int(float(value))\n",
    "    except (ValueError, TypeError, OverflowError):\n",
    "        return None\n",
    "\n",
    "# Convert Pay Payment Key to integers for mapping (keep all rows)\n",
    "df_times_clean['Pay_Payment_Key_Int'] = df_times_clean['Pay Payment Key'].apply(safe_convert_to_int)\n",
    "\n",
    "# Count conversion issues but don't drop rows\n",
    "conversion_failed = df_times_clean['Pay_Payment_Key_Int'].isna().sum()\n",
    "conversion_success = df_times_clean['Pay_Payment_Key_Int'].notna().sum()\n",
    "\n",
    "print(f\"Payment key conversions - Success: {conversion_success}, Failed: {conversion_failed}\")\n",
    "\n",
    "# Create mappings only from successfully converted keys (but keep all rows in dataframe)\n",
    "valid_conversions = df_times_clean['Pay_Payment_Key_Int'].notna()\n",
    "mapping_data = df_times_clean[valid_conversions].copy()\n",
    "mapping_data['Pay_Payment_Key_Int'] = mapping_data['Pay_Payment_Key_Int'].astype(int)\n",
    "\n",
    "print(f\"Payment times data: {len(df_times_clean)} total rows, {len(mapping_data)} usable for mapping\")\n",
    "\n",
    "# Create the three mappings (only from rows with valid conversions)\n",
    "payment_key_to_ttp_gross = mapping_data.set_index('Pay_Payment_Key_Int')['Pay Delay With Suspension'].to_dict()\n",
    "payment_key_to_ttp_net = mapping_data.set_index('Pay_Payment_Key_Int')['Pay Delay Without Suspension'].to_dict()\n",
    "payment_key_to_payment_in_time = mapping_data.set_index('Pay_Payment_Key_Int')['v_payment_in_time'].to_dict()\n",
    "\n",
    "print(f\"TTP Gross mapping created: {len(payment_key_to_ttp_gross)} entries\")\n",
    "print(f\"TTP Net mapping created: {len(payment_key_to_ttp_net)} entries\")\n",
    "print(f\"Payment in time mapping created: {len(payment_key_to_payment_in_time)} entries\")\n",
    "\n",
    "# Step 3: Split dataframe and apply mappings selectively\n",
    "print(\"\\n=== STEP 3: Split, Map, and Merge Strategy ===\")\n",
    "\n",
    "# Check conditions in df_paym\n",
    "exp_prefi_mask = df_paym['Pay Document Type Desc'] == 'Exp Pre-financing'\n",
    "payment_directive_mask = df_paym['Pay Document Type Desc'] == 'Payment Directive'\n",
    "other_mask = ~(exp_prefi_mask | payment_directive_mask)\n",
    "\n",
    "print(f\"Rows with 'Exp Pre-financing': {exp_prefi_mask.sum()}\")\n",
    "print(f\"Rows with 'Payment Directive': {payment_directive_mask.sum()}\")\n",
    "print(f\"Other document types: {other_mask.sum()}\")\n",
    "print(f\"Total rows in df_paym: {len(df_paym)}\")\n",
    "\n",
    "# Step 3.1: Split the dataframe\n",
    "df_exp_prefi = df_paym[exp_prefi_mask].copy()\n",
    "df_payment_directive = df_paym[payment_directive_mask].copy()\n",
    "df_other = df_paym[other_mask].copy()\n",
    "\n",
    "print(f\"\\nDataframes split:\")\n",
    "print(f\"- Exp Pre-financing: {len(df_exp_prefi)} rows\")\n",
    "print(f\"- Payment Directive: {len(df_payment_directive)} rows\")\n",
    "print(f\"- Other types: {len(df_other)} rows\")\n",
    "\n",
    "# Step 3.2: Apply mapping ONLY to Exp Pre-financing dataframe\n",
    "if len(df_exp_prefi) > 0:\n",
    "    print(\"\\nApplying mappings to Exp Pre-financing dataframe...\")\n",
    "    \n",
    "    # Mapping function for payment data\n",
    "    def map_payment_data(pay_key, mapping_dict):\n",
    "        \"\"\"Map payment key to corresponding value\"\"\"\n",
    "        try:\n",
    "            if pd.isna(pay_key):\n",
    "                return np.nan\n",
    "                \n",
    "            # Convert pay_key to int for lookup\n",
    "            if isinstance(pay_key, str):\n",
    "                if pay_key.endswith('.0'):\n",
    "                    numeric_key = int(pay_key[:-2])\n",
    "                else:\n",
    "                    numeric_key = int(float(pay_key))\n",
    "            else:\n",
    "                numeric_key = int(float(pay_key))\n",
    "                \n",
    "            # Lookup in mapping\n",
    "            if numeric_key in mapping_dict:\n",
    "                return mapping_dict[numeric_key]\n",
    "            else:\n",
    "                return np.nan\n",
    "                \n",
    "        except (ValueError, TypeError, OverflowError):\n",
    "            return np.nan\n",
    "    \n",
    "    # Add the three new columns to Exp Pre-financing dataframe ONLY\n",
    "    df_exp_prefi['v_TTP_GROSS'] = df_exp_prefi['Pay Payment Key'].apply(\n",
    "        lambda x: map_payment_data(x, payment_key_to_ttp_gross)\n",
    "    )\n",
    "    \n",
    "    df_exp_prefi['v_TTP_NET'] = df_exp_prefi['Pay Payment Key'].apply(\n",
    "        lambda x: map_payment_data(x, payment_key_to_ttp_net)\n",
    "    )\n",
    "    \n",
    "    df_exp_prefi['v_payment_in_time'] = df_exp_prefi['Pay Payment Key'].apply(\n",
    "        lambda x: map_payment_data(x, payment_key_to_payment_in_time)\n",
    "    )\n",
    "    \n",
    "    print(\"Mapping applied to Exp Pre-financing rows!\")\n",
    "    \n",
    "    # Show sample of what was mapped\n",
    "    sample_mapped = df_exp_prefi[['Pay Payment Key', 'Pay Document Type Desc', 'v_TTP_GROSS', 'v_TTP_NET', 'v_payment_in_time']].head()\n",
    "    print(\"Sample mapped rows:\")\n",
    "    print(sample_mapped)\n",
    "else:\n",
    "    print(\"No Exp Pre-financing rows to map!\")\n",
    "\n",
    "# Step 3.3: Payment Directive dataframe - ADD columns but DON'T change any existing values\n",
    "if len(df_payment_directive) > 0:\n",
    "    print(\"\\nPreserving Payment Directive dataframe completely...\")\n",
    "    \n",
    "    # Check if these columns already exist in Payment Directive rows\n",
    "    if 'v_TTP_GROSS' in df_payment_directive.columns:\n",
    "        print(\"v_TTP_GROSS already exists in Payment Directive - preserving original values\")\n",
    "    else:\n",
    "        # Only add columns if they don't exist, with NaN values\n",
    "        df_payment_directive['v_TTP_GROSS'] = np.nan\n",
    "        \n",
    "    if 'v_TTP_NET' in df_payment_directive.columns:\n",
    "        print(\"v_TTP_NET already exists in Payment Directive - preserving original values\")\n",
    "    else:\n",
    "        df_payment_directive['v_TTP_NET'] = np.nan\n",
    "        \n",
    "    if 'v_payment_in_time' in df_payment_directive.columns:\n",
    "        print(\"v_payment_in_time already exists in Payment Directive - preserving original values\")\n",
    "    else:\n",
    "        df_payment_directive['v_payment_in_time'] = np.nan\n",
    "    \n",
    "    print(\"Payment Directive rows completely preserved!\")\n",
    "\n",
    "# Step 3.4: Handle other document types\n",
    "if len(df_other) > 0:\n",
    "    print(\"Adding columns to other document types with NaN values...\")\n",
    "    df_other['v_TTP_GROSS'] = np.nan\n",
    "    df_other['v_TTP_NET'] = np.nan\n",
    "    df_other['v_payment_in_time'] = np.nan\n",
    "\n",
    "# Step 3.5: Merge all dataframes back together\n",
    "print(\"\\nMerging dataframes back together...\")\n",
    "\n",
    "dataframes_to_merge = []\n",
    "if len(df_exp_prefi) > 0:\n",
    "    dataframes_to_merge.append(df_exp_prefi)\n",
    "if len(df_payment_directive) > 0:\n",
    "    dataframes_to_merge.append(df_payment_directive)\n",
    "if len(df_other) > 0:\n",
    "    dataframes_to_merge.append(df_other)\n",
    "\n",
    "if dataframes_to_merge:\n",
    "    df_paym = pd.concat(dataframes_to_merge, ignore_index=True)\n",
    "    print(f\"Dataframes merged successfully! Final shape: {df_paym.shape}\")\n",
    "else:\n",
    "    print(\"Warning: No dataframes to merge!\")\n",
    "\n",
    "# Step 4: Check results\n",
    "print(\"\\n=== STEP 4: Results ===\")\n",
    "print(\"v_TTP_GROSS value counts:\")\n",
    "print(df_paym['v_TTP_GROSS'].value_counts(dropna=False))\n",
    "print(\"\\nv_TTP_NET value counts:\")\n",
    "print(df_paym['v_TTP_NET'].value_counts(dropna=False))\n",
    "print(\"\\nv_payment_in_time value counts:\")\n",
    "print(df_paym['v_payment_in_time'].value_counts(dropna=False))\n",
    "\n",
    "# Show sample of mapped rows\n",
    "print(\"\\nSample of mapped rows:\")\n",
    "mapped_sample = df_paym[exp_prefi_mask & df_paym['v_TTP_GROSS'].notna()][\n",
    "    ['Pay Payment Key', 'Pay Document Type Desc', 'v_TTP_GROSS', 'v_TTP_NET', 'v_payment_in_time']\n",
    "].head()\n",
    "print(mapped_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7224e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paym.to_excel('paym.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from typing import Tuple\n",
    "\n",
    "# Existing periodicity functions\n",
    "def determine_epoch_year(cutoff_date: pd.Timestamp) -> int:\n",
    "    \"\"\"\n",
    "    Returns the correct reporting year.\n",
    "    If the cutoff is in January, then we are reporting for the *previous* year.\n",
    "    \"\"\"\n",
    "    return cutoff_date.year - 1 if cutoff_date.month == 1 else cutoff_date.year\n",
    "\n",
    "def get_scope_start_end(cutoff: pd.Timestamp) -> Tuple[pd.Timestamp, pd.Timestamp]:\n",
    "    \"\"\"\n",
    "    Unified scope logic with year transition:\n",
    "    • If cutoff is in January → report full previous year\n",
    "    • Otherwise → return start of year to quarter-end\n",
    "    \"\"\"\n",
    "    if cutoff.month == 1:\n",
    "        year = cutoff.year - 1\n",
    "        return pd.Timestamp(year=year, month=1, day=1), pd.Timestamp(year=year, month=12, day=31)\n",
    "\n",
    "    def quarter_end(cutoff: pd.Timestamp) -> pd.Timestamp:\n",
    "        first_day = cutoff.replace(day=1)\n",
    "        last_month = first_day - pd.offsets.MonthBegin()\n",
    "        m = last_month.month\n",
    "\n",
    "        if m <= 3:\n",
    "            return pd.Timestamp(year=cutoff.year, month=3, day=31)\n",
    "        elif m <= 6:\n",
    "            return pd.Timestamp(year=cutoff.year, month=6, day=30)\n",
    "        elif m <= 9:\n",
    "            return pd.Timestamp(year=cutoff.year, month=9, day=30)\n",
    "        else:\n",
    "            return pd.Timestamp(year=cutoff.year, month=12, day=31)\n",
    "\n",
    "    return pd.Timestamp(year=cutoff.year, month=1, day=1), quarter_end(cutoff)\n",
    "\n",
    "def months_in_scope(cutoff: pd.Timestamp) -> list[str]:\n",
    "    \"\"\"\n",
    "    Returns list of month names from January to last *full* month before cutoff.\n",
    "    Handles year rollover if cutoff is in January.\n",
    "    \"\"\"\n",
    "    if cutoff.month == 1:\n",
    "        year = cutoff.year - 1\n",
    "        end_month = 12\n",
    "    else:\n",
    "        year = cutoff.year\n",
    "        end_month = cutoff.month - 1\n",
    "\n",
    "    months = pd.date_range(\n",
    "        start=pd.Timestamp(year=year, month=1, day=1),\n",
    "        end=pd.Timestamp(year=year, month=end_month, day=1),\n",
    "        freq=\"MS\"\n",
    "    ).strftime(\"%B\").tolist()\n",
    "\n",
    "    return months\n",
    "\n",
    "def create_quarterly_payment_tables(df_paym, cutoff_date=None):\n",
    "    \"\"\"\n",
    "    Create quarterly payment tables matching the format from the Excel file\n",
    "    - Amount summing: All v_amount_to_sum per payment key, regrouped by fund source\n",
    "    - Number of payments: Count unique Pay Payment Key occurrences (deduplicated)\n",
    "    - Assumes df_paym is already filtered for the correct time scope\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== QUARTERLY PAYMENT TABLES GENERATION ===\")\n",
    "    \n",
    "    # Step 1: Set cutoff date for metadata\n",
    "    if cutoff_date is None:\n",
    "        cutoff_date = pd.Timestamp.now()\n",
    "    elif isinstance(cutoff_date, str):\n",
    "        cutoff_date = pd.Timestamp(cutoff_date)\n",
    "    \n",
    "    print(f\"Cutoff date: {cutoff_date}\")\n",
    "    \n",
    "    # Step 2: Get reporting metadata (for reference)\n",
    "    reporting_year = determine_epoch_year(cutoff_date)\n",
    "    scope_start, scope_end = get_scope_start_end(cutoff_date)\n",
    "    months_in_report = months_in_scope(cutoff_date)\n",
    "    \n",
    "    print(f\"Reporting year: {reporting_year}\")\n",
    "    print(f\"Expected scope: {scope_start} to {scope_end}\")\n",
    "    print(f\"Note: Assuming df_paym is already filtered for this scope\")\n",
    "    \n",
    "    # Step 3: Validate required columns\n",
    "    required_columns = [\n",
    "        'Pay Payment Key', \n",
    "        'v_amount_to_sum', \n",
    "        'Fund Source',\n",
    "        'v_payment_type', \n",
    "        'Pay Document Date (dd/mm/yyyy)',\n",
    "        'Programme'\n",
    "    ]\n",
    "    \n",
    "    # Check for optional call_type column\n",
    "    optional_columns = ['call_type', 'Call Type', 'v_call_type']\n",
    "    call_type_col = None\n",
    "    for col in optional_columns:\n",
    "        if col in df_paym.columns:\n",
    "            call_type_col = col\n",
    "            print(f\"Found call type column: {col}\")\n",
    "            break\n",
    "    \n",
    "    if call_type_col:\n",
    "        required_columns.append(call_type_col)\n",
    "    else:\n",
    "        print(\"No call_type column found - will use Fund Source only\")\n",
    "    \n",
    "    missing_columns = [col for col in required_columns if col not in df_paym.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"ERROR: Missing required columns: {missing_columns}\")\n",
    "        return None\n",
    "    \n",
    "    print(\"✓ All required columns present\")\n",
    "    \n",
    "    # Step 4: Create working dataframe (skip date filtering since already done)\n",
    "    df_work = df_paym[required_columns].copy()\n",
    "    \n",
    "    # Check for any remaining invalid dates\n",
    "    invalid_dates = df_work['Pay Document Date (dd/mm/yyyy)'].isna().sum()\n",
    "    if invalid_dates > 0:\n",
    "        print(f\"WARNING: {invalid_dates} rows with invalid dates found, removing them\")\n",
    "        df_work = df_work.dropna(subset=['Pay Document Date (dd/mm/yyyy)'])\n",
    "    \n",
    "    print(f\"Working dataset: {len(df_work)} rows\")\n",
    "    \n",
    "    if len(df_work) == 0:\n",
    "        print(\"ERROR: No data available after validation\")\n",
    "        return None\n",
    "    \n",
    "    # Create quarter and year columns\n",
    "    df_work['Quarter'] = df_work['Pay Document Date (dd/mm/yyyy)'].dt.to_period('Q')\n",
    "    df_work['Year'] = df_work['Pay Document Date (dd/mm/yyyy)'].dt.year\n",
    "    df_work['Quarter_Label'] = df_work['Quarter'].astype(str)\n",
    "    \n",
    "    print(f\"Actual date range: {df_work['Pay Document Date (dd/mm/yyyy)'].min()} to {df_work['Pay Document Date (dd/mm/yyyy)'].max()}\")\n",
    "    print(f\"Quarters found: {sorted(df_work['Quarter_Label'].unique())}\")\n",
    "    \n",
    "    # Step 5: Map payment types and fund sources\n",
    "    payment_type_mapping = {\n",
    "        'IP': 'Interim Payments',\n",
    "        'FP': 'Final Payments', \n",
    "        'PF': 'Pre-financing',\n",
    "        'EXPERTS': 'Experts and Support'\n",
    "    }\n",
    "    \n",
    "    # Keep original fund sources for now (don't map to C1/E0 yet)\n",
    "    df_work['Payment_Type_Desc'] = df_work['v_payment_type'].map(payment_type_mapping)\n",
    "    \n",
    "    # Use call_type if available, otherwise use Fund Source\n",
    "    if call_type_col:\n",
    "        df_work['Call_Type_Display'] = df_work[call_type_col]\n",
    "        print(f\"Call types found: {sorted(df_work['Call_Type_Display'].unique())}\")\n",
    "    else:\n",
    "        df_work['Call_Type_Display'] = df_work['Fund Source']\n",
    "        print(f\"Using Fund Source as call type: {sorted(df_work['Call_Type_Display'].unique())}\")\n",
    "    \n",
    "    # Handle unmapped payment types\n",
    "    unmapped_payments = df_work[df_work['Payment_Type_Desc'].isna()]['v_payment_type'].unique()\n",
    "    if len(unmapped_payments) > 0:\n",
    "        print(f\"WARNING: Unmapped payment types found: {unmapped_payments}\")\n",
    "        # Keep unmapped ones with their original value\n",
    "        df_work['Payment_Type_Desc'] = df_work['Payment_Type_Desc'].fillna(df_work['v_payment_type'])\n",
    "    \n",
    "    # Step 6: Split by Programme (H2020 and HEU)\n",
    "    programmes = df_work['Programme'].unique()\n",
    "    print(f\"Programmes found: {programmes}\")\n",
    "    \n",
    "    results = {\n",
    "        'metadata': {\n",
    "            'cutoff_date': cutoff_date,\n",
    "            'reporting_year': reporting_year,\n",
    "            'scope_start': scope_start,\n",
    "            'scope_end': scope_end,\n",
    "            'months_in_scope': months_in_report,\n",
    "            'actual_date_range': {\n",
    "                'start': df_work['Pay Document Date (dd/mm/yyyy)'].min(),\n",
    "                'end': df_work['Pay Document Date (dd/mm/yyyy)'].max()\n",
    "            },\n",
    "            'call_type_column': call_type_col,\n",
    "            'has_call_types': call_type_col is not None\n",
    "        },\n",
    "        'tables': {}\n",
    "    }\n",
    "    \n",
    "    for programme in programmes:\n",
    "        if programme not in ['H2020', 'HEU']:\n",
    "            print(f\"Skipping programme: {programme}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n=== Processing {programme} ===\")\n",
    "        df_prog = df_work[df_work['Programme'] == programme].copy()\n",
    "        \n",
    "        if len(df_prog) == 0:\n",
    "            print(f\"No data for {programme}\")\n",
    "            continue\n",
    "        \n",
    "        # Create aggregation tables\n",
    "        tables = create_programme_tables(df_prog, programme, reporting_year)\n",
    "        results['tables'][programme] = tables\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_programme_tables(df_prog, programme_name, reporting_year):\n",
    "    \"\"\"\n",
    "    Create all payment type tables for a specific programme\n",
    "    \"\"\"\n",
    "    \n",
    "    tables = {}\n",
    "    \n",
    "    # Get unique payment types in this programme\n",
    "    payment_types = df_prog['Payment_Type_Desc'].dropna().unique()\n",
    "    \n",
    "    for payment_type in payment_types:\n",
    "        print(f\"  Creating table for: {payment_type}\")\n",
    "        \n",
    "        df_type = df_prog[df_prog['Payment_Type_Desc'] == payment_type].copy()\n",
    "        \n",
    "        if len(df_type) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Create quarterly aggregation\n",
    "        quarterly_table = create_quarterly_aggregation(df_type, payment_type, reporting_year)\n",
    "        tables[payment_type] = quarterly_table\n",
    "    \n",
    "    # Create overall summary table\n",
    "    print(f\"  Creating overall summary table\")\n",
    "    overall_table = create_quarterly_aggregation(df_prog, \"All Payments\", reporting_year)\n",
    "    tables['All_Payments'] = overall_table\n",
    "    \n",
    "    return tables\n",
    "\n",
    "def create_quarterly_aggregation(df_type, payment_type_name, reporting_year):\n",
    "    \"\"\"\n",
    "    Create quarterly aggregation table for a specific payment type\n",
    "    - Amounts: Sum all v_amount_to_sum (including by call type/fund source)\n",
    "    - Transactions: Count unique Pay Payment Key\n",
    "    - VOBU/EFTA: Sum only EFTA and VOBU fund sources\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create base aggregation structure\n",
    "    agg_data = []\n",
    "    \n",
    "    # Get all quarters in the data\n",
    "    quarters = sorted(df_type['Quarter'].unique())\n",
    "    \n",
    "    for quarter in quarters:\n",
    "        df_q = df_type[df_type['Quarter'] == quarter].copy()\n",
    "        \n",
    "        # Get call types for this quarter (using Call_Type_Display)\n",
    "        call_types = df_q['Call_Type_Display'].unique()\n",
    "        \n",
    "        quarter_row = {\n",
    "            'Quarter': str(quarter),\n",
    "            'Quarter_Short': f\"{quarter.quarter}Q{quarter.year}\",\n",
    "            'Year': quarter.year,\n",
    "            'Payment_Type': payment_type_name,\n",
    "            'Reporting_Year': reporting_year\n",
    "        }\n",
    "        \n",
    "        # AMOUNTS: Sum all v_amount_to_sum by call type\n",
    "        total_amount_all_types = 0\n",
    "        vobu_efta_amount_all_types = 0\n",
    "        \n",
    "        for call_type in call_types:\n",
    "            df_call_type = df_q[df_q['Call_Type_Display'] == call_type]\n",
    "            \n",
    "            # Total amount for this call type\n",
    "            total_amount = df_call_type['v_amount_to_sum'].sum()\n",
    "            quarter_row[f'Total_Amount_{call_type}'] = total_amount\n",
    "            total_amount_all_types += total_amount\n",
    "            \n",
    "            # VOBU/EFTA amount: Only sum EFTA and VOBU fund sources\n",
    "            df_vobu_efta = df_call_type[df_call_type['Fund Source'].isin(['VOBU', 'EFTA'])]\n",
    "            vobu_efta_amount = df_vobu_efta['v_amount_to_sum'].sum()\n",
    "            quarter_row[f'VOBU_EFTA_Amount_{call_type}'] = vobu_efta_amount\n",
    "            vobu_efta_amount_all_types += vobu_efta_amount\n",
    "            \n",
    "            # TRANSACTIONS: Count unique Pay Payment Key for this call type\n",
    "            unique_transactions_call_type = df_call_type['Pay Payment Key'].nunique()\n",
    "            quarter_row[f'No_of_Transactions_{call_type}'] = unique_transactions_call_type\n",
    "        \n",
    "        # TRANSACTIONS: Count unique Pay Payment Key (deduplicated across all call types)\n",
    "        unique_transactions = df_q['Pay Payment Key'].nunique()\n",
    "        quarter_row['No_of_Transactions'] = unique_transactions\n",
    "        \n",
    "        # OVERALL TOTALS\n",
    "        quarter_row['Total_Amount'] = total_amount_all_types\n",
    "        quarter_row['VOBU_EFTA_Amount'] = vobu_efta_amount_all_types\n",
    "        \n",
    "        agg_data.append(quarter_row)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df_result = pd.DataFrame(agg_data)\n",
    "    \n",
    "    # Add total row\n",
    "    if len(df_result) > 0:\n",
    "        total_row = create_total_row(df_type, df_result, payment_type_name, reporting_year)\n",
    "        df_result = pd.concat([df_result, total_row], ignore_index=True)\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "def create_total_row(df_type, df_result, payment_type_name, reporting_year):\n",
    "    \"\"\"\n",
    "    Create total row for the aggregation table with VOBU/EFTA logic and transaction counts by call type\n",
    "    \"\"\"\n",
    "    \n",
    "    total_row = {\n",
    "        'Quarter': 'Total',\n",
    "        'Quarter_Short': 'Total',\n",
    "        'Year': reporting_year,\n",
    "        'Payment_Type': payment_type_name,\n",
    "        'Reporting_Year': reporting_year\n",
    "    }\n",
    "    \n",
    "    # Sum all amount columns (exclude Total row if it exists)\n",
    "    df_data_only = df_result[df_result['Quarter'] != 'Total']\n",
    "    \n",
    "    # Sum individual call type amounts\n",
    "    amount_cols = [col for col in df_result.columns if 'Amount' in col and col not in ['Total_Amount', 'VOBU_EFTA_Amount']]\n",
    "    for col in amount_cols:\n",
    "        total_row[col] = df_data_only[col].sum()\n",
    "    \n",
    "    # Calculate VOBU/EFTA total from original data (not summing quarterly totals to avoid double counting)\n",
    "    df_vobu_efta = df_type[df_type['Fund Source'].isin(['VOBU', 'EFTA'])]\n",
    "    total_row['VOBU_EFTA_Amount'] = df_vobu_efta['v_amount_to_sum'].sum()\n",
    "    \n",
    "    # Calculate transaction counts by call type from original data\n",
    "    call_types = df_type['Call_Type_Display'].unique()\n",
    "    for call_type in call_types:\n",
    "        df_call_type = df_type[df_type['Call_Type_Display'] == call_type]\n",
    "        total_row[f'No_of_Transactions_{call_type}'] = df_call_type['Pay Payment Key'].nunique()\n",
    "    \n",
    "    # Overall total amount\n",
    "    total_row['Total_Amount'] = df_type['v_amount_to_sum'].sum()\n",
    "    \n",
    "    # Sum unique transactions across all quarters (deduplicated at total level)\n",
    "    total_row['No_of_Transactions'] = df_type['Pay Payment Key'].nunique()\n",
    "    \n",
    "    return pd.DataFrame([total_row])\n",
    "\n",
    "def format_table_for_great_tables(df_table, payment_type, programme, repeat_quarter=True):\n",
    "    \"\"\"\n",
    "    Format table for great_tables library - creates clean pandas DataFrame\n",
    "    Structure exactly like Excel: Quarter | Metric | ADG | COG | POC | STG | SYG | Total\n",
    "    \n",
    "    Args:\n",
    "        repeat_quarter (bool): If True, repeat quarter value in each row. If False, show only once per group.\n",
    "                              True is recommended for great_tables compatibility.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(df_table) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Separate data rows from total row\n",
    "    df_data = df_table[df_table['Quarter'] != 'Total'].copy()\n",
    "    df_total = df_table[df_table['Quarter'] == 'Total'].copy()\n",
    "    \n",
    "    if len(df_data) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get unique quarters and call types from the data\n",
    "    quarters = sorted(df_data['Quarter_Short'].unique())\n",
    "    \n",
    "    # Extract call type columns from the dataframe\n",
    "    call_type_cols = [col for col in df_data.columns if col.startswith('Total_Amount_') and not col.endswith('Amount')]\n",
    "    call_types = sorted([col.replace('Total_Amount_', '') for col in call_type_cols if col != 'Total_Amount'])\n",
    "    \n",
    "    print(f\"  Formatting for great_tables - Call types: {call_types}, Quarters: {quarters}\")\n",
    "    print(f\"  Quarter repeat mode: {repeat_quarter}\")\n",
    "    \n",
    "    # Create the structure for great_tables - Quarter and Metric as separate columns\n",
    "    table_data = []\n",
    "    \n",
    "    # === PROCESS EACH QUARTER ===\n",
    "    for quarter in quarters:\n",
    "        quarter_data = df_data[df_data['Quarter_Short'] == quarter]\n",
    "        \n",
    "        if len(quarter_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        # ROW 1: Total Amount for this quarter\n",
    "        total_amount_row = {\n",
    "            'Quarter': quarter, \n",
    "            'Metric': 'Total Amount'\n",
    "        }\n",
    "        \n",
    "        for call_type in call_types:\n",
    "            amount_col = f'Total_Amount_{call_type}'\n",
    "            total_amount_row[call_type] = quarter_data[amount_col].iloc[0] if amount_col in quarter_data.columns else 0\n",
    "        \n",
    "        total_amount_row['Total'] = quarter_data['Total_Amount'].iloc[0]\n",
    "        table_data.append(total_amount_row)\n",
    "        \n",
    "        # ROW 2: Out of Which VOBU/EFTA for this quarter\n",
    "        vobu_efta_row = {\n",
    "            'Quarter': quarter if repeat_quarter else '', \n",
    "            'Metric': 'Out of Which VOBU/EFTA'\n",
    "        }\n",
    "        \n",
    "        for call_type in call_types:\n",
    "            vobu_efta_col = f'VOBU_EFTA_Amount_{call_type}'\n",
    "            vobu_efta_row[call_type] = quarter_data[vobu_efta_col].iloc[0] if vobu_efta_col in quarter_data.columns else 0\n",
    "        \n",
    "        vobu_efta_row['Total'] = quarter_data['VOBU_EFTA_Amount'].iloc[0]\n",
    "        table_data.append(vobu_efta_row)\n",
    "        \n",
    "        # ROW 3: No of Transactions for this quarter\n",
    "        transactions_row = {\n",
    "            'Quarter': quarter if repeat_quarter else '', \n",
    "            'Metric': 'No of Transactions'\n",
    "        }\n",
    "        \n",
    "        for call_type in call_types:\n",
    "            transactions_col = f'No_of_Transactions_{call_type}'\n",
    "            transactions_row[call_type] = quarter_data[transactions_col].iloc[0] if transactions_col in quarter_data.columns else 0\n",
    "        \n",
    "        transactions_row['Total'] = quarter_data['No_of_Transactions'].iloc[0]\n",
    "        table_data.append(transactions_row)\n",
    "    \n",
    "    # === TOTAL ROWS (from df_total) ===\n",
    "    if len(df_total) > 0:\n",
    "        \n",
    "        # TOTAL ROW 1: Total Amount\n",
    "        total_amount_row = {\n",
    "            'Quarter': 'Total', \n",
    "            'Metric': 'Total Amount'\n",
    "        }\n",
    "        \n",
    "        for call_type in call_types:\n",
    "            amount_col = f'Total_Amount_{call_type}'\n",
    "            total_amount_row[call_type] = df_total[amount_col].iloc[0] if amount_col in df_total.columns else 0\n",
    "        \n",
    "        total_amount_row['Total'] = df_total['Total_Amount'].iloc[0]\n",
    "        table_data.append(total_amount_row)\n",
    "        \n",
    "        # TOTAL ROW 2: Out of Which VOBU/EFTA\n",
    "        total_vobu_efta_row = {\n",
    "            'Quarter': 'Total' if repeat_quarter else '', \n",
    "            'Metric': 'Out of Which VOBU/EFTA'\n",
    "        }\n",
    "        \n",
    "        for call_type in call_types:\n",
    "            vobu_efta_col = f'VOBU_EFTA_Amount_{call_type}'\n",
    "            total_vobu_efta_row[call_type] = df_total[vobu_efta_col].iloc[0] if vobu_efta_col in df_total.columns else 0\n",
    "        \n",
    "        total_vobu_efta_row['Total'] = df_total['VOBU_EFTA_Amount'].iloc[0]\n",
    "        table_data.append(total_vobu_efta_row)\n",
    "        \n",
    "        # TOTAL ROW 3: No of Transactions\n",
    "        total_transactions_row = {\n",
    "            'Quarter': 'Total' if repeat_quarter else '', \n",
    "            'Metric': 'No of Transactions'\n",
    "        }\n",
    "        \n",
    "        for call_type in call_types:\n",
    "            transactions_col = f'No_of_Transactions_{call_type}'\n",
    "            total_transactions_row[call_type] = df_total[transactions_col].iloc[0] if transactions_col in df_total.columns else 0\n",
    "        \n",
    "        total_transactions_row['Total'] = df_total['No_of_Transactions'].iloc[0]\n",
    "        table_data.append(total_transactions_row)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    great_tables_df = pd.DataFrame(table_data)\n",
    "    \n",
    "    # Reorder columns: Quarter, Metric, then call types in alphabetical order, then Total\n",
    "    column_order = ['Quarter', 'Metric'] + call_types + ['Total']\n",
    "    great_tables_df = great_tables_df[column_order]\n",
    "    \n",
    "    return great_tables_df\n",
    "\n",
    "# Main execution function with periodicity integration\n",
    "def generate_all_quarterly_tables(df_paym, cutoff_date=None):\n",
    "    \"\"\"\n",
    "    Main function to generate all quarterly payment tables with proper periodicity handling\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Starting quarterly table generation with periodicity logic...\")\n",
    "    \n",
    "    if cutoff_date is not None:\n",
    "        print(f\"Using provided cutoff date: {cutoff_date}\")\n",
    "    else:\n",
    "        cutoff_date = pd.Timestamp.now()\n",
    "        print(f\"Using current date as cutoff: {cutoff_date}\")\n",
    "    \n",
    "    # Generate tables with scope filtering\n",
    "    results = create_quarterly_payment_tables(df_paym, cutoff_date)\n",
    "    \n",
    "    if results is None:\n",
    "        return None\n",
    "    \n",
    "    # Format for display\n",
    "    formatted_results = format_quarterly_tables_for_display(results)\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\n=== GENERATION COMPLETE ===\")\n",
    "    print(f\"Reporting for: {results['metadata']['reporting_year']}\")\n",
    "    print(f\"Scope: {results['metadata']['scope_start']} to {results['metadata']['scope_end']}\")\n",
    "    \n",
    "    if 'tables' in results:\n",
    "        for programme, tables in results['tables'].items():\n",
    "            print(f\"\\n{programme} Programme:\")\n",
    "            for payment_type, table in tables.items():\n",
    "                data_rows = len(table[table['Quarter'] != 'Total']) if len(table) > 0 else 0\n",
    "                print(f\"  - {payment_type}: {data_rows} quarters\")\n",
    "    \n",
    "    return formatted_results\n",
    "\n",
    "def format_quarterly_tables_for_great_tables(results):\n",
    "    \"\"\"\n",
    "    Format the results for great_tables library - clean pandas DataFrames\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'tables' not in results:\n",
    "        return results\n",
    "        \n",
    "    formatted_results = {\n",
    "        'metadata': results['metadata'],\n",
    "        'great_tables': {}\n",
    "    }\n",
    "    \n",
    "    for programme, tables in results['tables'].items():\n",
    "        formatted_results['great_tables'][programme] = {}\n",
    "        \n",
    "        for payment_type, df_table in tables.items():\n",
    "            # Create great_tables format\n",
    "            gt_table = format_table_for_great_tables(df_table, payment_type, programme)\n",
    "            formatted_results['great_tables'][programme][payment_type] = gt_table\n",
    "    \n",
    "    return formatted_results\n",
    "\n",
    "# Main execution function with great_tables output\n",
    "def generate_all_quarterly_tables(df_paym, cutoff_date=None):\n",
    "    \"\"\"\n",
    "    Main function to generate all quarterly payment tables for great_tables\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Starting quarterly table generation for great_tables...\")\n",
    "    \n",
    "    if cutoff_date is not None:\n",
    "        print(f\"Using provided cutoff date: {cutoff_date}\")\n",
    "    else:\n",
    "        cutoff_date = pd.Timestamp.now()\n",
    "        print(f\"Using current date as cutoff: {cutoff_date}\")\n",
    "    \n",
    "    # Generate tables with scope filtering\n",
    "    results = create_quarterly_payment_tables(df_paym, cutoff_date)\n",
    "    \n",
    "    if results is None:\n",
    "        return None\n",
    "    \n",
    "    # Format for great_tables\n",
    "    formatted_results = format_quarterly_tables_for_great_tables(results)\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\n=== GENERATION COMPLETE ===\")\n",
    "    print(f\"Reporting for: {results['metadata']['reporting_year']}\")\n",
    "    print(f\"Scope: {results['metadata']['scope_start']} to {results['metadata']['scope_end']}\")\n",
    "    print(f\"VOBU/EFTA aggregation: Only EFTA and VOBU fund sources included\")\n",
    "    \n",
    "    if 'tables' in results:\n",
    "        for programme, tables in results['tables'].items():\n",
    "            print(f\"\\n{programme} Programme:\")\n",
    "            for payment_type, table in tables.items():\n",
    "                data_rows = len(table[table['Quarter'] != 'Total']) if len(table) > 0 else 0\n",
    "                print(f\"  - {payment_type}: {data_rows} quarters\")\n",
    "    \n",
    "    return formatted_results\n",
    "\n",
    "# Updated utility functions for great_tables\n",
    "def get_great_table(formatted_results, programme, payment_type):\n",
    "    \"\"\"\n",
    "    Get a specific table formatted for great_tables\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return formatted_results['great_tables'][programme][payment_type]\n",
    "    except KeyError:\n",
    "        print(f\"Table not found: {programme} - {payment_type}\")\n",
    "        available_programmes = list(formatted_results.get('great_tables', {}).keys())\n",
    "        print(f\"Available programmes: {available_programmes}\")\n",
    "        if programme in formatted_results.get('great_tables', {}):\n",
    "            available_payment_types = list(formatted_results['great_tables'][programme].keys())\n",
    "            print(f\"Available payment types for {programme}: {available_payment_types}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def get_summary_table(formatted_results, programme):\n",
    "    \"\"\"\n",
    "    Get the summary table that includes all payment types (including experts)\n",
    "    \"\"\"\n",
    "    return get_great_table(formatted_results, programme, 'All_Payments')\n",
    "\n",
    "def create_comprehensive_summary_table(results, programme):\n",
    "    \"\"\"\n",
    "    Create a comprehensive summary table showing all payment types in one view\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'tables' not in results or programme not in results['tables']:\n",
    "        print(f\"No data found for programme: {programme}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    programme_tables = results['tables'][programme]\n",
    "    \n",
    "    # Initialize summary data\n",
    "    summary_data = []\n",
    "    \n",
    "    # Get all call types from any table\n",
    "    all_call_types = set()\n",
    "    for payment_type, table in programme_tables.items():\n",
    "        if payment_type != 'All_Payments' and len(table) > 0:\n",
    "            total_row = table[table['Quarter'] == 'Total']\n",
    "            if len(total_row) > 0:\n",
    "                call_type_cols = [col for col in total_row.columns if col.startswith('Total_Amount_')]\n",
    "                call_types = [col.replace('Total_Amount_', '') for col in call_type_cols]\n",
    "                all_call_types.update(call_types)\n",
    "    \n",
    "    all_call_types = sorted(list(all_call_types))\n",
    "    \n",
    "    # Create rows for each payment type\n",
    "    for payment_type, table in programme_tables.items():\n",
    "        if payment_type == 'All_Payments':\n",
    "            continue  # Skip the existing all payments, we'll create our own\n",
    "            \n",
    "        if len(table) == 0:\n",
    "            continue\n",
    "            \n",
    "        total_row = table[table['Quarter'] == 'Total']\n",
    "        if len(total_row) == 0:\n",
    "            continue\n",
    "            \n",
    "        # === TOTAL AMOUNT ROW ===\n",
    "        amount_row = {'Payment_Type': payment_type, 'Metric': 'Total Amount'}\n",
    "        \n",
    "        for call_type in all_call_types:\n",
    "            amount_col = f'Total_Amount_{call_type}'\n",
    "            amount_row[call_type] = total_row[amount_col].iloc[0] if amount_col in total_row.columns else 0\n",
    "        \n",
    "        amount_row['Total'] = total_row['Total_Amount'].iloc[0]\n",
    "        summary_data.append(amount_row)\n",
    "        \n",
    "        # === VOBU/EFTA ROW ===\n",
    "        vobu_efta_row = {'Payment_Type': payment_type, 'Metric': 'Out of Which VOBU/EFTA'}\n",
    "        \n",
    "        for call_type in all_call_types:\n",
    "            vobu_efta_col = f'VOBU_EFTA_Amount_{call_type}'\n",
    "            vobu_efta_row[call_type] = total_row[vobu_efta_col].iloc[0] if vobu_efta_col in total_row.columns else 0\n",
    "        \n",
    "        vobu_efta_row['Total'] = total_row['VOBU_EFTA_Amount'].iloc[0]\n",
    "        summary_data.append(vobu_efta_row)\n",
    "        \n",
    "        # === TRANSACTIONS ROW ===\n",
    "        transactions_row = {'Payment_Type': payment_type, 'Metric': 'No of Transactions'}\n",
    "        \n",
    "        for call_type in all_call_types:\n",
    "            transactions_col = f'No_of_Transactions_{call_type}'\n",
    "            transactions_row[call_type] = total_row[transactions_col].iloc[0] if transactions_col in total_row.columns else 0\n",
    "        \n",
    "        transactions_row['Total'] = total_row['No_of_Transactions'].iloc[0]\n",
    "        summary_data.append(transactions_row)\n",
    "    \n",
    "    # === CREATE OVERALL TOTALS ===\n",
    "    if summary_data:\n",
    "        # Get the All_Payments table data\n",
    "        all_payments_table = programme_tables.get('All_Payments', pd.DataFrame())\n",
    "        \n",
    "        if len(all_payments_table) > 0:\n",
    "            total_row = all_payments_table[all_payments_table['Quarter'] == 'Total']\n",
    "            \n",
    "            if len(total_row) > 0:\n",
    "                # TOTAL AMOUNTS ACROSS ALL PAYMENT TYPES\n",
    "                total_amount_row = {'Payment_Type': 'TOTAL ALL TYPES', 'Metric': 'Total Amount'}\n",
    "                for call_type in all_call_types:\n",
    "                    amount_col = f'Total_Amount_{call_type}'\n",
    "                    total_amount_row[call_type] = total_row[amount_col].iloc[0] if amount_col in total_row.columns else 0\n",
    "                total_amount_row['Total'] = total_row['Total_Amount'].iloc[0]\n",
    "                summary_data.append(total_amount_row)\n",
    "                \n",
    "                # TOTAL VOBU/EFTA ACROSS ALL PAYMENT TYPES\n",
    "                total_vobu_efta_row = {'Payment_Type': 'TOTAL ALL TYPES', 'Metric': 'Out of Which VOBU/EFTA'}\n",
    "                for call_type in all_call_types:\n",
    "                    vobu_efta_col = f'VOBU_EFTA_Amount_{call_type}'\n",
    "                    total_vobu_efta_row[call_type] = total_row[vobu_efta_col].iloc[0] if vobu_efta_col in total_row.columns else 0\n",
    "                total_vobu_efta_row['Total'] = total_row['VOBU_EFTA_Amount'].iloc[0]\n",
    "                summary_data.append(total_vobu_efta_row)\n",
    "                \n",
    "                # TOTAL TRANSACTIONS ACROSS ALL PAYMENT TYPES (deduplicated)\n",
    "                total_transactions_row = {'Payment_Type': 'TOTAL ALL TYPES', 'Metric': 'No of Transactions'}\n",
    "                for call_type in all_call_types:\n",
    "                    transactions_col = f'No_of_Transactions_{call_type}'\n",
    "                    total_transactions_row[call_type] = total_row[transactions_col].iloc[0] if transactions_col in total_row.columns else 0\n",
    "                total_transactions_row['Total'] = total_row['No_of_Transactions'].iloc[0]\n",
    "                summary_data.append(total_transactions_row)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    if summary_data:\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        \n",
    "        # Reorder columns\n",
    "        column_order = ['Payment_Type', 'Metric'] + all_call_types + ['Total']\n",
    "        summary_df = summary_df[column_order]\n",
    "        \n",
    "        return summary_df\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def create_payment_type_comparison_table(results, programme):\n",
    "    \"\"\"\n",
    "    Create a table showing just the totals for each payment type for easy comparison\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'tables' not in results or programme not in results['tables']:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    programme_tables = results['tables'][programme]\n",
    "    comparison_data = []\n",
    "    \n",
    "    for payment_type, table in programme_tables.items():\n",
    "        if payment_type == 'All_Payments':\n",
    "            continue\n",
    "            \n",
    "        if len(table) == 0:\n",
    "            continue\n",
    "            \n",
    "        total_row = table[table['Quarter'] == 'Total']\n",
    "        if len(total_row) == 0:\n",
    "            continue\n",
    "        \n",
    "        comparison_row = {\n",
    "            'Payment_Type': payment_type,\n",
    "            'Total_Amount': total_row['Total_Amount'].iloc[0],\n",
    "            'VOBU_EFTA_Amount': total_row['VOBU_EFTA_Amount'].iloc[0],\n",
    "            'No_of_Transactions': total_row['No_of_Transactions'].iloc[0]\n",
    "        }\n",
    "        \n",
    "        comparison_data.append(comparison_row)\n",
    "    \n",
    "    # Add overall total\n",
    "    if comparison_data:\n",
    "        all_payments_table = programme_tables.get('All_Payments', pd.DataFrame())\n",
    "        if len(all_payments_table) > 0:\n",
    "            total_row = all_payments_table[all_payments_table['Quarter'] == 'Total']\n",
    "            if len(total_row) > 0:\n",
    "                overall_row = {\n",
    "                    'Payment_Type': 'TOTAL ALL TYPES',\n",
    "                    'Total_Amount': total_row['Total_Amount'].iloc[0],\n",
    "                    'VOBU_EFTA_Amount': total_row['VOBU_EFTA_Amount'].iloc[0],\n",
    "                    'No_of_Transactions': total_row['No_of_Transactions'].iloc[0]\n",
    "                }\n",
    "                comparison_data.append(overall_row)\n",
    "    \n",
    "    return pd.DataFrame(comparison_data)\n",
    "\n",
    "def list_available_tables(formatted_results):\n",
    "    \"\"\"\n",
    "    List all available tables including summary options\n",
    "    \"\"\"\n",
    "    print(\"=== AVAILABLE TABLES FOR GREAT_TABLES ===\")\n",
    "    \n",
    "    if 'tables' not in formatted_results:\n",
    "        print(\"No tables found\")\n",
    "        return\n",
    "    \n",
    "    for programme, tables in formatted_results['tables'].items():\n",
    "        print(f\"\\n{programme} Programme:\")\n",
    "        for payment_type, df_table in tables.items():\n",
    "            rows, cols = df_table.shape\n",
    "            if payment_type == 'All_Payments':\n",
    "                print(f\"  - {payment_type}: {rows} rows x {cols} columns ⭐ SUMMARY TABLE\")\n",
    "            else:\n",
    "                print(f\"  - {payment_type}: {rows} rows x {cols} columns\")\n",
    "        \n",
    "        print(f\"\\n  📊 Access functions available:\")\n",
    "        print(f\"    # Individual payment types:\")\n",
    "        print(f\"    get_great_table(results, '{programme}', 'Pre-financing', repeat_quarter=True)  # Recommended\")\n",
    "        print(f\"    get_great_table_repeated(results, '{programme}', 'Pre-financing')  # Same as above\")\n",
    "        print(f\"    get_great_table_grouped(results, '{programme}', 'Pre-financing')   # Excel visual style\")\n",
    "        print(f\"    \")\n",
    "        print(f\"    # Summary tables:\")\n",
    "        print(f\"    get_summary_table(results, '{programme}', repeat_quarter=True)  # All payment types\")\n",
    "        print(f\"    create_comprehensive_summary_table(results, '{programme}')       # Alternative\")\n",
    "        print(f\"    create_payment_type_comparison_table(results, '{programme}')     # Quick comparison\")\n",
    "\n",
    "def get_all_programme_tables(formatted_results, programme):\n",
    "    \"\"\"\n",
    "    Get all tables for a specific programme as a dictionary\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return formatted_results['tables'][programme]\n",
    "    except KeyError:\n",
    "        print(f\"Programme not found: {programme}\")\n",
    "        available = list(formatted_results.get('tables', {}).keys())\n",
    "        print(f\"Available programmes: {available}\")\n",
    "        return {}\n",
    "\n",
    "def combine_payment_types_table(formatted_results, programme):\n",
    "    \"\"\"\n",
    "    Combine all payment types for a programme into one large table\n",
    "    \"\"\"\n",
    "    programme_tables = get_all_programme_tables(formatted_results, programme)\n",
    "    \n",
    "    if not programme_tables:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    combined_tables = []\n",
    "    \n",
    "    for payment_type, df_table in programme_tables.items():\n",
    "        if len(df_table) > 0:\n",
    "            # Add a separator row if not the first table\n",
    "            if len(combined_tables) > 0:\n",
    "                separator_row = pd.DataFrame([{\n",
    "                    'Metric': f'--- {payment_type} ---',\n",
    "                    **{col: '' for col in df_table.columns if col != 'Metric'}\n",
    "                }])\n",
    "                combined_tables.append(separator_row)\n",
    "            \n",
    "            combined_tables.append(df_table)\n",
    "    \n",
    "    if combined_tables:\n",
    "        return pd.concat(combined_tables, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Example usage functions\n",
    "def show_table_summary_for_great_tables(formatted_results):\n",
    "    \"\"\"Display summary of all generated tables for great_tables\"\"\"\n",
    "    print(\"=== QUARTERLY TABLES SUMMARY FOR GREAT_TABLES ===\")\n",
    "    print(f\"Reporting Period: {formatted_results['metadata']['reporting_year']}\")\n",
    "    print(f\"Data Range: {formatted_results['metadata']['actual_date_range']['start'].strftime('%Y-%m-%d')} to {formatted_results['metadata']['actual_date_range']['end'].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"VOBU/EFTA Logic: Aggregates only EFTA and VOBU fund sources\")\n",
    "    \n",
    "    if 'great_tables' in formatted_results:\n",
    "        for programme, tables in formatted_results['great_tables'].items():\n",
    "            print(f\"\\n{programme}:\")\n",
    "            for payment_type, table in tables.items():\n",
    "                if len(table) > 0:\n",
    "                    # Get total amounts from the 'Total Amount' row\n",
    "                    total_amount_row = table[table['Metric'] == 'Total Amount']\n",
    "                    vobu_efta_row = table[table['Metric'] == 'Out of Which VOBU/EFTA']\n",
    "                    transactions_row = table[table['Metric'] == 'No of Transactions']\n",
    "                    \n",
    "                    if len(total_amount_row) > 0:\n",
    "                        total_amount = total_amount_row['Total'].iloc[0]\n",
    "                        vobu_efta_amount = vobu_efta_row['Total'].iloc[0] if len(vobu_efta_row) > 0 else 0\n",
    "                        total_transactions = transactions_row['Total'].iloc[0] if len(transactions_row) > 0 else 0\n",
    "                        print(f\"  {payment_type}: €{total_amount:,.0f} total (€{vobu_efta_amount:,.0f} VOBU/EFTA) - {total_transactions} transactions\")\n",
    "\n",
    "# Updated access examples\n",
    "# Backwards compatibility functions\n",
    "def get_excel_format_table(formatted_results, programme, payment_type):\n",
    "    \"\"\"\n",
    "    Backwards compatibility function - redirects to get_great_table\n",
    "    \"\"\"\n",
    "    print(\"Note: get_excel_format_table is deprecated, use get_great_table for great_tables formatting\")\n",
    "    return get_great_table(formatted_results, programme, payment_type)\n",
    "\n",
    "def show_table_summary(formatted_results):\n",
    "    \"\"\"\n",
    "    Backwards compatibility function - redirects to show_table_summary_for_great_tables\n",
    "    \"\"\"\n",
    "    return show_table_summary_for_great_tables(formatted_results)\n",
    "\n",
    "# Updated access examples with summary tables\n",
    "def print_usage_instructions():\n",
    "    \"\"\"\n",
    "    Print instructions for using the generated tables including summary tables\n",
    "    \"\"\"\n",
    "    print(\"\"\"\n",
    "=== HOW TO USE THE QUARTERLY TABLES (Two Format Options) ===\n",
    "\n",
    "1. GENERATE TABLES:\n",
    "   quarterly_tables = generate_all_quarterly_tables(df_paym, cutoff)\n",
    "\n",
    "2. ACCESS INDIVIDUAL PAYMENT TYPE TABLES:\n",
    "   \n",
    "   # OPTION A: Repeated quarters (RECOMMENDED for great_tables)\n",
    "   heu_prefinancing = get_great_table(quarterly_tables, 'HEU', 'Pre-financing', repeat_quarter=True)\n",
    "   heu_interim = get_great_table(quarterly_tables, 'HEU', 'Interim Payments', repeat_quarter=True)\n",
    "   \n",
    "   # OPTION B: Grouped quarters (Excel visual style)\n",
    "   heu_prefinancing_grouped = get_great_table(quarterly_tables, 'HEU', 'Pre-financing', repeat_quarter=False)\n",
    "   \n",
    "   # Shortcut functions:\n",
    "   heu_prefinancing = get_great_table_repeated(quarterly_tables, 'HEU', 'Pre-financing')  # Same as Option A\n",
    "   heu_prefinancing_grouped = get_great_table_grouped(quarterly_tables, 'HEU', 'Pre-financing')  # Same as Option B\n",
    "\n",
    "3. ACCESS SUMMARY TABLES (ALL PAYMENT TYPES INCLUDING EXPERTS):\n",
    "   \n",
    "   # Summary table with repeated quarters (recommended for great_tables)\n",
    "   heu_summary = get_summary_table(quarterly_tables, 'HEU', repeat_quarter=True)\n",
    "   \n",
    "   # Summary table with grouped quarters (Excel visual style)\n",
    "   heu_summary_grouped = get_summary_table(quarterly_tables, 'HEU', repeat_quarter=False)\n",
    "   \n",
    "   # Alternative access\n",
    "   heu_summary_alt = create_comprehensive_summary_table(quarterly_tables, 'HEU', repeat_quarter=True)\n",
    "   \n",
    "   # Quick comparison table (different format - just totals by payment type)\n",
    "   heu_comparison = create_payment_type_comparison_table(quarterly_tables, 'HEU')\n",
    "\n",
    "4. LIST ALL AVAILABLE TABLES:\n",
    "   list_available_tables(quarterly_tables)\n",
    "\n",
    "5. USE WITH GREAT_TABLES:\n",
    "   from great_tables import GT\n",
    "   \n",
    "   # Individual payment type (using repeated format)\n",
    "   gt_table = (\n",
    "       GT(heu_prefinancing)\n",
    "       .tab_header(title=\"HEU Pre-financing\", subtitle=\"Q1 2025\")\n",
    "       .fmt_currency(columns=['ADG', 'COG', 'POC', 'STG', 'SYG', 'Total'], currency='EUR')\n",
    "       .tab_row_group(label=\"2024Q1\", rows=[\"2024Q1\"])  # Can group by Quarter if using repeated format\n",
    "   )\n",
    "\n",
    "FORMAT OPTIONS:\n",
    "\n",
    "OPTION A - Repeated Quarters (RECOMMENDED for great_tables):\n",
    "Quarter | Metric                  | ADG | COG | POC | STG | SYG | Total\n",
    "2024Q1  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
    "2024Q1  | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
    "2024Q1  | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
    "2024Q2  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
    "2024Q2  | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
    "2024Q2  | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
    "\n",
    "OPTION B - Grouped Quarters (Excel visual style):\n",
    "Quarter | Metric                  | ADG | COG | POC | STG | SYG | Total\n",
    "2024Q1  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
    "        | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
    "        | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
    "2024Q2  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
    "        | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
    "        | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
    "\n",
    "RECOMMENDATION:\n",
    "✅ Use repeat_quarter=True (Option A) for great_tables - better for:\n",
    "  - Data processing and filtering\n",
    "  - Row grouping operations\n",
    "  - Exporting to other formats\n",
    "  - Table manipulation\n",
    "\n",
    "Use repeat_quarter=False (Option B) for:\n",
    "  - Pure visual presentation matching Excel\n",
    "  - When you want minimal visual clutter\n",
    "\"\"\")\n",
    "\n",
    "def show_summary_examples():\n",
    "    \"\"\"\n",
    "    Show examples of the different summary table options with correct format\n",
    "    \"\"\"\n",
    "    print(\"\"\"\n",
    "=== SUMMARY TABLE EXAMPLES (Both Format Options) ===\n",
    "\n",
    "# 1a. Summary table with repeated quarters (RECOMMENDED for great_tables)\n",
    "heu_summary = get_summary_table(quarterly_tables, 'HEU', repeat_quarter=True)\n",
    "# Quarter | Metric                  | ADG | COG | POC | STG | SYG | Total\n",
    "# 2024Q1  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
    "# 2024Q1  | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
    "# 2024Q1  | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
    "# Total   | Total Amount            | ... | ... | ... | ... | ... | ...\n",
    "# Total   | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
    "# Total   | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
    "\n",
    "# 1b. Summary table with grouped quarters (Excel visual style)\n",
    "heu_summary_grouped = get_summary_table(quarterly_tables, 'HEU', repeat_quarter=False)\n",
    "# Quarter | Metric                  | ADG | COG | POC | STG | SYG | Total\n",
    "# 2024Q1  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
    "#         | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
    "#         | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
    "# Total   | Total Amount            | ... | ... | ... | ... | ... | ...\n",
    "#         | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
    "#         | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
    "\n",
    "# 2. Quick comparison (different format - by payment type)\n",
    "heu_comparison = create_payment_type_comparison_table(quarterly_tables, 'HEU')\n",
    "# Payment_Type | Total_Amount | VOBU_EFTA_Amount | No_of_Transactions\n",
    "# Pre-financing | 352,568,326 | 336,797,403 | 309\n",
    "# Interim Payments | 185,710,686 | 175,320,845 | 115\n",
    "# TOTAL ALL TYPES | 1,628,225,910 | 1,398,938,052 | 1,573\n",
    "\n",
    "BOTH formats contain the same data, just different visual presentation!\n",
    "\"\"\")\n",
    "\n",
    "# If run directly, show instructions\n",
    "if __name__ == \"__main__\":\n",
    "    print_usage_instructions()\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    show_summary_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f6cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "quarterly_tables = generate_all_quarterly_tables(df_paym, cutoff )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b86c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_tables import GT, md, loc, style\n",
    "import pandas as pd\n",
    "\n",
    "def format_table_clean(df, title=\"HEU grants - all payments, number of transactions, and corresponding amounts\",\n",
    "                          rowname_col=\"Metric\", groupname_col=\"Quarter\", \n",
    "                          programme_name=\"HEU\", metric_col=\"Metric\",\n",
    "                          table_colors=None):\n",
    "    \"\"\"\n",
    "    Clean, single-pass HEU table formatter that applies all styling consistently\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with data to format\n",
    "        title: Table title\n",
    "        rowname_col: Column name for row names (e.g. \"Quarter\")\n",
    "        groupname_col: Column name for groups (e.g. \"Year\")\n",
    "        programme_name: Program name for spanner label (e.g. \"HEU\")\n",
    "        metric_col: Metric column name (e.g. \"Metric\")\n",
    "        table_colors: Dictionary with custom colors\n",
    "    \"\"\"\n",
    "    \n",
    "    # Default colors if not provided\n",
    "    if table_colors is None:\n",
    "        table_colors = {}\n",
    "    \n",
    "    BLUE = table_colors.get(\"BLUE\", \"#004A99\")\n",
    "    LIGHT_BLUE = table_colors.get(\"LIGHT_BLUE\", \"#d6e6f4\")\n",
    "    DARK_BLUE = table_colors.get(\"DARK_BLUE\", \"#01244B\") \n",
    "    SUB_TOTAL_BACKGROUND = table_colors.get(\"subtotal_background_color\", \"#E6E6FA\")\n",
    "    \n",
    "    # Identify columns and rows for formatting\n",
    "    exclude_cols = [rowname_col, groupname_col, metric_col]\n",
    "    spanner_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "    num_data_columns = len(spanner_cols)\n",
    "\n",
    "    # Smart width calculation based on column count\n",
    "    if num_data_columns == 1:\n",
    "        # Single column: compact table\n",
    "        stub_width = 180\n",
    "        column_width = 140\n",
    "        base_width = stub_width + column_width + 100  # Extra padding for single column\n",
    "        \n",
    "    elif num_data_columns == 2:\n",
    "        # Two columns: still compact but balanced\n",
    "        stub_width = 160\n",
    "        column_width = 130\n",
    "        base_width = stub_width + (num_data_columns * column_width) + 80\n",
    "        \n",
    "    elif num_data_columns <= 4:\n",
    "        # Few columns: moderate width\n",
    "        stub_width = 140\n",
    "        column_width = 120\n",
    "        base_width = stub_width + (num_data_columns * column_width) + 60\n",
    "        \n",
    "    elif num_data_columns <= 7:\n",
    "        # Standard columns: your current formula works well\n",
    "        stub_width = 140\n",
    "        column_width = 110\n",
    "        base_width = stub_width + (num_data_columns * column_width) + 50\n",
    "        \n",
    "    else:\n",
    "        # Many columns: slightly narrower columns to fit\n",
    "        stub_width = 130\n",
    "        column_width = 100\n",
    "        base_width = stub_width + (num_data_columns * column_width) + 40\n",
    "    \n",
    "    # Apply reasonable min/max bounds\n",
    "    min_width = 400 if num_data_columns == 1 else 500\n",
    "    max_width = 1600\n",
    "    \n",
    "    optimal_width = max(min_width, min(base_width, max_width))\n",
    "\n",
    "    \n",
    "    # Identify special rows\n",
    "    total_rows_indices = df.index[df[rowname_col].astype(str).str.contains('VOBU/EFTA', case=False, na=False)].tolist()\n",
    "    amount_mask = df[metric_col].str.contains('Total Amount|Out of Which', case=False, na=False)\n",
    "    amount_rows = df[amount_mask].index.tolist()\n",
    "    transaction_mask = df[metric_col].str.contains('No of Transactions', case=False, na=False)\n",
    "    transaction_rows = df[transaction_mask].index.tolist()\n",
    "\n",
    "    \n",
    "    # Create and format table in ONE clean chain\n",
    "    tbl = (\n",
    "        GT(df, \n",
    "           rowname_col=rowname_col, \n",
    "           groupname_col=groupname_col)\n",
    "        \n",
    "        # 1. Basic setup\n",
    "        .tab_header(title=md(title))\n",
    "        .tab_spanner(label=programme_name, columns=spanner_cols)\n",
    "        .tab_stubhead(label=\"Quarter\")\n",
    " \n",
    "        \n",
    "        # 2. Table options\n",
    "        .tab_options(\n",
    "            table_font_size=\"12px\",\n",
    "            table_width=\"100%\",\n",
    "            table_font_color=DARK_BLUE,\n",
    "        )\n",
    "\n",
    "        #3.Apply Theme \n",
    "        .opt_stylize(style=3, color='blue')\n",
    "        \n",
    "        #4. Customize Theme \n",
    "        .tab_style(\n",
    "            style=[\n",
    "                style.text(color=DARK_BLUE, weight=\"bold\", font='Arial'),\n",
    "            ],\n",
    "            locations=[\n",
    "                loc.body(rows=total_rows_indices),\n",
    "                loc.stub(rows=total_rows_indices)\n",
    "            ]\n",
    "        )\n",
    "        .opt_table_font(font=\"Arial\")\n",
    "        .tab_options(\n",
    "                table_background_color=\"white\",\n",
    "                heading_background_color=\"white\",\n",
    "                #  stub_background_color=\"#0076BA\",\n",
    "                table_font_size='small',\n",
    "                row_group_font_size='small',\n",
    "                row_group_font_weight='bold',\n",
    "                table_width='800px',\n",
    "        )\n",
    "        \n",
    "        # 5. Currency formatting\n",
    "        .fmt_currency(\n",
    "            columns=spanner_cols,\n",
    "            rows=amount_rows,\n",
    "            currency=\"EUR\",\n",
    "            decimals=2,\n",
    "            use_seps=True\n",
    "        )\n",
    "        \n",
    "        # 6. Integer formatting\n",
    "        .fmt_integer(\n",
    "            columns=spanner_cols,\n",
    "            rows=transaction_rows,\n",
    "            use_seps=True\n",
    "        )\n",
    "  \n",
    "    )\n",
    "   \n",
    "    return tbl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30779b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED VERSION OF YOUR CODE WITH SUGGESTIONS\n",
    "\n",
    "def generate_all_program_tables(quarterly_tables, db_path, report, table_colors, logger):\n",
    "    \"\"\"\n",
    "    Generate and save all program tables with improved error handling and cleaner logic\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuration - easier to maintain\n",
    "    PROGRAMS = ['HEU', 'H2020']\n",
    "    \n",
    "    # Payment types with corresponding titles - eliminates if/elif chain\n",
    "    PAYMENT_TYPES = {\n",
    "        'All_Payments': 'All payments: number of transactions, and corresponding amounts',\n",
    "        'Pre-financing': 'Pre-financing: number of transactions, and corresponding amounts', \n",
    "        'Interim Payments': 'Interim Payments: number of transactions, and corresponding amounts',\n",
    "        'Final Payments': 'Final Payments: number of transactions, and corresponding amounts',\n",
    "        'Experts and Support': 'Experts and Support: number of transactions, and corresponding amounts'\n",
    "    }\n",
    "    \n",
    "    # Track success/failure statistics\n",
    "    results = {\n",
    "        'successful': [],\n",
    "        'failed': [],\n",
    "        'skipped': []\n",
    "    }\n",
    "    \n",
    "    logger.info(f\"🚀 Starting table generation for {len(PROGRAMS)} programs × {len(PAYMENT_TYPES)} payment types\")\n",
    "    \n",
    "    for program in PROGRAMS:\n",
    "        logger.info(f\"📊 Processing program: {program}\")\n",
    "        \n",
    "        for pay_type, title in PAYMENT_TYPES.items():\n",
    "            var_name = f'{program}_{pay_type}'\n",
    "            \n",
    "            try:\n",
    "                # 1. Get table data\n",
    "                logger.debug(f\"Fetching data for {var_name}\")\n",
    "                table_data = get_great_table(quarterly_tables, program, pay_type)\n",
    "                \n",
    "                # Fixed DataFrame validation - avoid ambiguous truth value\n",
    "                if table_data is None or (isinstance(table_data, pd.DataFrame) and table_data.empty):\n",
    "                    logger.warning(f\"⚠️  No data found for {var_name} - skipping\")\n",
    "                    results['skipped'].append(var_name)\n",
    "                    continue\n",
    "                \n",
    "                # Additional validation - check if DataFrame has the expected structure\n",
    "                if isinstance(table_data, pd.DataFrame):\n",
    "                    required_columns = [\"Metric\", \"Quarter\"]  # Add other required columns as needed\n",
    "                    missing_columns = [col for col in required_columns if col not in table_data.columns]\n",
    "                    if missing_columns:\n",
    "                        logger.error(f\"❌ Missing required columns in {var_name}: {missing_columns}\")\n",
    "                        results['failed'].append(f\"{var_name} (missing columns)\")\n",
    "                        continue\n",
    "                \n",
    "                # 2. Format table\n",
    "                logger.debug(f\"Formatting table for {var_name}\")\n",
    "                formatted_table = format_table_clean(  # Using your improved function\n",
    "                    df=table_data,\n",
    "                    title=f\"{program} grants - {title}\",  # More descriptive title\n",
    "                    rowname_col=\"Metric\",\n",
    "                    groupname_col=\"Quarter\",\n",
    "                    programme_name=program,\n",
    "                    metric_col=\"Metric\",\n",
    "                    table_colors=table_colors\n",
    "                )\n",
    "                \n",
    "                # 3. Save to database\n",
    "                logger.debug(f\"Saving {var_name} to database\")\n",
    "                insert_variable(\n",
    "                    report=report,\n",
    "                    module=\"AuritModule\",\n",
    "                    var=var_name,\n",
    "                    value=table_data.to_dict() if isinstance(table_data, pd.DataFrame) else table_data,\n",
    "                    db_path=db_path,\n",
    "                    anchor=var_name,\n",
    "                    gt_table=formatted_table\n",
    "                )\n",
    "                \n",
    "                logger.info(f\"✅ Successfully processed {var_name}\")\n",
    "                results['successful'].append(var_name)\n",
    "                \n",
    "            except KeyError as e:\n",
    "                logger.error(f\"❌ Data source not found for {var_name}: {str(e)}\")\n",
    "                results['failed'].append(f\"{var_name} (data not found)\")\n",
    "                \n",
    "            except ValueError as e:\n",
    "                logger.error(f\"❌ Data validation error for {var_name}: {str(e)}\")\n",
    "                results['failed'].append(f\"{var_name} (validation error)\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"❌ Unexpected error processing {var_name}: {str(e)}\")\n",
    "                results['failed'].append(f\"{var_name} (unexpected error)\")\n",
    "    \n",
    "    # Summary report\n",
    "    logger.info(\"\\n\" + \"=\"*50)\n",
    "    logger.info(\"📈 TABLE GENERATION SUMMARY\")\n",
    "    logger.info(\"=\"*50)\n",
    "    logger.info(f\"✅ Successful: {len(results['successful'])}\")\n",
    "    logger.info(f\"❌ Failed: {len(results['failed'])}\")\n",
    "    logger.info(f\"⚠️  Skipped: {len(results['skipped'])}\")\n",
    "    \n",
    "    if results['successful']:\n",
    "        logger.info(f\"\\n✅ Successful tables: {', '.join(results['successful'])}\")\n",
    "    \n",
    "    if results['failed']:\n",
    "        logger.warning(f\"\\n❌ Failed tables: {', '.join(results['failed'])}\")\n",
    "    \n",
    "    if results['skipped']:\n",
    "        logger.warning(f\"\\n⚠️  Skipped tables: {', '.join(results['skipped'])}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def check_available_data(quarterly_tables, logger):\n",
    "    \"\"\"\n",
    "    Check what data is actually available for each program and payment type\n",
    "    \"\"\"\n",
    "    PROGRAMS = ['HEU', 'H2020']\n",
    "    PAYMENT_TYPES = ['All_Payments', 'Pre-financing', 'Interim Payments', 'Final Payments']\n",
    "    \n",
    "    logger.info(\"🔍 CHECKING AVAILABLE DATA:\")\n",
    "    logger.info(\"=\"*40)\n",
    "    \n",
    "    availability_map = {}\n",
    "    \n",
    "    for program in PROGRAMS:\n",
    "        logger.info(f\"\\n📊 Program: {program}\")\n",
    "        available_types = []\n",
    "        \n",
    "        for pay_type in PAYMENT_TYPES:\n",
    "            try:\n",
    "                table_data = get_great_table(quarterly_tables, program, pay_type)\n",
    "                if table_data is not None and isinstance(table_data, pd.DataFrame) and not table_data.empty:\n",
    "                    logger.info(f\"  ✅ {pay_type}: Available ({len(table_data)} rows)\")\n",
    "                    available_types.append(pay_type)\n",
    "                else:\n",
    "                    logger.warning(f\"  ❌ {pay_type}: Not available or empty\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"  ❌ {pay_type}: Error - {str(e)}\")\n",
    "        \n",
    "        availability_map[program] = available_types\n",
    "        logger.info(f\"  📋 Available for {program}: {available_types}\")\n",
    "    \n",
    "    return availability_map\n",
    "\n",
    "\n",
    "# ALTERNATIVE: More modular approach\n",
    "def process_single_table(quarterly_tables, program, pay_type, title, \n",
    "                        db_path, report, table_colors, logger):\n",
    "    \"\"\"\n",
    "    Process a single program/payment type combination\n",
    "    Returns: (success: bool, message: str)\n",
    "    \"\"\"\n",
    "    var_name = f'{program}_{pay_type}'\n",
    "    \n",
    "    try:\n",
    "        # Get data\n",
    "        table_data = get_great_table(quarterly_tables, program, pay_type)\n",
    "        \n",
    "        if table_data is None or (isinstance(table_data, pd.DataFrame) and table_data.empty):\n",
    "            return False, f\"No data available for {var_name}\"\n",
    "        \n",
    "        # Format table\n",
    "        formatted_table = format_table_clean(\n",
    "            df=table_data,\n",
    "            title=f\"{program} grants - {title}\",\n",
    "            rowname_col=\"Metric\",\n",
    "            groupname_col=\"Quarter\",\n",
    "            programme_name=program,\n",
    "            metric_col=\"Metric\",\n",
    "            table_colors=table_colors\n",
    "        )\n",
    "        \n",
    "        # Save to database\n",
    "        insert_variable(\n",
    "            report=report,\n",
    "            module=\"PaymentsModule\",\n",
    "            var=var_name,\n",
    "            value=table_data.to_dict() if isinstance(table_data, pd.DataFrame) else table_data,\n",
    "            db_path=db_path,\n",
    "            anchor=var_name,\n",
    "            gt_table=formatted_table\n",
    "        )\n",
    "        \n",
    "        return True, f\"Successfully processed {var_name}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return False, f\"Error processing {var_name}: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "generate_all_program_tables(quarterly_tables, db_path, report, table_colors, logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d3d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_all = fetch_vars_for_report(report, db_path)\n",
    "heu_vars_data = vars_all.get('table_2a_HE')\n",
    "h2020_vars_data = vars_all.get('table_2a_H2020')\n",
    "\n",
    "heu_total_appropriations = next(\n",
    "    (item['Available_Payment_Appropriations'] for item in heu_vars_data \n",
    "     if item['Budget Address Type'] == 'Total'), \n",
    "    None\n",
    ")\n",
    "\n",
    "heu_total_appropriations_expt = next(\n",
    "    (item['Available_Payment_Appropriations'] for item in heu_vars_data \n",
    "     if item['Budget Address Type'] == 'Experts'), \n",
    "    None\n",
    ")\n",
    "\n",
    "h2020_total_appropriations = next(\n",
    "    (item['Available_Payment_Appropriations'] for item in h2020_vars_data \n",
    "     if item['Budget Address Type'] == 'Total'), \n",
    "    None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3714a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"database/reporting.db\"\n",
    "DB_PATH = Path(\"database/reporting.db\")\n",
    "report = 'Quarterly_Report'\n",
    "report_params = load_report_params(report_name=report, db_path=DB_PATH )\n",
    "TTP_gross = report_params.get(\"TTP_GROSS_HISTORY\")\n",
    "TTP_gross_H2020 = TTP_gross.get('H2020')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4177733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# =============================================================================\n",
    "# CLEAN TTP CALCULATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_current_ttp_metrics(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Calculate current TTP metrics from df_paym data\n",
    "    \"\"\"\n",
    "    # Filter data up to cutoff and deduplicate by Pay Payment Key\n",
    "    quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "    last_valid_date = quarter_dates[1]\n",
    "\n",
    "    df_filtered = df_paym[\n",
    "        df_paym['Pay Document Date (dd/mm/yyyy)'] <= last_valid_date\n",
    "    ].copy()\n",
    "    df_unique = df_filtered.drop_duplicates(subset=['Pay Payment Key']).copy()\n",
    "    \n",
    "    # Convert to numeric\n",
    "    df_unique['v_TTP_NET'] = pd.to_numeric(df_unique['v_TTP_NET'], errors='coerce')\n",
    "    df_unique['v_TTP_GROSS'] = pd.to_numeric(df_unique['v_TTP_GROSS'], errors='coerce')\n",
    "    df_unique['v_payment_in_time'] = pd.to_numeric(df_unique['v_payment_in_time'], errors='coerce')\n",
    "\n",
    "    # Filter out negative TTP_NET values\n",
    "    df_unique = df_unique[df_unique['v_TTP_NET'] >= 0]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Calculate by Programme and Payment Type\n",
    "    for programme in ['H2020', 'HEU']:\n",
    "        prog_data = df_unique[df_unique['Programme'] == programme]\n",
    "        if len(prog_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        results[programme] = {}\n",
    "        \n",
    "        # Overall programme metrics\n",
    "        prog_valid = prog_data[prog_data['v_payment_in_time'].notna()]\n",
    "        results[programme]['overall'] = {\n",
    "            'avg_ttp_net': prog_data['v_TTP_NET'].mean(),\n",
    "            'avg_ttp_gross': prog_data['v_TTP_GROSS'].mean(),\n",
    "            'on_time_pct': prog_data['v_payment_in_time'].sum() / len(prog_valid) if len(prog_valid) > 0 else 0\n",
    "        }\n",
    "        \n",
    "        # By payment type - using correct short form values from v_payment_type\n",
    "        payment_types = ['IP', 'FP', 'EXPERTS', 'PF']  # Short form values\n",
    "        \n",
    "        for payment_type in payment_types:\n",
    "            pt_data = prog_data[prog_data['v_payment_type'] == payment_type]\n",
    "            if len(pt_data) > 0:\n",
    "                pt_valid = pt_data[pt_data['v_payment_in_time'].notna()]\n",
    "                results[programme][payment_type] = {\n",
    "                    'avg_ttp_net': pt_data['v_TTP_NET'].mean(),\n",
    "                    'avg_ttp_gross': pt_data['v_TTP_GROSS'].mean(),\n",
    "                    'on_time_pct': pt_data['v_payment_in_time'].sum() / len(pt_valid) if len(pt_valid) > 0 else 0\n",
    "                }\n",
    "    \n",
    "    # Overall total\n",
    "    total_valid = df_unique[df_unique['v_payment_in_time'].notna()]\n",
    "    results['TOTAL'] = {\n",
    "        'avg_ttp_net': df_unique['v_TTP_NET'].mean(),\n",
    "        'avg_ttp_gross': df_unique['v_TTP_GROSS'].mean(),\n",
    "        'on_time_pct': df_unique['v_payment_in_time'].sum() / len(total_valid) if len(total_valid) > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def load_historical_ttp_data(report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Load historical TTP data from database\n",
    "    \"\"\"\n",
    "    DB_PATH = Path(db_path)\n",
    "    report_params = load_report_params(report_name=report_name, db_path=DB_PATH)\n",
    "    \n",
    "    return {\n",
    "        \"TTP_NET_HISTORY\": report_params.get(\"TTP_NET_HISTORY\"),\n",
    "        \"TTP_GROSS_HISTORY\": report_params.get(\"TTP_GROSS_HISTORY\"),\n",
    "        \"PAYMENTS_ON_TIME_HISTORY\": report_params.get(\"PAYMENTS_ON_TIME_HISTORY\")\n",
    "    }\n",
    "\n",
    "def create_ttp_comparison_table(df_paym, cutoff, historical_data):\n",
    "    \"\"\"\n",
    "    Create TTP comparison table matching the image structure\n",
    "    \"\"\"\n",
    "    # Calculate current metrics\n",
    "    current_metrics = calculate_current_ttp_metrics(df_paym, cutoff)\n",
    "    \n",
    "    # Determine labels based on cutoff\n",
    "    cutoff_date = pd.to_datetime(cutoff)\n",
    "    current_year = cutoff_date.year\n",
    "    current_label = f\"{current_year}-YTD\"\n",
    "    historical_label = f\"Dec {current_year - 1}\"\n",
    "    \n",
    "    # Build comparison data\n",
    "    comparison_data = []\n",
    "    \n",
    "    # H2020 section\n",
    "    h2020_current = current_metrics.get('H2020', {})\n",
    "    \n",
    "    # H2020 - Interim Payments (IP)\n",
    "    current_ip = h2020_current.get('IP', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Interim Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_ip['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"H2020\"].get(\"IP\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_ip['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"H2020\"].get(\"IP\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_ip['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('IP', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # H2020 - Final Payments (FP)\n",
    "    current_fp = h2020_current.get('FP', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Final Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_fp['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"H2020\"].get(\"FP\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_fp['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"H2020\"].get(\"FP\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_fp['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('FP', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # H2020 - Experts Payments (EXPERTS)\n",
    "    current_exp = h2020_current.get('EXPERTS', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Experts Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_exp['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"H2020\"].get(\"Experts\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_exp['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"H2020\"].get(\"Experts\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_exp['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('Experts', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # H2020 - Overall\n",
    "    current_h2020 = h2020_current.get('overall', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'H2020',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_h2020['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"H2020\"].get(\"H2020\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_h2020['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"H2020\"].get(\"H2020\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_h2020['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('H2020', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU section\n",
    "    heu_current = current_metrics.get('HEU', {})\n",
    "    \n",
    "    # HEU - Prefinancing Payments (PF)\n",
    "    current_pf = heu_current.get('PF', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Prefinancing Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_pf['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"PF\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_pf['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"PF\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_pf['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('PF', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU - Interim Payments (IP)\n",
    "    current_ip_heu = heu_current.get('IP', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Interim Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_ip_heu['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"IP\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_ip_heu['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"IP\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_ip_heu['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('IP', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU - Final Payments (FP)\n",
    "    current_fp_heu = heu_current.get('FP', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Final Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_fp_heu['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"FP\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_fp_heu['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"FP\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_fp_heu['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('FP', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU - Experts Payment (EXPERTS)\n",
    "    current_exp_heu = heu_current.get('EXPERTS', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Experts Payment',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_exp_heu['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"Experts\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_exp_heu['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"Experts\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_exp_heu['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('Experts', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU - Overall\n",
    "    current_heu = heu_current.get('overall', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'HEU',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_heu['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"HEU\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_heu['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"HEU\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_heu['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('HEU', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # TOTAL row\n",
    "    current_total = current_metrics.get('TOTAL', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'TOTAL',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_total['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"ALL\"].get(\"TOTAL\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_total['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"ALL\"].get(\"TOTAL\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_total['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['ALL'].get('TOTAL', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame(comparison_data)\n",
    "\n",
    "def create_ttp_effectiveness_table(df_paym, cutoff, historical_data, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Create TTP effectiveness and efficiency indicators table\n",
    "    \"\"\"\n",
    "    # Calculate current metrics\n",
    "    current_metrics = calculate_current_ttp_metrics(df_paym, cutoff)\n",
    "    \n",
    "    # Determine labels based on cutoff using get_scope_start_end\n",
    "    quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "    last_valid_date = quarter_dates[1]\n",
    "    current_month = pd.to_datetime(last_valid_date).strftime('%b-%y')\n",
    "    \n",
    "    cutoff_date = pd.to_datetime(cutoff)\n",
    "    current_year = cutoff_date.year\n",
    "    historical_label = f\"Dec-{str(current_year-1)[-2:]}\"\n",
    "    \n",
    "    # Load database parameters for admin and expert meetings\n",
    "    from pathlib import Path\n",
    "    DB_PATH = Path(db_path)\n",
    "    report_params = load_report_params(report_name=report_name, db_path=DB_PATH)\n",
    "    \n",
    "    admin_eff = report_params.get(\"Administrative_expenditure_Effectiveness\", {})\n",
    "    admin_ttp = report_params.get(\"Administrative_expenditure_ttp\", {})\n",
    "    expt_meet_eff = report_params.get(\"Expert_meetings_Effectiveness\", {})\n",
    "    expt_meet_ttp = report_params.get(\"Expert_meetings_ttp\", {})\n",
    "    \n",
    "    # Build effectiveness data\n",
    "    effectiveness_data = []\n",
    "    \n",
    "    # Get current metrics for calculations\n",
    "    h2020_current = current_metrics.get('H2020', {})\n",
    "    heu_current = current_metrics.get('HEU', {})\n",
    "    \n",
    "    # Research grants - Interim Payments - H2020\n",
    "    h2020_ip = h2020_current.get('IP', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Interim Payments - H2020',\n",
    "        current_month: f\"{h2020_ip*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('IP', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 90 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants - Final Payments - H2020\n",
    "    h2020_fp = h2020_current.get('FP', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Final Payments - H2020',\n",
    "        current_month: f\"{h2020_fp*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('FP', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 90 days'\n",
    "    })\n",
    "    \n",
    "    # Experts with Appointment Letters H2020\n",
    "    h2020_exp = h2020_current.get('EXPERTS', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Experts with Appointment Letters H2020',\n",
    "        current_month: f\"{h2020_exp*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('Experts', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 30 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants - Pre-financings HEU\n",
    "    heu_pf = heu_current.get('PF', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Pre-financings HEU',\n",
    "        current_month: f\"{heu_pf*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('PF', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 30 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants - Interim Payments HEU\n",
    "    heu_ip = heu_current.get('IP', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Interim Payments HEU',\n",
    "        current_month: f\"{heu_ip*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('IP', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 90 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants - Final Payments HEU\n",
    "    heu_fp = heu_current.get('FP', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Final Payments HEU',\n",
    "        current_month: f\"{heu_fp*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('FP', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 90 days'\n",
    "    })\n",
    "    \n",
    "    # Administrative expenditure (from database)\n",
    "    admin_current = admin_eff.get(\"Current\", 0)\n",
    "    admin_old = admin_eff.get(\"Old\", 0)\n",
    "    admin_target = admin_eff.get(\"Target\", \"99% in 30 days\")\n",
    "    \n",
    "    # Format admin values - handle both percentage (0.985) and already formatted (98.5%) values\n",
    "    if isinstance(admin_current, (int, float)) and admin_current <= 1:\n",
    "        admin_current_str = f\"{admin_current*100:.2f}%\"\n",
    "    else:\n",
    "        admin_current_str = str(admin_current) if admin_current != \"na\" else \"n/a\"\n",
    "        \n",
    "    if isinstance(admin_old, (int, float)) and admin_old <= 1:\n",
    "        admin_old_str = f\"{admin_old*100:.2f}%\"\n",
    "    else:\n",
    "        admin_old_str = str(admin_old) if admin_old != \"na\" else \"n/a\"\n",
    "    \n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Administrative expenditure',\n",
    "        current_month: admin_current_str,\n",
    "        historical_label: admin_old_str,\n",
    "        'Target': admin_target\n",
    "    })\n",
    "    \n",
    "    # Experts with Appointment Letters HEU\n",
    "    heu_exp = heu_current.get('EXPERTS', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Experts with Appointment Letters HEU',\n",
    "        current_month: f\"{heu_exp*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('Experts', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 30 days'\n",
    "    })\n",
    "    \n",
    "    # Expert meetings PMO (from database)\n",
    "    expt_current = expt_meet_eff.get(\"Current\", \"na\")\n",
    "    expt_old = expt_meet_eff.get(\"Old\", \"na\")\n",
    "    expt_target = expt_meet_eff.get(\"Target\", \"n/a\")\n",
    "    \n",
    "    # Format expert values - handle both percentage and string values\n",
    "    if isinstance(expt_current, (int, float)) and expt_current <= 1:\n",
    "        expt_current_str = f\"{expt_current*100:.2f}%\"\n",
    "    else:\n",
    "        expt_current_str = str(expt_current) if expt_current != \"na\" else \"n/a\"\n",
    "        \n",
    "    if isinstance(expt_old, (int, float)) and expt_old <= 1:\n",
    "        expt_old_str = f\"{expt_old*100:.2f}%\"\n",
    "    else:\n",
    "        expt_old_str = str(expt_old) if expt_old != \"na\" else \"n/a\"\n",
    "    \n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Expert meetings PMO',\n",
    "        current_month: expt_current_str,\n",
    "        historical_label: expt_old_str,\n",
    "        'Target': expt_target\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame(effectiveness_data)\n",
    "\n",
    "\n",
    "\n",
    "def create_ttp_days_table(df_paym, cutoff, historical_data, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Create Time to Pay: Average number of days (H2020 - HEU) table\n",
    "    \"\"\"\n",
    "    # Calculate current metrics\n",
    "    current_metrics = calculate_current_ttp_metrics(df_paym, cutoff)\n",
    "    \n",
    "    # Load database parameters for admin and expert meetings\n",
    "    from pathlib import Path\n",
    "    DB_PATH = Path(db_path)\n",
    "    report_params = load_report_params(report_name=report_name, db_path=DB_PATH)\n",
    "    \n",
    "    admin_eff = report_params.get(\"Administrative_expenditure_Effectiveness\", {})\n",
    "    admin_ttp = report_params.get(\"Administrative_expenditure_ttp\", {})\n",
    "    expt_meet_eff = report_params.get(\"Expert_meetings_Effectiveness\", {})\n",
    "    expt_meet_ttp = report_params.get(\"Expert_meetings_ttp\", {})\n",
    "    \n",
    "    # Build days data\n",
    "    days_data = []\n",
    "    \n",
    "    # Get current metrics for calculations\n",
    "    h2020_current = current_metrics.get('H2020', {})\n",
    "    heu_current = current_metrics.get('HEU', {})\n",
    "    \n",
    "    # Research grants (days) - Interim Payments- H2020\n",
    "    h2020_ip = h2020_current.get('IP', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Interim Payments- H2020',\n",
    "        'NET': round(h2020_ip.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(h2020_ip.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '90 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants (days) - Final Payments- H2020\n",
    "    h2020_fp = h2020_current.get('FP', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Final Payments- H2020',\n",
    "        'NET': round(h2020_fp.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(h2020_fp.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '90 days'\n",
    "    })\n",
    "    \n",
    "    # Experts with Appointment Letters (days) H2020\n",
    "    h2020_exp = h2020_current.get('EXPERTS', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Experts with Appointment Letters (days) H2020',\n",
    "        'NET': round(h2020_exp.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(h2020_exp.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants (days) - Pre-financings - HEU\n",
    "    heu_pf = heu_current.get('PF', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Pre-financings - HEU',\n",
    "        'NET': round(heu_pf.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(heu_pf.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants (days) - Interim Payments- HEU\n",
    "    heu_ip = heu_current.get('IP', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Interim Payments- HEU',\n",
    "        'NET': round(heu_ip.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(heu_ip.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '90 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants (days) - Final Payments- HEU\n",
    "    heu_fp = heu_current.get('FP', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Final Payments- HEU',\n",
    "        'NET': round(heu_fp.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(heu_fp.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '90 days'\n",
    "    })\n",
    "    \n",
    "    # Expert with Appointment Letter (days) HEU\n",
    "    heu_exp = heu_current.get('EXPERTS', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Expert with Appointment Letter (days) HEU',\n",
    "        'NET': round(heu_exp.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(heu_exp.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    # Expert meetings (PMO) (days) - from database\n",
    "    expt_net_current = expt_meet_ttp.get(\"Current\", \"na\")\n",
    "    expt_gross_current = expt_meet_ttp.get(\"Current\", \"na\")  # Assuming same for both NET and GROSS\n",
    "    \n",
    "    # Format expert meeting values\n",
    "    if isinstance(expt_net_current, (int, float)):\n",
    "        expt_net_str = str(round(expt_net_current, 1))\n",
    "        expt_gross_str = str(round(expt_gross_current, 1))\n",
    "    else:\n",
    "        expt_net_str = \"n/a\"\n",
    "        expt_gross_str = \"n/a\"\n",
    "    \n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Expert meetings (PMO) (days)',\n",
    "        'NET': expt_net_str,\n",
    "        'GROSS': expt_gross_str,\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    # Administrative expenditure (days) - from database\n",
    "    admin_net_current = admin_ttp.get(\"Current\", 0)\n",
    "    admin_gross_current = admin_ttp.get(\"Current\", 0)  # Assuming same for both NET and GROSS\n",
    "    \n",
    "    # Format admin values\n",
    "    if isinstance(admin_net_current, (int, float)):\n",
    "        admin_net_str = str(round(admin_net_current, 1))\n",
    "        admin_gross_str = str(round(admin_gross_current, 1))\n",
    "    else:\n",
    "        admin_net_str = \"n/a\"\n",
    "        admin_gross_str = \"n/a\"\n",
    "    \n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Administrative expenditure (days)',\n",
    "        'NET': admin_net_str,\n",
    "        'GROSS': admin_gross_str,\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame(days_data)\n",
    "\n",
    "def generate_all_ttp_tables(df_paym, cutoff, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Generate all three TTP tables - comparison table, effectiveness table, and days table\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    comparison_table, effectiveness_table, days_table = generate_all_ttp_tables(df_paym, cutoff)\n",
    "    \"\"\"\n",
    "    # Load historical data\n",
    "    historical_data = load_historical_ttp_data(report_name=report_name, db_path=db_path)\n",
    "    \n",
    "    # Create all three tables\n",
    "    comparison_table = create_ttp_comparison_table(df_paym, cutoff, historical_data)\n",
    "    effectiveness_table = create_ttp_effectiveness_table(df_paym, cutoff, historical_data, report_name, db_path)\n",
    "    days_table = create_ttp_days_table(df_paym, cutoff, historical_data, report_name, db_path)\n",
    "    \n",
    "    return comparison_table, effectiveness_table, days_table\n",
    "\n",
    "# =============================================================================\n",
    "# UPDATED MAIN FUNCTION - USE THIS IN JUPYTER\n",
    "# =============================================================================\n",
    "\n",
    "def generate_ttp_tables(df_paym, cutoff, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Main function to generate all TTP tables\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    comparison_table, effectiveness_table, days_table = generate_ttp_tables(df_paym, cutoff)\n",
    "    \n",
    "    # Display all three tables\n",
    "    print(\"TTP Comparison Table:\")\n",
    "    display(comparison_table)\n",
    "    \n",
    "    print(\"\\nEffectiveness and Efficiency Indicators:\")\n",
    "    display(effectiveness_table)\n",
    "    \n",
    "    print(\"\\nTime to Pay: Average number of days:\")\n",
    "    display(days_table)\n",
    "    \"\"\"\n",
    "    return generate_all_ttp_tables(df_paym, cutoff, report_name, db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de92fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# USAGE IN JUPYTER NOTEBOOK\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# Use this in your Jupyter notebook:\n",
    "comparison_table, effectiveness_table, ttp_days_table = generate_ttp_tables(df_paym, cutoff)\n",
    "comparison_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3668c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_tables import GT, md, loc, style\n",
    "import pandas as pd\n",
    "\n",
    "def format_table_ttp_summary(df,\n",
    "                            title=\"Time-to-Pay Performance Summary\",\n",
    "                            rowname_col=\"Type of Payments\",\n",
    "                            table_colors=None):\n",
    "    \"\"\"\n",
    "    Format TTP table with 3 spanners: Average Net Time to Pay, Average Gross Time to Pay, Target Paid on Time\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with TTP data\n",
    "        title: Table title\n",
    "        rowname_col: Column name for row names (default: \"Type of Payments\")\n",
    "        table_colors: Dictionary with custom colors\n",
    "    \"\"\"\n",
    "    \n",
    "    # Default colors if not provided\n",
    "    if table_colors is None:\n",
    "        table_colors = {}\n",
    "    \n",
    "    BLUE = table_colors.get(\"BLUE\", \"#004A99\")\n",
    "    LIGHT_BLUE = table_colors.get(\"LIGHT_BLUE\", \"#d6e6f4\")\n",
    "    DARK_BLUE = table_colors.get(\"DARK_BLUE\", \"#01244B\") \n",
    "    SUB_TOTAL_BACKGROUND = table_colors.get(\"subtotal_background_color\", \"#E6E6FA\")\n",
    "    \n",
    "    # Identify columns for each spanner\n",
    "    all_columns = [col for col in df.columns if col != rowname_col]\n",
    "    \n",
    "    # Identify spanner columns based on column names\n",
    "    net_time_cols = [col for col in all_columns if 'Average Net Time to Pay' in col]\n",
    "    gross_time_cols = [col for col in all_columns if 'Average Gross Time to Pay' in col]\n",
    "    target_cols = [col for col in all_columns if 'Target Paid on Time' in col]\n",
    "    \n",
    "    print(f\"📊 Identified columns:\")\n",
    "    print(f\"   Net Time columns: {net_time_cols}\")\n",
    "    print(f\"   Gross Time columns: {gross_time_cols}\")\n",
    "    print(f\"   Target columns: {target_cols}\")\n",
    "    \n",
    "    # Identify second columns for LIGHT_BLUE highlighting\n",
    "    second_columns = []\n",
    "    if len(net_time_cols) > 1:\n",
    "        second_columns.append(net_time_cols[1])\n",
    "    if len(gross_time_cols) > 1:\n",
    "        second_columns.append(gross_time_cols[1])\n",
    "    if len(target_cols) > 1:\n",
    "        second_columns.append(target_cols[1])\n",
    "    \n",
    "    print(f\"🎨 Second columns (LIGHT_BLUE background): {second_columns}\")\n",
    "    \n",
    "    # Fixed width for TTP table (6 data columns + stub)\n",
    "    table_width = \"1200px\"\n",
    "    \n",
    "    # Identify special rows for formatting\n",
    "    h2020_rows = df.index[df[rowname_col].astype(str).str.contains('H2020', case=False, na=False)].tolist()\n",
    "    heu_rows = df.index[df[rowname_col].astype(str).str.contains('HEU', case=False, na=False)].tolist()\n",
    "    total_rows = df.index[df[rowname_col].astype(str).str.contains('TOTAL', case=False, na=False)].tolist()\n",
    "    \n",
    "    # Create and format table with 3 spanners\n",
    "    tbl = (\n",
    "        GT(df, rowname_col=rowname_col)\n",
    "        \n",
    "        # 1. Basic setup\n",
    "        .tab_header(title=md(title))\n",
    "        \n",
    "        # 2. Create the 3 spanners\n",
    "        .tab_spanner(label=\"Average Net Time to Pay (in days)\", columns=net_time_cols)\n",
    "        .tab_spanner(label=\"Average Gross Time to Pay (in days)\", columns=gross_time_cols)\n",
    "        .tab_spanner(label=\"Target Paid on Time - Contractually\", columns=target_cols)\n",
    "        \n",
    "        # 3. Set stub header\n",
    "        .tab_stubhead(label=\"Type of Payments\")\n",
    "        \n",
    "        # 4. Apply theme and basic styling\n",
    "        .opt_stylize(style=5, color='blue')\n",
    "        .opt_table_font(font=\"Arial\")\n",
    "        \n",
    "        # 5. Table options\n",
    "        .tab_options(\n",
    "            table_background_color=\"white\",\n",
    "            heading_background_color=\"white\",\n",
    "            table_font_size='small',\n",
    "            table_font_color=DARK_BLUE,\n",
    "            table_width=table_width,\n",
    "            heading_title_font_size=\"16px\",\n",
    "            heading_title_font_weight=\"bold\",\n",
    "            stub_background_color=LIGHT_BLUE,\n",
    "            row_striping_include_table_body=False,\n",
    "            row_striping_include_stub=False,\n",
    "        )\n",
    "        \n",
    "        # 6. Format time columns (days) as numbers with 1 decimal\n",
    "        .fmt_number(\n",
    "            columns=net_time_cols + gross_time_cols,\n",
    "            decimals=1\n",
    "        )\n",
    "        \n",
    "        # # 7. Format target columns (percentages) \n",
    "        # .fmt_percent(\n",
    "        #     columns=target_cols,\n",
    "        #     decimals=2\n",
    "        # )\n",
    "        \n",
    "   # 8. Style second column of each spanner with LIGHT_BLUE background\n",
    "        .tab_style(\n",
    "            style=[style.fill(color=\"#E3EDF6\"),\n",
    "            style.text(color=DARK_BLUE, weight=\"bold\")],\n",
    "            locations=loc.body(columns=[col for col in [\n",
    "                net_time_cols[1] if len(net_time_cols) > 1 else None,\n",
    "                gross_time_cols[1] if len(gross_time_cols) > 1 else None,\n",
    "                target_cols[1] if len(target_cols) > 1 else None\n",
    "            ] if col is not None])\n",
    "        )\n",
    "        \n",
    "        # 9. Style special rows\n",
    "        .tab_style(\n",
    "            style=[\n",
    "                style.text(color='white', weight=\"bold\"),\n",
    "                style.fill(color=\"#004d80\")\n",
    "            ],\n",
    "            locations=[\n",
    "                loc.body(rows=h2020_rows + heu_rows + total_rows),\n",
    "                loc.stub(rows=h2020_rows + heu_rows + total_rows)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # 10. Style column spanners\n",
    "        .tab_style(\n",
    "            style=[\n",
    "                style.text(color=\"white\", weight=\"bold\"),\n",
    "                style.fill(color=BLUE)\n",
    "            ],\n",
    "            locations=loc.column_labels()\n",
    "        )\n",
    "        \n",
    "        # 11. Center align data columns\n",
    "        .cols_align(\n",
    "            align=\"center\",\n",
    "            columns=all_columns\n",
    "        )\n",
    "        \n",
    "        # 12. Make stub (row names) left-aligned and bold\n",
    "        .tab_style(\n",
    "            style=style.text(weight=\"bold\"),\n",
    "            locations=loc.stub()\n",
    "        )\n",
    "    )\n",
    "   \n",
    "    return tbl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cb3077",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = format_table_ttp_summary(comparison_table,\n",
    "                            title=\"Time-to-Pay Performance Summary\",\n",
    "                            rowname_col=\"Type of Payments\",\n",
    "                            table_colors=table_colors)\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1776247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "effectiveness_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64016b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttp_days_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41432c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_tables_ttp_overview(df,table_colors=None):\n",
    "    \"\"\"\n",
    "    Format TTP table with 3 spanners: Average Net Time to Pay, Average Gross Time to Pay, Target Paid on Time\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with TTP data\n",
    "        title: Table title\n",
    "        rowname_col: Column name for row names (default: \"Type of Payments\")\n",
    "        table_colors: Dictionary with custom colors\n",
    "    \"\"\"\n",
    "    \n",
    "    # Default colors if not provided\n",
    "    if table_colors is None:\n",
    "        table_colors = {}\n",
    "    \n",
    "    BLUE = table_colors.get(\"BLUE\", \"#004A99\")\n",
    "    LIGHT_BLUE = table_colors.get(\"LIGHT_BLUE\", \"#d6e6f4\")\n",
    "    DARK_BLUE = table_colors.get(\"DARK_BLUE\", \"#01244B\") \n",
    "    SUB_TOTAL_BACKGROUND = table_colors.get(\"subtotal_background_color\", \"#E6E6FA\")\n",
    "    \n",
    "    columns_cetered = df.columns[1:].tolist()\n",
    "    # Fixed width for TTP table (6 data columns + stub)\n",
    "    table_width = \"1200px\"\n",
    "    \n",
    "    # Create and format table with 3 spanners\n",
    "    tbl = (\n",
    "        GT(df)\n",
    "        \n",
    "        # 4. Apply theme and basic styling\n",
    "        .opt_stylize(style=5, color='blue')\n",
    "        .opt_table_font(font=\"Arial\")\n",
    "       \n",
    "        # 5. Table options\n",
    "        .tab_options(\n",
    "            table_background_color=\"white\",\n",
    "            heading_background_color=\"white\",\n",
    "            table_font_size='small',\n",
    "            table_font_color=DARK_BLUE,\n",
    "            table_width=table_width,\n",
    "            heading_title_font_size=\"16px\",\n",
    "            heading_title_font_weight=\"bold\",\n",
    "            row_striping_include_table_body=False,\n",
    "            row_striping_include_stub=False,\n",
    "            column_labels_background_color=LIGHT_BLUE,\n",
    "            column_labels_font_weight='bold',\n",
    "        )\n",
    "    \n",
    "\n",
    "         # 11. Center align data columns\n",
    "        .cols_align(\n",
    "            align=\"center\",\n",
    "            columns=columns_cetered \n",
    "        )\n",
    "        \n",
    "    )\n",
    "   \n",
    "    return tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ff8018",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_overview = [\n",
    "    (ttp_days_table, 'Table_overview_ttp'), \n",
    "    (effectiveness_table, 'Table_overview_ttp_effectiveness')\n",
    "]\n",
    "\n",
    "def create_overview_tables(table_data, var_name):\n",
    "  \n",
    "        if table_data is None or (isinstance(table_data, pd.DataFrame) and table_data.empty):\n",
    "            return False, f\"No data available for {var_name}\"\n",
    "        \n",
    "        formatted_table =  format_tables_ttp_overview(table_data, table_colors)\n",
    "      \n",
    "        try:\n",
    "            # Save to database\n",
    "            insert_variable(\n",
    "                report=report,\n",
    "                module=\"OverviewModule\",\n",
    "                var=var_name,\n",
    "                value=table_data.to_dict() if isinstance(table_data, pd.DataFrame) else table_data,\n",
    "                db_path=db_path,\n",
    "                anchor=var_name,\n",
    "                gt_table=formatted_table\n",
    "            )\n",
    "            \n",
    "            return True, f\"Successfully processed {var_name}\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            return False, f\"Error processing {var_name}: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "for table_data, var_name in tables_overview:\n",
    "    create_overview_tables(table_data, var_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b6833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# =============================================================================\n",
    "# TABLE GENERATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_current_ttp_metrics(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Calculate current TTP metrics from df_paym data, filtering out negative v_TTP_NET\n",
    "    \"\"\"\n",
    "    # Filter data up to cutoff and deduplicate by Pay Payment Key\n",
    "    quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "    last_valid_date = quarter_dates[1]\n",
    "\n",
    "    df_filtered = df_paym[\n",
    "        df_paym['Pay Document Date (dd/mm/yyyy)'] <= last_valid_date\n",
    "    ].copy()\n",
    "    df_unique = df_filtered.drop_duplicates(subset=['Pay Payment Key']).copy()\n",
    "    \n",
    "    # Convert to numeric and filter negative v_TTP_NET\n",
    "    df_unique['v_TTP_NET'] = pd.to_numeric(df_unique['v_TTP_NET'], errors='coerce')\n",
    "    df_unique['v_TTP_GROSS'] = pd.to_numeric(df_unique['v_TTP_GROSS'], errors='coerce')\n",
    "    df_unique['v_payment_in_time'] = pd.to_numeric(df_unique['v_payment_in_time'], errors='coerce')\n",
    "    df_unique = df_unique[df_unique['v_TTP_NET'] >= 0]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Calculate by Programme and Payment Type\n",
    "    for programme in ['H2020', 'HEU']:\n",
    "        prog_data = df_unique[df_unique['Programme'] == programme]\n",
    "        if len(prog_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        results[programme] = {}\n",
    "        \n",
    "        # Overall programme metrics\n",
    "        prog_valid = prog_data[prog_data['v_payment_in_time'].notna()]\n",
    "        results[programme]['overall'] = {\n",
    "            'avg_ttp_net': prog_data['v_TTP_NET'].mean(),\n",
    "            'avg_ttp_gross': prog_data['v_TTP_GROSS'].mean(),\n",
    "            'on_time_pct': prog_data['v_payment_in_time'].sum() / len(prog_valid) if len(prog_valid) > 0 else 0\n",
    "        }\n",
    "        \n",
    "        # By payment type - using correct short form values from v_payment_type\n",
    "        payment_types = ['IP', 'FP', 'EXPERTS', 'PF']  # Short form values\n",
    "        for payment_type in payment_types:\n",
    "            pt_data = prog_data[prog_data['v_payment_type'] == payment_type]\n",
    "            if len(pt_data) > 0:\n",
    "                pt_valid = pt_data[pt_data['v_payment_in_time'].notna()]\n",
    "                results[programme][payment_type] = {\n",
    "                    'avg_ttp_net': pt_data['v_TTP_NET'].mean(),\n",
    "                    'avg_ttp_gross': pt_data['v_TTP_GROSS'].mean(),\n",
    "                    'on_time_pct': pt_data['v_payment_in_time'].sum() / len(pt_valid) if len(pt_valid) > 0 else 0\n",
    "                }\n",
    "    \n",
    "    # Overall total\n",
    "    total_valid = df_unique[df_unique['v_payment_in_time'].notna()]\n",
    "    results['TOTAL'] = {\n",
    "        'avg_ttp_net': df_unique['v_TTP_NET'].mean(),\n",
    "        'avg_ttp_gross': df_unique['v_TTP_GROSS'].mean(),\n",
    "        'on_time_pct': df_unique['v_payment_in_time'].sum() / len(total_valid) if len(total_valid) > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "def create_quarterly_ttp_table(df_paym, cutoff, programme, payment_type):\n",
    "    \"\"\"\n",
    "    Create a quarterly TTP table for a specific programme and payment type\n",
    "    Returns table, programme, payment_type, and a flag indicating if the table is empty\n",
    "    \"\"\"\n",
    "    # Use same logic as calculate_current_ttp_metrics\n",
    "    quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "    last_valid_date = quarter_dates[1]\n",
    "\n",
    "    # Filter data up to cutoff and deduplicate by Pay Payment Key (same as comparison table)\n",
    "    df_filtered = df_paym[\n",
    "        df_paym['Pay Document Date (dd/mm/yyyy)'] <= last_valid_date\n",
    "    ].copy()\n",
    "    df_unique = df_filtered.drop_duplicates(subset=['Pay Payment Key']).copy()\n",
    "    \n",
    "    # Convert to numeric and filter negative v_TTP_NET (same as comparison table)\n",
    "    df_unique['v_TTP_NET'] = pd.to_numeric(df_unique['v_TTP_NET'], errors='coerce')\n",
    "    df_unique['v_TTP_GROSS'] = pd.to_numeric(df_unique['v_TTP_GROSS'], errors='coerce')\n",
    "    df_unique['v_payment_in_time'] = pd.to_numeric(df_unique['v_payment_in_time'], errors='coerce')\n",
    "    df_unique = df_unique[df_unique['v_TTP_NET'] >= 0]\n",
    "    \n",
    "    # Now filter by programme and payment type (same as comparison table order)\n",
    "    df_filtered = df_unique[\n",
    "        (df_unique['Programme'] == programme) &\n",
    "        (df_unique['v_payment_type'] == payment_type)\n",
    "    ].copy()\n",
    "    \n",
    "    # If no data after filtering, return an empty table with a flag\n",
    "    if df_filtered.empty:\n",
    "        empty_table = pd.DataFrame(columns=['Quarter', 'ADG', 'COG', 'POC', 'STG', 'SYG', 'Total'])\n",
    "        return empty_table, programme, payment_type, True\n",
    "    \n",
    "    # Extract quarter from date\n",
    "    df_filtered['Quarter'] = pd.to_datetime(df_filtered['Pay Document Date (dd/mm/yyyy)']).dt.to_period('Q').astype(str)\n",
    "    \n",
    "    # Use call_type as CallType (based on logs)\n",
    "    if 'call_type' not in df_filtered.columns:\n",
    "        df_filtered['call_type'] = 'Default'  # Placeholder if call_type is missing\n",
    "    df_filtered['CallType'] = df_filtered['call_type']\n",
    "    \n",
    "    # Aggregate by Quarter and CallType (using v_TTP_NET mean as metric)\n",
    "    quarterly_data = df_filtered.groupby(['Quarter', 'CallType']).agg({\n",
    "        'v_TTP_NET': 'mean'\n",
    "    }).round(1).unstack(fill_value=0)\n",
    "    \n",
    "    # Rename columns to match call types from logs (ADG, COG, etc.)\n",
    "    quarterly_data.columns = [f'{col[1]}' for col in quarterly_data.columns]\n",
    "    \n",
    "    # Add Total column (average across call types for each quarter)\n",
    "    quarterly_data['Total'] = quarterly_data.mean(axis=1).round(1)\n",
    "    \n",
    "    # Calculate total row from original data (to match comparison table calculation)\n",
    "    total_by_calltype = df_filtered.groupby('CallType')['v_TTP_NET'].mean().round(1)\n",
    "    overall_total = df_filtered['v_TTP_NET'].mean().round(1)\n",
    "    \n",
    "    # Create total row with proper structure matching quarterly_data columns\n",
    "    total_row = pd.Series(index=quarterly_data.columns, dtype=float)\n",
    "    for col in quarterly_data.columns:\n",
    "        if col == 'Total':\n",
    "            total_row[col] = overall_total\n",
    "        elif col in total_by_calltype.index:\n",
    "            total_row[col] = total_by_calltype[col]\n",
    "        else:\n",
    "            total_row[col] = 0.0\n",
    "    total_row.name = 'Total'\n",
    "    \n",
    "    quarterly_table = pd.concat([quarterly_data, total_row.to_frame().T])\n",
    "    \n",
    "    # Simplify index to only include Quarter\n",
    "    quarterly_table.index = quarterly_table.index.droplevel([1, 2]) if isinstance(quarterly_table.index, pd.MultiIndex) else quarterly_table.index\n",
    "    \n",
    "    return quarterly_table, programme, payment_type, False\n",
    "\n",
    "def generate_quarterly_tables(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Generate quarterly TTP tables for each programme and payment type\n",
    "    Includes a flag to indicate empty tables\n",
    "    \"\"\"\n",
    "    tables = {}\n",
    "    payment_types = ['IP', 'FP', 'EXPERTS', 'PF']  # Short form values\n",
    "    programs = ['H2020', 'HEU']\n",
    "\n",
    "    for prog in programs:\n",
    "        for pt in payment_types:\n",
    "            table, program, payment_type, is_empty = create_quarterly_ttp_table(df_paym, cutoff, prog, pt)\n",
    "            tables[f'{prog}_{pt}_table'] = {\n",
    "                'table': table,\n",
    "                'programme': program,\n",
    "                'payment_type': payment_type,\n",
    "                'is_empty': is_empty\n",
    "            }\n",
    "\n",
    "    return tables\n",
    "\n",
    "\n",
    "def format_tables_ttp_main(df,table_colors=None,table_title='nothing', table_subtitle='nothing'):\n",
    "    \"\"\"\n",
    "    Format TTP table with 3 spanners: Average Net Time to Pay, Average Gross Time to Pay, Target Paid on Time\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with TTP data\n",
    "        title: Table title\n",
    "        rowname_col: Column name for row names (default: \"Type of Payments\")\n",
    "        table_colors: Dictionary with custom colors\n",
    "    \"\"\"\n",
    "    \n",
    "    # Default colors if not provided\n",
    "    if table_colors is None:\n",
    "        table_colors = {}\n",
    "    \n",
    "    BLUE = table_colors.get(\"BLUE\", \"#004A99\")\n",
    "    LIGHT_BLUE = table_colors.get(\"LIGHT_BLUE\", \"#d6e6f4\")\n",
    "    DARK_BLUE = table_colors.get(\"DARK_BLUE\", \"#01244B\") \n",
    "    SUB_TOTAL_BACKGROUND = table_colors.get(\"subtotal_background_color\", \"#E6E6FA\")\n",
    "    \n",
    "    # Dynamic width calculation\n",
    "    ttp_columns = df.columns[1:].to_list()\n",
    "    num_data_columns = len(ttp_columns)\n",
    "    base_width_per_column = 40  # pixels per column\n",
    "    stub_width = 200  # width for the first column (Quarter)\n",
    "    \n",
    "    table_width = f\"{stub_width + (num_data_columns * base_width_per_column)}px\"\n",
    "    \n",
    "    total_rows = df.index[df['Quarter'].astype(str).str.contains('Total', case=False, na=False)].tolist()\n",
    "    ttp_columns = df.columns[1:].to_list()\n",
    "    \n",
    "    # Create and format table with 3 spanners\n",
    "    tbl = (\n",
    "        GT(df)\n",
    "        \n",
    "        # 4. Apply theme and basic styling\n",
    "        .opt_stylize(style=5, color='blue')\n",
    "        .opt_table_font(font=\"Arial\")\n",
    "\n",
    "        .tab_header(\n",
    "                title =  table_title,\n",
    "                subtitle = table_subtitle\n",
    "            )\n",
    "        \n",
    "        \n",
    "        # 5. Table options\n",
    "        .tab_options(\n",
    "            table_background_color=\"white\",\n",
    "            heading_background_color=\"white\",\n",
    "            table_font_size='small',\n",
    "            table_font_color=DARK_BLUE,\n",
    "            table_width=table_width,\n",
    "            heading_title_font_size=\"12px\",\n",
    "            heading_subtitle_font_size=\"10px\",\n",
    "            heading_title_font_weight=\"bold\",\n",
    "            row_striping_include_table_body=False,\n",
    "            row_striping_include_stub=False\n",
    "        )\n",
    "         \n",
    "        #Format target columns (percentages) \n",
    "        .fmt_number(\n",
    "            columns=ttp_columns,\n",
    "            decimals=1\n",
    "        )\n",
    "        \n",
    "        .tab_style(\n",
    "            style=[\n",
    "                style.text(color='white', weight=\"bold\"),\n",
    "                style.fill(color=\"#004d80\")\n",
    "            ],\n",
    "            locations=[\n",
    "                loc.body(rows=total_rows),\n",
    "                loc.stub(rows=total_rows)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    )\n",
    "   \n",
    "    return tbl\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN USAGE FOR TABLES\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def main_tables(df_paym, cutoff, report=None, db_path=None, table_colors=None):\n",
    "    \"\"\"\n",
    "    Main function with GT table saving options to prevent infinite loops\n",
    "    \"\"\"\n",
    "    print(f\"DEBUG: report = {report}\")\n",
    "    print(f\"DEBUG: db_path = {db_path}\")\n",
    "    \n",
    "    # Generate tables\n",
    "    quarterly_tables = generate_quarterly_tables(df_paym, cutoff)\n",
    "    \n",
    "    # Track results\n",
    "    results = []\n",
    "    successful_tables = {}\n",
    "    \n",
    "    # Process each table\n",
    "    for key, data in quarterly_tables.items():\n",
    "        table_data = data['table']\n",
    "        program = data['programme']\n",
    "        payment_type = data['payment_type']\n",
    "        is_empty = data['is_empty']\n",
    "        \n",
    "        var_name = f'Table_ttp_{program}_{payment_type}'\n",
    "        \n",
    "        # Skip empty tables\n",
    "        if table_data is None or (isinstance(table_data, pd.DataFrame) and table_data.empty) or is_empty:\n",
    "            results.append((False, f\"No data available for {var_name}\"))\n",
    "            print(f\"Skipping {var_name}: No data available\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Reset index to create Quarter column\n",
    "            table_data_copy = table_data.copy()\n",
    "            table_data_copy.reset_index(inplace=True, names='Quarter')\n",
    "\n",
    "            if payment_type == 'IP':\n",
    "                table_title = 'Interim Payments – Time to Pay'\n",
    "            elif payment_type =='FP':\n",
    "                 table_title = 'Final Payments – Time to Pay'\n",
    "            elif payment_type =='PF':\n",
    "                 table_title = 'Pre-Finncing Payments – Time to Pay'\n",
    "            elif payment_type == 'EXPERTS' :\n",
    "                 table_title = 'Experts Payments and Support Activities – Time to Pay'\n",
    "            \n",
    "            # Format table\n",
    "            formatted_table = format_tables_ttp_main(table_data_copy, table_colors, table_title=program, table_subtitle=table_title)\n",
    "            \n",
    "            # Store successful table\n",
    "            successful_tables[key] = {\n",
    "                'table': table_data_copy,\n",
    "                'formatted_table': formatted_table,\n",
    "                'programme': program,\n",
    "                'payment_type': payment_type\n",
    "            }\n",
    "            \n",
    "            report = 'Quarterly_Report'\n",
    "            db_path = \"database/reporting.db\"\n",
    "            \n",
    "            # Save to database with simple GT save for TTP tables\n",
    "            if report and db_path:\n",
    "                print(f\"Saving {var_name} with simple GT save...\")\n",
    "                \n",
    "                # Use simple GT save to avoid infinite loops\n",
    "                insert_variable(\n",
    "                    report=report,\n",
    "                    module=\"PaymentsModule\",\n",
    "                    var=var_name,\n",
    "                    value=table_data_copy.to_dict() if isinstance(table_data_copy, pd.DataFrame) else table_data_copy,\n",
    "                    db_path=db_path,\n",
    "                    anchor=var_name,\n",
    "                    gt_table=formatted_table,\n",
    "                    simple_gt_save=True  # ← KEY: Use simple save instead of complex retry logic\n",
    "                )\n",
    "                results.append((True, f\"Successfully processed and saved {var_name}\"))\n",
    "                print(f\"✓ Successfully processed and saved {var_name}\")\n",
    "            else:\n",
    "                results.append((True, f\"Successfully processed {var_name} (not saved - missing db params)\"))\n",
    "                print(f\"✓ Successfully processed {var_name} (not saved to DB)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            results.append((False, f\"Error processing {var_name}: {str(e)}\"))\n",
    "            print(f\"✗ Error processing {var_name}: {str(e)}\")\n",
    "    \n",
    "    # Print summary\n",
    "    successful_count = sum(1 for success, _ in results if success)\n",
    "    total_count = len(results)\n",
    "    print(f\"\\nSummary: {successful_count}/{total_count} tables processed successfully\")\n",
    "    \n",
    "    return quarterly_tables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b359d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example usage (uncomment to run)\n",
    "quarterly_tables = main_tables(df_paym, cutoff, report='Quartlry_Report', db_path=db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import time\n",
    "import warnings\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "\n",
    "# Suppress the Altair FutureWarning about convert_dtype\n",
    "warnings.filterwarnings(\"ignore\", message=\".*convert_dtype.*\", category=FutureWarning)\n",
    "\n",
    "def rolling_ttp(df,programme,typeofpayment):\n",
    "    \n",
    "        start, end  = get_scope_start_end(cutoff)\n",
    "        last_month = int(end.month)\n",
    "        i = 1\n",
    "        moving_avg_ttp = []\n",
    "        months = []\n",
    "\n",
    "        quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "        last_valid_date = quarter_dates[1]\n",
    "\n",
    "        df_filtered = df[\n",
    "                df['Pay Document Date (dd/mm/yyyy)'] <= last_valid_date\n",
    "        ].copy()\n",
    "        df_unique = df_filtered.drop_duplicates(subset=['Pay Payment Key']).copy()\n",
    "        \n",
    "        # Convert to numeric and filter negative v_TTP_NET\n",
    "        df_unique['v_TTP_NET'] = pd.to_numeric(df_unique['v_TTP_NET'], errors='coerce')\n",
    "        df_unique['v_TTP_GROSS'] = pd.to_numeric(df_unique['v_TTP_GROSS'], errors='coerce')\n",
    "        df_unique['v_payment_in_time'] = pd.to_numeric(df_unique['v_payment_in_time'], errors='coerce')\n",
    "        df_unique = df_unique[df_unique['v_TTP_NET'] >= 0]\n",
    "\n",
    "        while i <= last_month : \n",
    "                df_test =  df_unique.loc[( df_unique['Programme'] == programme) & ( df_unique['v_payment_type'] == typeofpayment) & ( df_unique['Month']<= i )]    \n",
    "                mean = round(df_test['TTP_NET'].mean(),1)\n",
    "                moving_avg_ttp.insert(i,mean)\n",
    "                months.insert(i,i)\n",
    "                i+=1\n",
    "\n",
    "        d = {'Month': months, 'TTP': moving_avg_ttp}\n",
    "        df_mov_ttp = pd.DataFrame(data=d)\n",
    "        return df_mov_ttp \n",
    "\n",
    "def avg_ttp(df,programme,typeofpayment):\n",
    "    \n",
    "        start, end  = get_scope_start_end(cutoff)\n",
    "        last_month = int(end.month)\n",
    "        i = 1\n",
    "        moving_avg_ttp = []\n",
    "        months = []\n",
    "\n",
    "        quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "        last_valid_date = quarter_dates[1]\n",
    "\n",
    "        df_filtered = df[\n",
    "                df['Pay Document Date (dd/mm/yyyy)'] <= last_valid_date\n",
    "        ].copy()\n",
    "        df_unique = df_filtered.drop_duplicates(subset=['Pay Payment Key']).copy()\n",
    "        \n",
    "        # Convert to numeric and filter negative v_TTP_NET\n",
    "        df_unique['v_TTP_NET'] = pd.to_numeric(df_unique['v_TTP_NET'], errors='coerce')\n",
    "        df_unique['v_TTP_GROSS'] = pd.to_numeric(df_unique['v_TTP_GROSS'], errors='coerce')\n",
    "        df_unique['v_payment_in_time'] = pd.to_numeric(df_unique['v_payment_in_time'], errors='coerce')\n",
    "        df_unique = df_unique[df_unique['v_TTP_NET'] >= 0]\n",
    "\n",
    "        pivot_ttp_month =  df_unique.pivot_table( index= df_unique[[\"Month\"]], values= df_unique[['TTP_NET']],fill_value=0,aggfunc='mean')\n",
    "        pivot_ttp_month['TTP_NET'] = pivot_ttp_month['TTP_NET'].round(1)\n",
    "        #pivot_ttp_month.columns =  pivot_ttp_month.columns.droplevel()\n",
    "        pivot_ttp_month.reset_index(inplace = True)\n",
    "\n",
    "        return pivot_ttp_month\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CHART GENERATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def chart_machine_ttp(df, paymentType, prog, avg, rollingAvg):\n",
    "    \"\"\"Clean version with all positioning and styling issues fixed\"\"\"\n",
    "    \n",
    "    # Time limits\n",
    "    time_limits = {\n",
    "        'PF': 30, 'EXPERTS': 30, 'IP': 90, 'FP': 90\n",
    "    }\n",
    "    time_limit = time_limits.get(paymentType, 90)\n",
    "    \n",
    "    # Clean data\n",
    "    df_clean = df.copy()\n",
    "    df_clean['Month'] = pd.to_numeric(df_clean['Month'], errors='coerce')\n",
    "    df_clean['TTP_NET'] = pd.to_numeric(df_clean['TTP_NET'], errors='coerce')\n",
    "    df_clean = df_clean.dropna(subset=['Month', 'TTP_NET'])\n",
    "    \n",
    "    rollingAvg_clean = rollingAvg.copy()\n",
    "    rollingAvg_clean['Month'] = pd.to_numeric(rollingAvg_clean['Month'], errors='coerce')\n",
    "    rollingAvg_clean['TTP'] = pd.to_numeric(rollingAvg_clean['TTP'], errors='coerce')\n",
    "    rollingAvg_clean = rollingAvg_clean.dropna()\n",
    "    \n",
    "    if df_clean.empty:\n",
    "        return alt.Chart().mark_text(text=\"No data available\")\n",
    "    \n",
    "    # Calculate Y-axis range - extend if values are close to limits\n",
    "    max_value = max(\n",
    "        df_clean['TTP_NET'].max() if not df_clean.empty else 0,\n",
    "        rollingAvg_clean['TTP'].max() if not rollingAvg_clean.empty else 0,\n",
    "        time_limit\n",
    "    )\n",
    "    \n",
    "    # Extend Y-axis if monthly average is close to time limit (within 10 days)\n",
    "    if abs(avg - time_limit) <= 10:\n",
    "        y_max = max_value * 1.2  # Extend by 20%\n",
    "    else:\n",
    "        y_max = max_value * 1.1  # Normal 10% extension\n",
    "    \n",
    "    # Get last month with data for triangle positioning\n",
    "    last_month_with_data = df_clean['Month'].max() if not df_clean.empty else 1\n",
    "    start, end = get_scope_start_end(cutoff)\n",
    "    year = int(end.year)\n",
    "    \n",
    "    # Get rolling average value for triangle positioning - position exactly on the line\n",
    "    last_rolling_value = rollingAvg_clean[\n",
    "        rollingAvg_clean['Month'] == last_month_with_data\n",
    "    ]['TTP'].values\n",
    "    triangle_y_pos = last_rolling_value[0] if len(last_rolling_value) > 0 else avg\n",
    "    \n",
    "    # Create triangle annotation data positioned on the rolling average line\n",
    "    triangle_data = pd.DataFrame({\n",
    "        'Month': [last_month_with_data],\n",
    "        'TTP': [triangle_y_pos],  # Exact position on rolling average line\n",
    "        'Triangle': ['⯆'],  # Down-pointing arrow\n",
    "        'Comment': [f'{prog} Average {year} = {avg}']\n",
    "    })\n",
    "    \n",
    "    # Main bars with darker color for better label visibility\n",
    "    bars = alt.Chart(df_clean).mark_bar(\n",
    "        opacity=0.8,\n",
    "        color='#4682B4'  # Darker steel blue for better contrast\n",
    "    ).encode(\n",
    "        x=alt.X('Month:O', title='Month'),\n",
    "        y=alt.Y('TTP_NET:Q', title='Days', scale=alt.Scale(domain=[0, y_max]))\n",
    "    )\n",
    "    \n",
    "    # Bar labels with darker color for visibility\n",
    "    bar_labels = bars.mark_text(\n",
    "        dy=-8,\n",
    "        fontSize=11,\n",
    "        fontWeight='bold',\n",
    "        color=\"#0A6BBA\"  # Dark blue for better visibility\n",
    "    ).encode(\n",
    "        text=alt.Text('TTP_NET:Q', format='.1f')\n",
    "    )\n",
    "    \n",
    "    # Rolling average line - keeping red as requested\n",
    "    avg_line = alt.Chart(rollingAvg_clean).mark_line(\n",
    "        color='#DC143C',  # Crimson red\n",
    "        strokeWidth=3,\n",
    "        strokeDash=[5, 5]\n",
    "    ).encode(\n",
    "        x=alt.X('Month:O'),\n",
    "        y=alt.Y('TTP:Q', scale=alt.Scale(domain=[0, y_max]))\n",
    "    )\n",
    "    \n",
    "    # Time limit line - keeping orange\n",
    "    limit_line = alt.Chart(pd.DataFrame({\n",
    "        'Month': list(range(1, 13)),\n",
    "        'limit': [time_limit] * 12\n",
    "    })).mark_line(\n",
    "        color='#FF8C00',  # Dark orange\n",
    "        strokeWidth=2\n",
    "    ).encode(\n",
    "        x=alt.X('Month:O'),\n",
    "        y=alt.Y('limit:Q', scale=alt.Scale(domain=[0, y_max]))\n",
    "    )\n",
    "    \n",
    "    # Triangle positioned next to the rolling average line\n",
    "    triangle = alt.Chart(triangle_data).mark_text(\n",
    "        dx=15,   # Small offset to the right of the data point\n",
    "        dy=-5,   # Slightly above the rolling average line\n",
    "        fontSize=25,  # Bigger arrow\n",
    "        color='orange',\n",
    "        fontWeight='bold'\n",
    "    ).encode(\n",
    "        x=alt.X('Month:O'),\n",
    "        y=alt.Y('TTP:Q', scale=alt.Scale(domain=[0, y_max])),\n",
    "        text='Triangle:N'\n",
    "    )\n",
    "    \n",
    "    # Annotation text positioned above the triangle\n",
    "    annotation = alt.Chart(triangle_data).mark_text(\n",
    "        dx=15,   # Aligned with triangle\n",
    "        dy=-25,  # Above the triangle\n",
    "        fontSize=12,\n",
    "        fontWeight='bold',\n",
    "        color='#1B5390',\n",
    "        align='left'\n",
    "    ).encode(\n",
    "        x=alt.X('Month:O'),\n",
    "        y=alt.Y('TTP:Q', scale=alt.Scale(domain=[0, y_max])),\n",
    "        text='Comment:N'\n",
    "    )\n",
    "    \n",
    "    # Create unified legend data\n",
    "    legend_data = pd.DataFrame({\n",
    "        'Legend': ['Monthly Values', 'Rolling Average', 'Contractual Limit'],\n",
    "        'Month': [1, 1, 1],  # Dummy values for positioning\n",
    "        'Value': [0, 0, 0],   # Dummy values\n",
    "        'Color': ['#4682B4', '#DC143C', '#FF8C00']\n",
    "    })\n",
    "    \n",
    "    # Create legend as separate marks\n",
    "    legend_bars = alt.Chart(legend_data).mark_rect(\n",
    "        width=15,\n",
    "        height=15\n",
    "    ).encode(\n",
    "        x=alt.X('Legend:N', title=None, axis=alt.Axis(labelAngle=0)),\n",
    "        color=alt.Color('Color:N', scale=None, legend=None)\n",
    "    ).properties(\n",
    "        width=400,\n",
    "        height=30\n",
    "    ).resolve_scale(color='independent')\n",
    "    \n",
    "    # Main chart\n",
    "    main_chart = (bars + bar_labels + avg_line + limit_line + triangle + annotation).properties(\n",
    "        width=600,\n",
    "        height=300,\n",
    "        title=alt.TitleParams(\n",
    "            text=f'{prog} {paymentType} - Time to Pay Analysis',\n",
    "            fontSize=16,\n",
    "            fontWeight='bold',\n",
    "            anchor='start',\n",
    "            color='#1B5390'\n",
    "        )\n",
    "    ).resolve_scale(\n",
    "        color='independent'\n",
    "    )\n",
    "    \n",
    "    # Combine main chart with legend\n",
    "    final_chart = alt.vconcat(\n",
    "        main_chart,\n",
    "        legend_bars\n",
    "    ).resolve_scale(\n",
    "        color='independent'\n",
    "    )\n",
    "    \n",
    "    return final_chart\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL GENERATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def generate_charts(df_paym, cutoff, quarterly_tables):\n",
    "    \"\"\"\n",
    "    Generate TTP charts for each programme and payment type, skipping empty tables\n",
    "    \"\"\"\n",
    "    charts = {}\n",
    "    payment_types = ['IP', 'FP', 'EXPERTS', 'PF']  # Short form values\n",
    "    programs = ['H2020', 'HEU']\n",
    "\n",
    "    for prog in programs:\n",
    "        for pt in payment_types:\n",
    "            table_key = f'{prog}_{pt}_table'\n",
    "            # Skip chart generation if the corresponding table is empty\n",
    "            if quarterly_tables[table_key]['is_empty']:\n",
    "                print(f\"Skipping chart for {table_key} (empty table)\")\n",
    "                continue\n",
    "\n",
    "            # Prepare data for chart\n",
    "            df_chart = df_paym[\n",
    "                (df_paym['Programme'] == prog) &\n",
    "                (df_paym['v_payment_type'] == pt)\n",
    "            ].copy()\n",
    "            df_chart['Month'] = pd.to_datetime(df_chart['Pay Document Date (dd/mm/yyyy)']).dt.month\n",
    "            df_chart['TTP_NET'] = pd.to_numeric(df_chart['v_TTP_NET'], errors='coerce')\n",
    "            df_chart = df_chart[df_chart['TTP_NET'] >= 0]\n",
    "\n",
    "            # If df_chart is empty, this should be caught by the table check above, but confirm\n",
    "            if df_chart.empty:\n",
    "                print(f\"Data for chart {table_key} is empty, but table flag not set correctly\")\n",
    "                continue\n",
    "\n",
    "            # Calculate average for this combination\n",
    "            current_metrics = calculate_current_ttp_metrics(df_chart, cutoff)\n",
    "            avg_ttp_net = round(float(current_metrics[prog][pt]['avg_ttp_net']),1)if pt in current_metrics[prog] else 0\n",
    "            rolling_avg = rolling_ttp(df_chart, prog, pt)\n",
    "\n",
    "            df_ttp = avg_ttp(df_chart, prog, pt)\n",
    "\n",
    "            # Generate chart\n",
    "            chart = chart_machine_ttp(df_ttp, pt, prog, avg_ttp_net, rolling_avg)\n",
    "            logger.debug(f\"Generated tta_chart_img for {prog, '{prog}_{pt}_chart'}\")\n",
    "            \n",
    "            var_name = f'{prog}_{pt}_ttp_chart'\n",
    "            try:\n",
    "                logger.debug(f\"Saving {var_name} to database\")\n",
    "                insert_variable(\n",
    "                    report=report, module=\"PaymentsModule\", var=var_name,\n",
    "                    value=df_ttp,\n",
    "                    db_path=db_path, anchor=var_name, altair_chart=chart\n",
    "                )\n",
    "                logger.debug(f\"Saved {var_name} to database\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to save {var_name}: {str(e)}\")\n",
    "\n",
    "            charts[f'{prog}_{pt}_chart'] = chart\n",
    "            \n",
    "\n",
    "    return charts\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN USAGE FOR CHARTS\n",
    "# =============================================================================\n",
    "\n",
    "def main_charts(df_paym, cutoff, quarterly_tables):\n",
    "    \"\"\"\n",
    "    Main function to generate and display TTP charts, skipping empty tables\n",
    "    \"\"\"\n",
    "    # Generate charts\n",
    "    ttp_charts = generate_charts(df_paym, cutoff, quarterly_tables)\n",
    "    \n",
    "    # Display charts (in Jupyter Notebook)\n",
    "    for key, chart in ttp_charts.items():\n",
    "        print(f\"\\n{key}:\")\n",
    "        display(chart)\n",
    "    \n",
    "    return ttp_charts\n",
    "\n",
    "# Example usage (uncomment to run after generating tables)\n",
    "# ttp_charts = main_charts(df_paym, cutoff, quarterly_tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893d6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttp_charts = main_charts(df_paym, cutoff, quarterly_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc09283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_effectiveness_breakdown(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Create effectiveness breakdown tables by directorate and payment type\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter data up to cutoff and deduplicate by Pay Payment Key\n",
    "    quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "    last_valid_date = quarter_dates[1]\n",
    "\n",
    "    df_filtered = df_paym[\n",
    "        df_paym['Pay Document Date (dd/mm/yyyy)'] <= last_valid_date\n",
    "    ].copy()\n",
    "    df_unique = df_filtered.drop_duplicates(subset=['Pay Payment Key']).copy()\n",
    "    \n",
    "    # Convert to numeric\n",
    "    df_unique['v_TTP_NET'] = pd.to_numeric(df_unique['v_TTP_NET'], errors='coerce')\n",
    "    df_unique['v_TTP_GROSS'] = pd.to_numeric(df_unique['v_TTP_GROSS'], errors='coerce')\n",
    "    df_unique['v_payment_in_time'] = pd.to_numeric(df_unique['v_payment_in_time'], errors='coerce')\n",
    "    \n",
    "    # Filter out negative TTP_NET values\n",
    "    df_unique = df_unique[df_unique['v_TTP_NET'] >= 0]\n",
    "    \n",
    "    # Determine year label from cutoff\n",
    "    cutoff_date = pd.to_datetime(cutoff)\n",
    "    current_year = cutoff_date.year\n",
    "    year_label = f\"{current_year} - YTD\"\n",
    "    \n",
    "    return df_unique, year_label\n",
    "\n",
    "def create_quarterly_ttp_breakdown(df_paym, cutoff, metric_type='NET'):\n",
    "    \"\"\"\n",
    "    Create quarterly TTP breakdown tables by directorate and payment type\n",
    "    \n",
    "    Parameters:\n",
    "    - df_paym: Payment data DataFrame\n",
    "    - cutoff: Cutoff date for analysis\n",
    "    - metric_type: 'NET' or 'GROSS' for which TTP metric to use\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter data up to cutoff and deduplicate by Pay Payment Key\n",
    "    quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "    last_valid_date = quarter_dates[1]\n",
    "\n",
    "    df_filtered = df_paym[\n",
    "        df_paym['Pay Document Date (dd/mm/yyyy)'] <= last_valid_date\n",
    "    ].copy()\n",
    "    df_unique = df_filtered.drop_duplicates(subset=['Pay Payment Key']).copy()\n",
    "    \n",
    "    # Convert to numeric\n",
    "    df_unique['v_TTP_NET'] = pd.to_numeric(df_unique['v_TTP_NET'], errors='coerce')\n",
    "    df_unique['v_TTP_GROSS'] = pd.to_numeric(df_unique['v_TTP_GROSS'], errors='coerce')\n",
    "    df_unique['v_payment_in_time'] = pd.to_numeric(df_unique['v_payment_in_time'], errors='coerce')\n",
    "    \n",
    "    # Filter out negative TTP_NET values\n",
    "    df_unique = df_unique[df_unique['v_TTP_NET'] >= 0]\n",
    "    \n",
    "    # Extract quarter from date\n",
    "    df_unique['Quarter'] = pd.to_datetime(df_unique['Pay Document Date (dd/mm/yyyy)']).dt.to_period('Q')\n",
    "    \n",
    "    # Create quarter labels (e.g., 2024Q1, 2024Q2, etc.)\n",
    "    df_unique['Quarter_Label'] = df_unique['Quarter'].astype(str)\n",
    "    \n",
    "    # Get unique quarters and sort them\n",
    "    quarters = sorted(df_unique['Quarter_Label'].unique())\n",
    "    \n",
    "    return quarters, df_unique\n",
    "\n",
    "def create_h2020_quarterly_table(df_paym, cutoff, metric_type='NET'):\n",
    "    \"\"\"\n",
    "    Create H2020 quarterly breakdown table with MultiIndex columns\n",
    "    \"\"\"\n",
    "    quarters, df_unique = create_quarterly_ttp_breakdown(df_paym, cutoff, metric_type)\n",
    "    \n",
    "    # Filter for H2020\n",
    "    h2020_data = df_unique[df_unique['Programme'] == 'H2020'].copy()\n",
    "    \n",
    "    # Get actual directorates from the data\n",
    "    available_directorates = sorted([d for d in h2020_data['call_type'].unique() if pd.notna(d)])\n",
    "    \n",
    "    # Define payment types based on the image structure\n",
    "    payment_types_h2020 = ['FP', 'IP']  # Final Payments and Interim Payments\n",
    "    \n",
    "    # Create MultiIndex columns structure\n",
    "    columns = []\n",
    "    \n",
    "    # Add directorate columns\n",
    "    for dir_name in available_directorates:\n",
    "        for pt in payment_types_h2020:\n",
    "            columns.append((dir_name, pt))\n",
    "    \n",
    "    # Add Experts column (single column, no sub-payment types)\n",
    "    columns.append(('Experts', 'Experts'))\n",
    "    \n",
    "    # Add Total column  \n",
    "    columns.append(('Total', 'Total'))\n",
    "    \n",
    "    multi_columns = pd.MultiIndex.from_tuples(columns, names=['Directorate', 'Payment_Type'])\n",
    "    \n",
    "    # Create DataFrame with quarters as index\n",
    "    quarters_with_summary = quarters + ['Dep C.']\n",
    "    quarterly_data = pd.DataFrame(index=quarters_with_summary, columns=multi_columns, dtype=float)\n",
    "    \n",
    "    ttp_column = f'v_TTP_{metric_type}'\n",
    "    \n",
    "    # Fill quarterly data\n",
    "    for quarter in quarters:\n",
    "        quarter_data = h2020_data[h2020_data['Quarter_Label'] == quarter]\n",
    "        \n",
    "        # Fill directorate data\n",
    "        for dir_name in available_directorates:\n",
    "            dir_data = quarter_data[quarter_data['call_type'] == dir_name]\n",
    "            \n",
    "            for pt in payment_types_h2020:\n",
    "                pt_data = dir_data[dir_data['v_payment_type'] == pt]\n",
    "                avg_ttp = pt_data[ttp_column].mean() if len(pt_data) > 0 else 0\n",
    "                quarterly_data.loc[quarter, (dir_name, pt)] = round(avg_ttp, 1) if not pd.isna(avg_ttp) else 0.0\n",
    "        \n",
    "        # Experts\n",
    "        experts_data = quarter_data[quarter_data['v_payment_type'] == 'EXPERTS']\n",
    "        experts_avg = experts_data[ttp_column].mean() if len(experts_data) > 0 else 0\n",
    "        quarterly_data.loc[quarter, ('Experts', 'Experts')] = round(experts_avg, 1) if not pd.isna(experts_avg) else 0.0\n",
    "        \n",
    "        # Total\n",
    "        total_avg = quarter_data[ttp_column].mean() if len(quarter_data) > 0 else 0\n",
    "        quarterly_data.loc[quarter, ('Total', 'Total')] = round(total_avg, 1) if not pd.isna(total_avg) else 0.0\n",
    "    \n",
    "    # Fill Dep C. summary row\n",
    "    for dir_name in available_directorates:\n",
    "        dir_data = h2020_data[h2020_data['call_type'] == dir_name]\n",
    "        \n",
    "        for pt in payment_types_h2020:\n",
    "            pt_data = dir_data[dir_data['v_payment_type'] == pt]\n",
    "            avg_ttp = pt_data[ttp_column].mean() if len(pt_data) > 0 else 0\n",
    "            quarterly_data.loc['Dep C.', (dir_name, pt)] = round(avg_ttp, 1) if not pd.isna(avg_ttp) else 0.0\n",
    "    \n",
    "    # Overall experts and total for Dep C.\n",
    "    experts_overall = h2020_data[h2020_data['v_payment_type'] == 'EXPERTS'][ttp_column].mean()\n",
    "    quarterly_data.loc['Dep C.', ('Experts', 'Experts')] = round(experts_overall, 1) if not pd.isna(experts_overall) else 0.0\n",
    "    \n",
    "    total_overall = h2020_data[ttp_column].mean()\n",
    "    quarterly_data.loc['Dep C.', ('Total', 'Total')] = round(total_overall, 1) if not pd.isna(total_overall) else 0.0\n",
    "    \n",
    "    # Convert to numeric and handle any remaining NaN values\n",
    "    quarterly_data = quarterly_data.fillna(0.0).infer_objects(copy=False).astype(float)\n",
    "    \n",
    "    return quarterly_data\n",
    "\n",
    "def create_heu_quarterly_table(df_paym, cutoff, metric_type='NET'):\n",
    "    \"\"\"\n",
    "    Create HEU quarterly breakdown table with MultiIndex columns\n",
    "    \"\"\"\n",
    "    quarters, df_unique = create_quarterly_ttp_breakdown(df_paym, cutoff, metric_type)\n",
    "    \n",
    "    # Filter for HEU\n",
    "    heu_data = df_unique[df_unique['Programme'] == 'HEU'].copy()\n",
    "    \n",
    "    # Get actual directorates from the data\n",
    "    available_directorates = sorted([d for d in heu_data['call_type'].unique() if pd.notna(d)])\n",
    "    \n",
    "    # Create MultiIndex columns structure based on image\n",
    "    columns = []\n",
    "    \n",
    "    # Based on image: ADG(PF,IP), COG(PF,FP), POC(PF,IP), STG(PF,IP), SYG(PF)\n",
    "    directorate_payment_mapping = {\n",
    "        'ADG': ['PF', 'IP'],\n",
    "        'COG': ['PF', 'FP'], \n",
    "        'POC': ['PF', 'IP'],\n",
    "        'STG': ['PF', 'IP'],\n",
    "        'SYG': ['PF']\n",
    "    }\n",
    "    \n",
    "    # Add columns for available directorates\n",
    "    for dir_name in available_directorates:\n",
    "        if dir_name in directorate_payment_mapping:\n",
    "            for pt in directorate_payment_mapping[dir_name]:\n",
    "                columns.append((dir_name, pt))\n",
    "    \n",
    "    # Add Experts column\n",
    "    columns.append(('Experts', 'Experts'))\n",
    "    \n",
    "    # Add Total column  \n",
    "    columns.append(('Total', 'Total'))\n",
    "    \n",
    "    multi_columns = pd.MultiIndex.from_tuples(columns, names=['Directorate', 'Payment_Type'])\n",
    "    \n",
    "    # Create DataFrame with quarters as index\n",
    "    quarters_with_summary = quarters + ['Dep C.']\n",
    "    quarterly_data = pd.DataFrame(index=quarters_with_summary, columns=multi_columns, dtype=float)\n",
    "\n",
    "    \n",
    "    ttp_column = f'v_TTP_{metric_type}'\n",
    "    \n",
    "    # Fill quarterly data\n",
    "    for quarter in quarters:\n",
    "        quarter_data = heu_data[heu_data['Quarter_Label'] == quarter]\n",
    "        \n",
    "        # Fill directorate data\n",
    "        for dir_name in available_directorates:\n",
    "            if dir_name in directorate_payment_mapping:\n",
    "                dir_data = quarter_data[quarter_data['call_type'] == dir_name]\n",
    "                \n",
    "                for pt in directorate_payment_mapping[dir_name]:\n",
    "                    pt_data = dir_data[dir_data['v_payment_type'] == pt]\n",
    "                    avg_ttp = pt_data[ttp_column].mean() if len(pt_data) > 0 else 0\n",
    "                    quarterly_data.loc[quarter, (dir_name, pt)] = round(avg_ttp, 1) if not pd.isna(avg_ttp) else 0.0\n",
    "        \n",
    "        # Experts\n",
    "        experts_data = quarter_data[quarter_data['v_payment_type'] == 'EXPERTS']\n",
    "        experts_avg = experts_data[ttp_column].mean() if len(experts_data) > 0 else 0\n",
    "        quarterly_data.loc[quarter, ('Experts', 'Experts')] = round(experts_avg, 1) if not pd.isna(experts_avg) else 0.0\n",
    "        \n",
    "        # Total\n",
    "        total_avg = quarter_data[ttp_column].mean() if len(quarter_data) > 0 else 0\n",
    "        quarterly_data.loc[quarter, ('Total', 'Total')] = round(total_avg, 1) if not pd.isna(total_avg) else 0.0\n",
    "    \n",
    "    # Fill Dep C. summary row\n",
    "    for dir_name in available_directorates:\n",
    "        if dir_name in directorate_payment_mapping:\n",
    "            dir_data = heu_data[heu_data['call_type'] == dir_name]\n",
    "            \n",
    "            for pt in directorate_payment_mapping[dir_name]:\n",
    "                pt_data = dir_data[dir_data['v_payment_type'] == pt]\n",
    "                avg_ttp = pt_data[ttp_column].mean() if len(pt_data) > 0 else 0\n",
    "                quarterly_data.loc['Dep C.', (dir_name, pt)] = round(avg_ttp, 1) if not pd.isna(avg_ttp) else 0.0\n",
    "    \n",
    "    # Overall experts and total for Dep C.\n",
    "    experts_overall = heu_data[heu_data['v_payment_type'] == 'EXPERTS'][ttp_column].mean()\n",
    "    quarterly_data.loc['Dep C.', ('Experts', 'Experts')] = round(experts_overall, 1) if not pd.isna(experts_overall) else 0.0\n",
    "    \n",
    "    total_overall = heu_data[ttp_column].mean()\n",
    "    quarterly_data.loc['Dep C.', ('Total', 'Total')] = round(total_overall, 1) if not pd.isna(total_overall) else 0.0\n",
    "    \n",
    "    # Convert to numeric and handle any remaining NaN values\n",
    "    quarterly_data = quarterly_data.fillna(0.0).infer_objects(copy=False).astype(float)\n",
    "    \n",
    "    return quarterly_data\n",
    "\n",
    "def generate_quarterly_breakdown_tables(df_paym, cutoff, metric_type='NET'):\n",
    "    \"\"\"\n",
    "    Generate both H2020 and HEU quarterly breakdown tables with MultiIndex columns\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    h2020_table, heu_table = generate_quarterly_breakdown_tables(df_paym, cutoff, 'NET')\n",
    "    \n",
    "    # Display tables\n",
    "    print(\"H2020 Quarterly Breakdown:\")\n",
    "    display(h2020_table)\n",
    "    \n",
    "    print(\"\\nHEU Quarterly Breakdown:\")\n",
    "    display(heu_table)\n",
    "    \n",
    "    # Access MultiIndex structure:\n",
    "    print(\"HEU columns:\", heu_table.columns.tolist())\n",
    "    print(\"Data for ADG-PF:\", heu_table[('ADG', 'PF')])\n",
    "    \"\"\"\n",
    "    h2020_table = create_h2020_quarterly_table(df_paym, cutoff, metric_type)\n",
    "    heu_table = create_heu_quarterly_table(df_paym, cutoff, metric_type)\n",
    "    \n",
    "    return h2020_table, heu_table\n",
    "\n",
    "def create_h2020_effectiveness_table(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Create H2020 effectiveness breakdown table by directorate\n",
    "    \"\"\"\n",
    "    df_unique, year_label = create_effectiveness_breakdown(df_paym, cutoff)\n",
    "    \n",
    "    # Filter for H2020\n",
    "    h2020_data = df_unique[df_unique['Programme'] == 'H2020'].copy()\n",
    "    \n",
    "    # Get actual directorates from the data\n",
    "    available_directorates = sorted([d for d in h2020_data['call_type'].unique() if pd.notna(d)])\n",
    "    \n",
    "    # Build table data\n",
    "    table_data = []\n",
    "    \n",
    "    # Calculate effectiveness for each directorate\n",
    "    for dir_name in available_directorates:\n",
    "        dir_data = h2020_data[h2020_data['call_type'] == dir_name]\n",
    "        row = {'call_type': dir_name}\n",
    "        \n",
    "        # Final Payments (30 days target)\n",
    "        fp_data = dir_data[dir_data['v_payment_type'] == 'FP']\n",
    "        if len(fp_data) > 0:\n",
    "            fp_valid = fp_data[fp_data['v_payment_in_time'].notna()]\n",
    "            fp_effectiveness = (fp_data['v_payment_in_time'].sum() / len(fp_valid) * 100) if len(fp_valid) > 0 else 0\n",
    "            row[f'Final Payments - The contractual time limit is 30 days {year_label}'] = f\"{fp_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'Final Payments - The contractual time limit is 30 days {year_label}'] = \"-\"\n",
    "        \n",
    "        # Interim Payments (60 days target)\n",
    "        ip_data = dir_data[dir_data['v_payment_type'] == 'IP']\n",
    "        if len(ip_data) > 0:\n",
    "            ip_valid = ip_data[ip_data['v_payment_in_time'].notna()]\n",
    "            ip_effectiveness = (ip_data['v_payment_in_time'].sum() / len(ip_valid) * 100) if len(ip_valid) > 0 else 0\n",
    "            row[f'Interim Payments - The contractual time limit is 60 days {year_label}'] = f\"{ip_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'Interim Payments - The contractual time limit is 60 days {year_label}'] = \"-\"\n",
    "        \n",
    "        # Experts Payment (30 days target)\n",
    "        exp_data = dir_data[dir_data['v_payment_type'] == 'EXPERTS']\n",
    "        if len(exp_data) > 0:\n",
    "            exp_valid = exp_data[exp_data['v_payment_in_time'].notna()]\n",
    "            exp_effectiveness = (exp_data['v_payment_in_time'].sum() / len(exp_valid) * 100) if len(exp_valid) > 0 else 0\n",
    "            row[f'Experts Payment - The contractual time limit is 30 days {year_label}'] = f\"{exp_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'Experts Payment - The contractual time limit is 30 days {year_label}'] = \"-\"\n",
    "        \n",
    "        # All Payments (60 days target)\n",
    "        if len(dir_data) > 0:\n",
    "            all_valid = dir_data[dir_data['v_payment_in_time'].notna()]\n",
    "            all_effectiveness = (dir_data['v_payment_in_time'].sum() / len(all_valid) * 100) if len(all_valid) > 0 else 0\n",
    "            row[f'All Payments - The contractual time limit is 60 days {year_label}'] = f\"{all_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'All Payments - The contractual time limit is 60 days {year_label}'] = \"-\"\n",
    "        \n",
    "        table_data.append(row)\n",
    "    \n",
    "    # Add \"All Payments\" summary row\n",
    "    all_row = {'call_type': 'All Payments'}\n",
    "    \n",
    "    # Calculate overall effectiveness for all directorates\n",
    "    # Final Payments\n",
    "    all_fp_data = h2020_data[h2020_data['v_payment_type'] == 'FP']\n",
    "    if len(all_fp_data) > 0:\n",
    "        all_fp_valid = all_fp_data[all_fp_data['v_payment_in_time'].notna()]\n",
    "        all_fp_effectiveness = (all_fp_data['v_payment_in_time'].sum() / len(all_fp_valid) * 100) if len(all_fp_valid) > 0 else 0\n",
    "        all_row[f'Final Payments - The contractual time limit is 30 days {year_label}'] = f\"{all_fp_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'Final Payments - The contractual time limit is 30 days {year_label}'] = \"-\"\n",
    "    \n",
    "    # Interim Payments\n",
    "    all_ip_data = h2020_data[h2020_data['v_payment_type'] == 'IP']\n",
    "    if len(all_ip_data) > 0:\n",
    "        all_ip_valid = all_ip_data[all_ip_data['v_payment_in_time'].notna()]\n",
    "        all_ip_effectiveness = (all_ip_data['v_payment_in_time'].sum() / len(all_ip_valid) * 100) if len(all_ip_valid) > 0 else 0\n",
    "        all_row[f'Interim Payments - The contractual time limit is 60 days {year_label}'] = f\"{all_ip_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'Interim Payments - The contractual time limit is 60 days {year_label}'] = \"-\"\n",
    "    \n",
    "    # Experts Payment\n",
    "    all_exp_data = h2020_data[h2020_data['v_payment_type'] == 'EXPERTS']\n",
    "    if len(all_exp_data) > 0:\n",
    "        all_exp_valid = all_exp_data[all_exp_data['v_payment_in_time'].notna()]\n",
    "        all_exp_effectiveness = (all_exp_data['v_payment_in_time'].sum() / len(all_exp_valid) * 100) if len(all_exp_valid) > 0 else 0\n",
    "        all_row[f'Experts Payment - The contractual time limit is 30 days {year_label}'] = f\"{all_exp_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'Experts Payment - The contractual time limit is 30 days {year_label}'] = \"-\"\n",
    "    \n",
    "    # All Payments\n",
    "    if len(h2020_data) > 0:\n",
    "        all_h2020_valid = h2020_data[h2020_data['v_payment_in_time'].notna()]\n",
    "        all_h2020_effectiveness = (h2020_data['v_payment_in_time'].sum() / len(all_h2020_valid) * 100) if len(all_h2020_valid) > 0 else 0\n",
    "        all_row[f'All Payments - The contractual time limit is 60 days {year_label}'] = f\"{all_h2020_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'All Payments - The contractual time limit is 60 days {year_label}'] = \"-\"\n",
    "    \n",
    "    table_data.append(all_row)\n",
    "    \n",
    "    return pd.DataFrame(table_data)\n",
    "\n",
    "def create_heu_effectiveness_table(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Create HEU effectiveness breakdown table by directorate\n",
    "    \"\"\"\n",
    "    df_unique, year_label = create_effectiveness_breakdown(df_paym, cutoff)\n",
    "    \n",
    "    # Filter for HEU\n",
    "    heu_data = df_unique[df_unique['Programme'] == 'HEU'].copy()\n",
    "    \n",
    "    # Get actual directorates from the data\n",
    "    available_directorates = sorted([d for d in heu_data['call_type'].unique() if pd.notna(d)])\n",
    "    \n",
    "    # Build table data\n",
    "    table_data = []\n",
    "    \n",
    "    # Calculate effectiveness for each directorate\n",
    "    for dir_name in available_directorates:\n",
    "        dir_data = heu_data[heu_data['call_type'] == dir_name]\n",
    "        row = {'call_type': dir_name}\n",
    "        \n",
    "        # Experts Payment (30 days target)\n",
    "        exp_data = dir_data[dir_data['v_payment_type'] == 'EXPERTS']\n",
    "        if len(exp_data) > 0:\n",
    "            exp_valid = exp_data[exp_data['v_payment_in_time'].notna()]\n",
    "            exp_effectiveness = (exp_data['v_payment_in_time'].sum() / len(exp_valid) * 100) if len(exp_valid) > 0 else 0\n",
    "            row[f'Experts Payment - The contractual time limit is 30 days {year_label}'] = f\"{exp_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'Experts Payment - The contractual time limit is 30 days {year_label}'] = \"-\"\n",
    "        \n",
    "        # Final Payments (90 days target)\n",
    "        fp_data = dir_data[dir_data['v_payment_type'] == 'FP']\n",
    "        if len(fp_data) > 0:\n",
    "            fp_valid = fp_data[fp_data['v_payment_in_time'].notna()]\n",
    "            fp_effectiveness = (fp_data['v_payment_in_time'].sum() / len(fp_valid) * 100) if len(fp_valid) > 0 else 0\n",
    "            row[f'Final Payments - The contractual time limit is 90 days {year_label}'] = f\"{fp_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'Final Payments - The contractual time limit is 90 days {year_label}'] = \"-\"\n",
    "        \n",
    "        # Interim Payments (90 days target)\n",
    "        ip_data = dir_data[dir_data['v_payment_type'] == 'IP']\n",
    "        if len(ip_data) > 0:\n",
    "            ip_valid = ip_data[ip_data['v_payment_in_time'].notna()]\n",
    "            ip_effectiveness = (ip_data['v_payment_in_time'].sum() / len(ip_valid) * 100) if len(ip_valid) > 0 else 0\n",
    "            row[f'Interim Payments - The contractual time limit is 90 days {year_label}'] = f\"{ip_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'Interim Payments - The contractual time limit is 90 days {year_label}'] = \"-\"\n",
    "        \n",
    "        # Prefinancing Payments (days target - need to determine from data)\n",
    "        pf_data = dir_data[dir_data['v_payment_type'] == 'PF']\n",
    "        if len(pf_data) > 0:\n",
    "            pf_valid = pf_data[pf_data['v_payment_in_time'].notna()]\n",
    "            pf_effectiveness = (pf_data['v_payment_in_time'].sum() / len(pf_valid) * 100) if len(pf_valid) > 0 else 0\n",
    "            row[f'Prefinancing Payments - The contractual time limit is days {year_label}'] = f\"{pf_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'Prefinancing Payments - The contractual time limit is days {year_label}'] = \"-\"\n",
    "        \n",
    "        # All Payments (90 days target)\n",
    "        if len(dir_data) > 0:\n",
    "            all_valid = dir_data[dir_data['v_payment_in_time'].notna()]\n",
    "            all_effectiveness = (dir_data['v_payment_in_time'].sum() / len(all_valid) * 100) if len(all_valid) > 0 else 0\n",
    "            row[f'All Payments - The contractual time limit is 90 days {year_label}'] = f\"{all_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'All Payments - The contractual time limit is 90 days {year_label}'] = \"-\"\n",
    "        \n",
    "        table_data.append(row)\n",
    "    \n",
    "    # Add \"All Payments\" summary row\n",
    "    all_row = {'call_type': 'All Payments'}\n",
    "    \n",
    "    # Calculate overall effectiveness for all directorates\n",
    "    # Experts Payment\n",
    "    all_exp_data = heu_data[heu_data['v_payment_type'] == 'EXPERTS']\n",
    "    if len(all_exp_data) > 0:\n",
    "        all_exp_valid = all_exp_data[all_exp_data['v_payment_in_time'].notna()]\n",
    "        all_exp_effectiveness = (all_exp_data['v_payment_in_time'].sum() / len(all_exp_valid) * 100) if len(all_exp_valid) > 0 else 0\n",
    "        all_row[f'Experts Payment - The contractual time limit is 30 days {year_label}'] = f\"{all_exp_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'Experts Payment - The contractual time limit is 30 days {year_label}'] = \"-\"\n",
    "    \n",
    "    # Final Payments\n",
    "    all_fp_data = heu_data[heu_data['v_payment_type'] == 'FP']\n",
    "    if len(all_fp_data) > 0:\n",
    "        all_fp_valid = all_fp_data[all_fp_data['v_payment_in_time'].notna()]\n",
    "        all_fp_effectiveness = (all_fp_data['v_payment_in_time'].sum() / len(all_fp_valid) * 100) if len(all_fp_valid) > 0 else 0\n",
    "        all_row[f'Final Payments - The contractual time limit is 90 days {year_label}'] = f\"{all_fp_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'Final Payments - The contractual time limit is 90 days {year_label}'] = \"-\"\n",
    "    \n",
    "    # Interim Payments\n",
    "    all_ip_data = heu_data[heu_data['v_payment_type'] == 'IP']\n",
    "    if len(all_ip_data) > 0:\n",
    "        all_ip_valid = all_ip_data[all_ip_data['v_payment_in_time'].notna()]\n",
    "        all_ip_effectiveness = (all_ip_data['v_payment_in_time'].sum() / len(all_ip_valid) * 100) if len(all_ip_valid) > 0 else 0\n",
    "        all_row[f'Interim Payments - The contractual time limit is 90 days {year_label}'] = f\"{all_ip_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'Interim Payments - The contractual time limit is 90 days {year_label}'] = \"-\"\n",
    "    \n",
    "    # Prefinancing Payments\n",
    "    all_pf_data = heu_data[heu_data['v_payment_type'] == 'PF']\n",
    "    if len(all_pf_data) > 0:\n",
    "        all_pf_valid = all_pf_data[all_pf_data['v_payment_in_time'].notna()]\n",
    "        all_pf_effectiveness = (all_pf_data['v_payment_in_time'].sum() / len(all_pf_valid) * 100) if len(all_pf_valid) > 0 else 0\n",
    "        all_row[f'Prefinancing Payments - The contractual time limit is days {year_label}'] = f\"{all_pf_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'Prefinancing Payments - The contractual time limit is days {year_label}'] = \"-\"\n",
    "    \n",
    "    # All Payments\n",
    "    if len(heu_data) > 0:\n",
    "        all_heu_valid = heu_data[heu_data['v_payment_in_time'].notna()]\n",
    "        all_heu_effectiveness = (heu_data['v_payment_in_time'].sum() / len(all_heu_valid) * 100) if len(all_heu_valid) > 0 else 0\n",
    "        all_row[f'All Payments - The contractual time limit is 90 days {year_label}'] = f\"{all_heu_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'All Payments - The contractual time limit is 90 days {year_label}'] = \"-\"\n",
    "    \n",
    "    table_data.append(all_row)\n",
    "    \n",
    "    return pd.DataFrame(table_data)\n",
    "\n",
    "\n",
    "def generate_effectiveness_breakdown_tables(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Generate both H2020 and HEU effectiveness breakdown tables (ORIGINAL STRUCTURE)\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    h2020_eff_table, heu_eff_table = generate_effectiveness_breakdown_tables(df_paym, cutoff)\n",
    "    \n",
    "    # Display tables\n",
    "    print(\"H2020 Effectiveness Breakdown:\")\n",
    "    display(h2020_eff_table)\n",
    "    \n",
    "    print(\"\\nHEU Effectiveness Breakdown:\")\n",
    "    display(heu_eff_table)\n",
    "    \"\"\"\n",
    "    h2020_eff_table = create_h2020_effectiveness_table(df_paym, cutoff)\n",
    "    heu_eff_table = create_heu_effectiveness_table(df_paym, cutoff)\n",
    "    \n",
    "    return h2020_eff_table, heu_eff_table\n",
    "\n",
    "# =============================================================================\n",
    "# CLEAN TTP CALCULATION FUNCTIONS (from original file)\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_current_ttp_metrics(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Calculate current TTP metrics from df_paym data\n",
    "    \"\"\"\n",
    "    # Filter data up to cutoff and deduplicate by Pay Payment Key\n",
    "    quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "    last_valid_date = quarter_dates[1]\n",
    "\n",
    "    df_filtered = df_paym[\n",
    "        df_paym['Pay Document Date (dd/mm/yyyy)'] <= last_valid_date\n",
    "    ].copy()\n",
    "    df_unique = df_filtered.drop_duplicates(subset=['Pay Payment Key']).copy()\n",
    "    \n",
    "    # Convert to numeric\n",
    "    df_unique['v_TTP_NET'] = pd.to_numeric(df_unique['v_TTP_NET'], errors='coerce')\n",
    "    df_unique['v_TTP_GROSS'] = pd.to_numeric(df_unique['v_TTP_GROSS'], errors='coerce')\n",
    "    df_unique['v_payment_in_time'] = pd.to_numeric(df_unique['v_payment_in_time'], errors='coerce')\n",
    "\n",
    "    # Filter out negative TTP_NET values\n",
    "    df_unique = df_unique[df_unique['v_TTP_NET'] >= 0]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Calculate by Programme and Payment Type\n",
    "    for programme in ['H2020', 'HEU']:\n",
    "        prog_data = df_unique[df_unique['Programme'] == programme]\n",
    "        if len(prog_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        results[programme] = {}\n",
    "        \n",
    "        # Overall programme metrics\n",
    "        prog_valid = prog_data[prog_data['v_payment_in_time'].notna()]\n",
    "        results[programme]['overall'] = {\n",
    "            'avg_ttp_net': prog_data['v_TTP_NET'].mean(),\n",
    "            'avg_ttp_gross': prog_data['v_TTP_GROSS'].mean(),\n",
    "            'on_time_pct': prog_data['v_payment_in_time'].sum() / len(prog_valid) if len(prog_valid) > 0 else 0\n",
    "        }\n",
    "        \n",
    "        # By payment type - using correct short form values from v_payment_type\n",
    "        payment_types = ['IP', 'FP', 'EXPERTS', 'PF']  # Short form values\n",
    "        \n",
    "        for payment_type in payment_types:\n",
    "            pt_data = prog_data[prog_data['v_payment_type'] == payment_type]\n",
    "            if len(pt_data) > 0:\n",
    "                pt_valid = pt_data[pt_data['v_payment_in_time'].notna()]\n",
    "                results[programme][payment_type] = {\n",
    "                    'avg_ttp_net': pt_data['v_TTP_NET'].mean(),\n",
    "                    'avg_ttp_gross': pt_data['v_TTP_GROSS'].mean(),\n",
    "                    'on_time_pct': pt_data['v_payment_in_time'].sum() / len(pt_valid) if len(pt_valid) > 0 else 0\n",
    "                }\n",
    "    \n",
    "    # Overall total\n",
    "    total_valid = df_unique[df_unique['v_payment_in_time'].notna()]\n",
    "    results['TOTAL'] = {\n",
    "        'avg_ttp_net': df_unique['v_TTP_NET'].mean(),\n",
    "        'avg_ttp_gross': df_unique['v_TTP_GROSS'].mean(),\n",
    "        'on_time_pct': df_unique['v_payment_in_time'].sum() / len(total_valid) if len(total_valid) > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def load_historical_ttp_data(report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Load historical TTP data from database\n",
    "    \"\"\"\n",
    "    DB_PATH = Path(db_path)\n",
    "    report_params = load_report_params(report_name=report_name, db_path=DB_PATH)\n",
    "    \n",
    "    return {\n",
    "        \"TTP_NET_HISTORY\": report_params.get(\"TTP_NET_HISTORY\"),\n",
    "        \"TTP_GROSS_HISTORY\": report_params.get(\"TTP_GROSS_HISTORY\"),\n",
    "        \"PAYMENTS_ON_TIME_HISTORY\": report_params.get(\"PAYMENTS_ON_TIME_HISTORY\")\n",
    "    }\n",
    "\n",
    "def create_ttp_comparison_table(df_paym, cutoff, historical_data):\n",
    "    \"\"\"\n",
    "    Create TTP comparison table matching the image structure\n",
    "    \"\"\"\n",
    "    # Calculate current metrics\n",
    "    current_metrics = calculate_current_ttp_metrics(df_paym, cutoff)\n",
    "    \n",
    "    # Determine labels based on cutoff\n",
    "    cutoff_date = pd.to_datetime(cutoff)\n",
    "    current_year = cutoff_date.year\n",
    "    current_label = f\"{current_year}-YTD\"\n",
    "    historical_label = f\"Dec {current_year - 1}\"\n",
    "    \n",
    "    # Build comparison data\n",
    "    comparison_data = []\n",
    "    \n",
    "    # H2020 section\n",
    "    h2020_current = current_metrics.get('H2020', {})\n",
    "    \n",
    "    # H2020 - Interim Payments (IP)\n",
    "    current_ip = h2020_current.get('IP', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Interim Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_ip['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"H2020\"].get(\"IP\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_ip['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"H2020\"].get(\"IP\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_ip['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('IP', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # H2020 - Final Payments (FP)\n",
    "    current_fp = h2020_current.get('FP', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Final Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_fp['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"H2020\"].get(\"FP\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_fp['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"H2020\"].get(\"FP\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_fp['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('FP', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # H2020 - Experts Payments (EXPERTS)\n",
    "    current_exp = h2020_current.get('EXPERTS', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Experts Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_exp['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"H2020\"].get(\"Experts\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_exp['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"H2020\"].get(\"Experts\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_exp['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('Experts', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # H2020 - Overall\n",
    "    current_h2020 = h2020_current.get('overall', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'H2020',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_h2020['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"H2020\"].get(\"H2020\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_h2020['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"H2020\"].get(\"H2020\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_h2020['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('H2020', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU section\n",
    "    heu_current = current_metrics.get('HEU', {})\n",
    "    \n",
    "    # HEU - Prefinancing Payments (PF)\n",
    "    current_pf = heu_current.get('PF', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Prefinancing Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_pf['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"PF\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_pf['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"PF\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_pf['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('PF', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU - Interim Payments (IP)\n",
    "    current_ip_heu = heu_current.get('IP', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Interim Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_ip_heu['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"IP\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_ip_heu['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"IP\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_ip_heu['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('IP', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU - Final Payments (FP)\n",
    "    current_fp_heu = heu_current.get('FP', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Final Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_fp_heu['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"FP\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_fp_heu['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"FP\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_fp_heu['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('FP', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU - Experts Payment (EXPERTS)\n",
    "    current_exp_heu = heu_current.get('EXPERTS', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Experts Payment',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_exp_heu['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"Experts\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_exp_heu['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"Experts\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_exp_heu['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('Experts', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU - Overall\n",
    "    current_heu = heu_current.get('overall', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'HEU',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_heu['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"HEU\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_heu['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"HEU\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_heu['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('HEU', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # TOTAL row\n",
    "    current_total = current_metrics.get('TOTAL', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'TOTAL',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_total['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"ALL\"].get(\"TOTAL\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_total['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"ALL\"].get(\"TOTAL\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_total['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['ALL'].get('TOTAL', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame(comparison_data)\n",
    "\n",
    "def create_ttp_effectiveness_table(df_paym, cutoff, historical_data, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Create TTP effectiveness and efficiency indicators table\n",
    "    \"\"\"\n",
    "    # Calculate current metrics\n",
    "    current_metrics = calculate_current_ttp_metrics(df_paym, cutoff)\n",
    "    \n",
    "    # Determine labels based on cutoff using get_scope_start_end\n",
    "    quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "    last_valid_date = quarter_dates[1]\n",
    "    current_month = pd.to_datetime(last_valid_date).strftime('%b-%y')\n",
    "    \n",
    "    cutoff_date = pd.to_datetime(cutoff)\n",
    "    current_year = cutoff_date.year\n",
    "    historical_label = f\"Dec-{str(current_year-1)[-2:]}\"\n",
    "    \n",
    "    # Load database parameters for admin and expert meetings\n",
    "    from pathlib import Path\n",
    "    DB_PATH = Path(db_path)\n",
    "    report_params = load_report_params(report_name=report_name, db_path=DB_PATH)\n",
    "    \n",
    "    admin_eff = report_params.get(\"Administrative_expenditure_Effectiveness\", {})\n",
    "    admin_ttp = report_params.get(\"Administrative_expenditure_ttp\", {})\n",
    "    expt_meet_eff = report_params.get(\"Expert_meetings_Effectiveness\", {})\n",
    "    expt_meet_ttp = report_params.get(\"Expert_meetings_ttp\", {})\n",
    "    \n",
    "    # Build effectiveness data\n",
    "    effectiveness_data = []\n",
    "    \n",
    "    # Get current metrics for calculations\n",
    "    h2020_current = current_metrics.get('H2020', {})\n",
    "    heu_current = current_metrics.get('HEU', {})\n",
    "    \n",
    "    # Research grants - Interim Payments - H2020\n",
    "    h2020_ip = h2020_current.get('IP', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Interim Payments - H2020',\n",
    "        current_month: f\"{h2020_ip*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('IP', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 90 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants - Final Payments - H2020\n",
    "    h2020_fp = h2020_current.get('FP', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Final Payments - H2020',\n",
    "        current_month: f\"{h2020_fp*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('FP', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 90 days'\n",
    "    })\n",
    "    \n",
    "    # Experts with Appointment Letters H2020\n",
    "    h2020_exp = h2020_current.get('EXPERTS', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Experts with Appointment Letters H2020',\n",
    "        current_month: f\"{h2020_exp*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('Experts', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 30 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants - Pre-financings HEU\n",
    "    heu_pf = heu_current.get('PF', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Pre-financings HEU',\n",
    "        current_month: f\"{heu_pf*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('PF', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 30 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants - Interim Payments HEU\n",
    "    heu_ip = heu_current.get('IP', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Interim Payments HEU',\n",
    "        current_month: f\"{heu_ip*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('IP', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 90 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants - Final Payments HEU\n",
    "    heu_fp = heu_current.get('FP', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Final Payments HEU',\n",
    "        current_month: f\"{heu_fp*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('FP', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 90 days'\n",
    "    })\n",
    "    \n",
    "    # Administrative expenditure (from database)\n",
    "    admin_current = admin_eff.get(\"Current\", 0)\n",
    "    admin_old = admin_eff.get(\"Old\", 0)\n",
    "    admin_target = admin_eff.get(\"Target\", \"99% in 30 days\")\n",
    "    \n",
    "    # Format admin values - handle both percentage (0.985) and already formatted (98.5%) values\n",
    "    if isinstance(admin_current, (int, float)) and admin_current <= 1:\n",
    "        admin_current_str = f\"{admin_current*100:.2f}%\"\n",
    "    else:\n",
    "        admin_current_str = str(admin_current) if admin_current != \"na\" else \"n/a\"\n",
    "        \n",
    "    if isinstance(admin_old, (int, float)) and admin_old <= 1:\n",
    "        admin_old_str = f\"{admin_old*100:.2f}%\"\n",
    "    else:\n",
    "        admin_old_str = str(admin_old) if admin_old != \"na\" else \"n/a\"\n",
    "    \n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Administrative expenditure',\n",
    "        current_month: admin_current_str,\n",
    "        historical_label: admin_old_str,\n",
    "        'Target': admin_target\n",
    "    })\n",
    "    \n",
    "    # Experts with Appointment Letters HEU\n",
    "    heu_exp = heu_current.get('EXPERTS', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Experts with Appointment Letters HEU',\n",
    "        current_month: f\"{heu_exp*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('Experts', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 30 days'\n",
    "    })\n",
    "    \n",
    "    # Expert meetings PMO (from database)\n",
    "    expt_current = expt_meet_eff.get(\"Current\", \"na\")\n",
    "    expt_old = expt_meet_eff.get(\"Old\", \"na\")\n",
    "    expt_target = expt_meet_eff.get(\"Target\", \"n/a\")\n",
    "    \n",
    "    # Format expert values - handle both percentage and string values\n",
    "    if isinstance(expt_current, (int, float)) and expt_current <= 1:\n",
    "        expt_current_str = f\"{expt_current*100:.2f}%\"\n",
    "    else:\n",
    "        expt_current_str = str(expt_current) if expt_current != \"na\" else \"n/a\"\n",
    "        \n",
    "    if isinstance(expt_old, (int, float)) and expt_old <= 1:\n",
    "        expt_old_str = f\"{expt_old*100:.2f}%\"\n",
    "    else:\n",
    "        expt_old_str = str(expt_old) if expt_old != \"na\" else \"n/a\"\n",
    "    \n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Expert meetings PMO',\n",
    "        current_month: expt_current_str,\n",
    "        historical_label: expt_old_str,\n",
    "        'Target': expt_target\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame(effectiveness_data)\n",
    "\n",
    "def create_ttp_days_table(df_paym, cutoff, historical_data, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Create Time to Pay: Average number of days (H2020 - HEU) table\n",
    "    \"\"\"\n",
    "    # Calculate current metrics\n",
    "    current_metrics = calculate_current_ttp_metrics(df_paym, cutoff)\n",
    "    \n",
    "    # Load database parameters for admin and expert meetings\n",
    "    from pathlib import Path\n",
    "    DB_PATH = Path(db_path)\n",
    "    report_params = load_report_params(report_name=report_name, db_path=DB_PATH)\n",
    "    \n",
    "    admin_eff = report_params.get(\"Administrative_expenditure_Effectiveness\", {})\n",
    "    admin_ttp = report_params.get(\"Administrative_expenditure_ttp\", {})\n",
    "    expt_meet_eff = report_params.get(\"Expert_meetings_Effectiveness\", {})\n",
    "    expt_meet_ttp = report_params.get(\"Expert_meetings_ttp\", {})\n",
    "    \n",
    "    # Build days data\n",
    "    days_data = []\n",
    "    \n",
    "    # Get current metrics for calculations\n",
    "    h2020_current = current_metrics.get('H2020', {})\n",
    "    heu_current = current_metrics.get('HEU', {})\n",
    "    \n",
    "    # Research grants (days) - Interim Payments- H2020\n",
    "    h2020_ip = h2020_current.get('IP', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Interim Payments- H2020',\n",
    "        'NET': round(h2020_ip.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(h2020_ip.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '90 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants (days) - Final Payments- H2020\n",
    "    h2020_fp = h2020_current.get('FP', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Final Payments- H2020',\n",
    "        'NET': round(h2020_fp.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(h2020_fp.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '90 days'\n",
    "    })\n",
    "    \n",
    "    # Experts with Appointment Letters (days) H2020\n",
    "    h2020_exp = h2020_current.get('EXPERTS', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Experts with Appointment Letters (days) H2020',\n",
    "        'NET': round(h2020_exp.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(h2020_exp.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants (days) - Pre-financings - HEU\n",
    "    heu_pf = heu_current.get('PF', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Pre-financings - HEU',\n",
    "        'NET': round(heu_pf.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(heu_pf.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants (days) - Interim Payments- HEU\n",
    "    heu_ip = heu_current.get('IP', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Interim Payments- HEU',\n",
    "        'NET': round(heu_ip.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(heu_ip.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '90 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants (days) - Final Payments- HEU\n",
    "    heu_fp = heu_current.get('FP', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Final Payments- HEU',\n",
    "        'NET': round(heu_fp.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(heu_fp.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '90 days'\n",
    "    })\n",
    "    \n",
    "    # Expert with Appointment Letter (days) HEU\n",
    "    heu_exp = heu_current.get('EXPERTS', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Expert with Appointment Letter (days) HEU',\n",
    "        'NET': round(heu_exp.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(heu_exp.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    # Expert meetings (PMO) (days) - from database\n",
    "    expt_net_current = expt_meet_ttp.get(\"Current\", \"na\")\n",
    "    expt_gross_current = expt_meet_ttp.get(\"Current\", \"na\")  # Assuming same for both NET and GROSS\n",
    "    \n",
    "    # Format expert meeting values\n",
    "    if isinstance(expt_net_current, (int, float)):\n",
    "        expt_net_str = str(round(expt_net_current, 1))\n",
    "        expt_gross_str = str(round(expt_gross_current, 1))\n",
    "    else:\n",
    "        expt_net_str = \"n/a\"\n",
    "        expt_gross_str = \"n/a\"\n",
    "    \n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Expert meetings (PMO) (days)',\n",
    "        'NET': expt_net_str,\n",
    "        'GROSS': expt_gross_str,\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    # Administrative expenditure (days) - from database\n",
    "    admin_net_current = admin_ttp.get(\"Current\", 0)\n",
    "    admin_gross_current = admin_ttp.get(\"Current\", 0)  # Assuming same for both NET and GROSS\n",
    "    \n",
    "    # Format admin values\n",
    "    if isinstance(admin_net_current, (int, float)):\n",
    "        admin_net_str = str(round(admin_net_current, 1))\n",
    "        admin_gross_str = str(round(admin_gross_current, 1))\n",
    "    else:\n",
    "        admin_net_str = \"n/a\"\n",
    "        admin_gross_str = \"n/a\"\n",
    "    \n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Administrative expenditure (days)',\n",
    "        'NET': admin_net_str,\n",
    "        'GROSS': admin_gross_str,\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame(days_data)\n",
    "\n",
    "def generate_all_ttp_tables(df_paym, cutoff, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Generate all three TTP tables - comparison table, effectiveness table, and days table\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    comparison_table, effectiveness_table, days_table = generate_all_ttp_tables(df_paym, cutoff)\n",
    "    \"\"\"\n",
    "    # Load historical data\n",
    "    historical_data = load_historical_ttp_data(report_name=report_name, db_path=db_path)\n",
    "    \n",
    "    # Create all three tables\n",
    "    comparison_table = create_ttp_comparison_table(df_paym, cutoff, historical_data)\n",
    "    effectiveness_table = create_ttp_effectiveness_table(df_paym, cutoff, historical_data, report_name, db_path)\n",
    "    days_table = create_ttp_days_table(df_paym, cutoff, historical_data, report_name, db_path)\n",
    "    \n",
    "    return comparison_table, effectiveness_table, days_table\n",
    "\n",
    "def generate_complete_ttp_suite(df_paym, cutoff, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Generate the complete TTP report suite with all table variations\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    tables = generate_complete_ttp_suite(df_paym, cutoff)\n",
    "    \n",
    "    # Access any table:\n",
    "    comparison_table = tables['comparison']\n",
    "    effectiveness_table = tables['effectiveness'] \n",
    "    days_table = tables['days']\n",
    "    h2020_net_quarterly = tables['h2020_net_quarterly']  # MultiIndex DataFrame\n",
    "    heu_net_quarterly = tables['heu_net_quarterly']      # MultiIndex DataFrame  \n",
    "    h2020_gross_quarterly = tables['h2020_gross_quarterly']\n",
    "    heu_gross_quarterly = tables['heu_gross_quarterly']\n",
    "    h2020_effectiveness = tables['h2020_effectiveness']  # Clean table like Picture 1\n",
    "    heu_effectiveness = tables['heu_effectiveness']      # Clean table like Picture 1\n",
    "    \n",
    "    # Example: Access specific data from MultiIndex quarterly table\n",
    "    print(\"ADG PF data:\", tables['heu_net_quarterly'][('ADG', 'PF')])\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate summary tables\n",
    "    comparison_table, effectiveness_table, days_table = generate_all_ttp_tables(df_paym, cutoff, report_name, db_path)\n",
    "    \n",
    "    # Generate quarterly breakdown tables (days) with MultiIndex - FOR GREAT_TABLES\n",
    "    h2020_net_quarterly, heu_net_quarterly = generate_quarterly_breakdown_tables(df_paym, cutoff, 'NET')\n",
    "    h2020_gross_quarterly, heu_gross_quarterly = generate_quarterly_breakdown_tables(df_paym, cutoff, 'GROSS')\n",
    "    \n",
    "    # Generate effectiveness breakdown tables (percentages) - CLEAN STRUCTURE like Picture 1\n",
    "    h2020_effectiveness, heu_effectiveness = generate_effectiveness_breakdown_tables(df_paym, cutoff)\n",
    "    \n",
    "    return {\n",
    "        'comparison': comparison_table,\n",
    "        'effectiveness': effectiveness_table,\n",
    "        'days': days_table,\n",
    "        'h2020_net_quarterly': h2020_net_quarterly,\n",
    "        'heu_net_quarterly': heu_net_quarterly,\n",
    "        'h2020_gross_quarterly': h2020_gross_quarterly,\n",
    "        'heu_gross_quarterly': heu_gross_quarterly,\n",
    "        'h2020_effectiveness': h2020_effectiveness,\n",
    "        'heu_effectiveness': heu_effectiveness\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# UPDATED MAIN FUNCTIONS - USE THESE IN JUPYTER\n",
    "# =============================================================================\n",
    "\n",
    "def generate_ttp_tables(df_paym, cutoff, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Main function to generate all TTP tables\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    comparison_table, effectiveness_table, days_table = generate_ttp_tables(df_paym, cutoff)\n",
    "    \n",
    "    # Display all three summary tables\n",
    "    print(\"TTP Comparison Table:\")\n",
    "    display(comparison_table)\n",
    "    \n",
    "    print(\"\\nEffectiveness and Efficiency Indicators:\")\n",
    "    display(effectiveness_table)\n",
    "    \n",
    "    print(\"\\nTime to Pay: Average number of days:\")\n",
    "    display(days_table)\n",
    "    \"\"\"\n",
    "    return generate_all_ttp_tables(df_paym, cutoff, report_name, db_path)\n",
    "\n",
    "def generate_quarterly_tables_for_great_tables(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Generate quarterly breakdown tables specifically formatted for great_tables (MultiIndex)\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    h2020_net, heu_net, h2020_gross, heu_gross = generate_quarterly_tables_for_great_tables(df_paym, cutoff)\n",
    "    \n",
    "    # These DataFrames have MultiIndex columns perfect for great_tables:\n",
    "    # - Level 0: Directorate (ADG, COG, POC, STG, SYG, Experts, Total)  \n",
    "    # - Level 1: Payment Type (PF, IP, FP, EXPERTS)\n",
    "    # - Index: Quarters (2024Q1, 2024Q2, etc.) + \"Dep C.\" summary row\n",
    "    \n",
    "    # Example usage:\n",
    "    print(\"HEU NET quarterly table structure:\")\n",
    "    print(\"Columns:\", heu_net.columns.tolist())\n",
    "    print(\"Index:\", heu_net.index.tolist())\n",
    "    print(\"ADG-PF column:\", heu_net[('ADG', 'PF')])\n",
    "    \"\"\"\n",
    "    h2020_net, heu_net = generate_quarterly_breakdown_tables(df_paym, cutoff, 'NET')\n",
    "    h2020_gross, heu_gross = generate_quarterly_breakdown_tables(df_paym, cutoff, 'GROSS')\n",
    "    \n",
    "    return h2020_net, heu_net, h2020_gross, heu_gross\n",
    "\n",
    "def generate_effectiveness_tables_for_display(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Generate effectiveness breakdown tables for regular display (Clean structure like Picture 1)\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    h2020_eff, heu_eff = generate_effectiveness_tables_for_display(df_paym, cutoff)\n",
    "    \n",
    "    # These DataFrames have clean structure like Picture 1:\n",
    "    # - Rows: Directorates (ADG, COG, POC, STG, SYG, All Payments)\n",
    "    # - Columns: Payment types with descriptive headers\n",
    "    # - Values: Formatted percentages like \"100.00%\"\n",
    "    \n",
    "    # Example usage:\n",
    "    print(\"H2020 Effectiveness Table:\")\n",
    "    display(h2020_eff)\n",
    "    \"\"\"\n",
    "    return generate_effectiveness_breakdown_tables(df_paym, cutoff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330ecd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_tables_ttp_annex(df, table_colors=None, table_title='nothing'):\n",
    "    \"\"\"\n",
    "    Format TTP table with MultiIndex columns converted to GT spanners\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with MultiIndex columns\n",
    "        table_colors: Dictionary with custom colors\n",
    "        table_title: Table title\n",
    "    \"\"\"\n",
    "    \n",
    "    # Default colors if not provided\n",
    "    if table_colors is None:\n",
    "        table_colors = {}\n",
    "    \n",
    "    BLUE = table_colors.get(\"BLUE\", \"#004A99\")\n",
    "    LIGHT_BLUE = table_colors.get(\"LIGHT_BLUE\", \"#d6e6f4\")\n",
    "    DARK_BLUE = table_colors.get(\"DARK_BLUE\", \"#01244B\") \n",
    "    SUB_TOTAL_BACKGROUND = table_colors.get(\"subtotal_background_color\", \"#E6E6FA\")\n",
    "    \n",
    "    # Step 1: Flatten MultiIndex columns\n",
    "    df_flat = df.copy()\n",
    "    \n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        # Combine MultiIndex levels into single column names\n",
    "        # Format: \"Level0_Level1\" or just \"Level1\" if Level0 is empty/duplicate\n",
    "        new_columns = []\n",
    "        level_0_groups = {}  # Track which columns belong to which top-level group\n",
    "        \n",
    "        for i, (level0, level1) in enumerate(df.columns):\n",
    "            if pd.isna(level0) or level0 == '' or 'Unnamed' in str(level0):\n",
    "                # If top level is empty, just use level1\n",
    "                col_name = str(level1)\n",
    "            else:\n",
    "                # Combine both levels\n",
    "                col_name = f\"{level0}_{level1}\"\n",
    "                # Track group membership for spanners\n",
    "                if level0 not in level_0_groups:\n",
    "                    level_0_groups[level0] = []\n",
    "                level_0_groups[level0].append(col_name)\n",
    "            \n",
    "            new_columns.append(col_name)\n",
    "        \n",
    "        # Apply flattened column names\n",
    "        df_flat.columns = new_columns\n",
    "        \n",
    "    else:\n",
    "        # Already flat columns\n",
    "        level_0_groups = {}\n",
    "        new_columns = df.columns.tolist()\n",
    "    \n",
    "    # Reset index to make the first column a regular column\n",
    "    df_flat = df_flat.reset_index()\n",
    "    \n",
    "    # Apply column renames AFTER reset_index (which creates 'index' column)\n",
    "    column_renames = {\n",
    "        'index': 'Quarter',\n",
    "        'Experts_Experts': 'Experts',\n",
    "        'Total_Total': 'Total'\n",
    "    }\n",
    "    df_flat = df_flat.rename(columns=column_renames)\n",
    "    \n",
    "    # Update level_0_groups to reflect renamed columns\n",
    "    if level_0_groups:\n",
    "        updated_groups = {}\n",
    "        for group_name, columns in level_0_groups.items():\n",
    "            updated_columns = [column_renames.get(col, col) for col in columns]\n",
    "            updated_groups[group_name] = updated_columns\n",
    "        level_0_groups = updated_groups\n",
    "    \n",
    "    # Step 2: Create GT table\n",
    "    tbl = GT(df_flat)\n",
    "    \n",
    "    # Step 3: Add spanners for MultiIndex structure\n",
    "    if level_0_groups:\n",
    "        for group_name, columns in level_0_groups.items():\n",
    "            # Only add spanner if there are multiple columns in the group\n",
    "            if len(columns) > 1:\n",
    "                tbl = tbl.tab_spanner(\n",
    "                    label=group_name,\n",
    "                    columns=columns\n",
    "                )\n",
    "    \n",
    "    # Step 4: Get data columns for formatting (exclude index column)\n",
    "    data_columns = [col for col in df_flat.columns if col != df_flat.columns[0]]\n",
    "    \n",
    "    total_rows =  df_flat.index[  df_flat['Quarter'].astype(str).str.contains('Dep C.', case=False, na=False)].tolist()\n",
    "    \n",
    "    # Dynamic width calculation\n",
    "    num_data_columns = len(data_columns)\n",
    "    base_width_per_column = 80  # Increased for better readability\n",
    "    stub_width = 200  # width for the first column\n",
    "    table_width = f\"{stub_width + (num_data_columns * base_width_per_column)}px\"\n",
    "    \n",
    "    # Step 5: Apply styling\n",
    "    tbl = (\n",
    "        tbl\n",
    "        .opt_stylize(style=5, color='blue')\n",
    "        .opt_table_font(font=\"Arial\")\n",
    "        \n",
    "        .tab_header(title=md(f'**{table_title}**'))\n",
    "        \n",
    "        .tab_options(\n",
    "            table_background_color=\"white\",\n",
    "            heading_background_color=\"white\",\n",
    "            table_font_size='small',\n",
    "            table_font_color=DARK_BLUE,\n",
    "            table_width=table_width,\n",
    "            heading_title_font_size=\"16px\",\n",
    "            heading_subtitle_font_size=\"10px\",\n",
    "            heading_title_font_weight=\"bold\",\n",
    "            row_striping_include_table_body=False,\n",
    "            row_striping_include_stub=False\n",
    "        )\n",
    "        \n",
    "        # Format numeric columns\n",
    "        .fmt_number(\n",
    "            columns=data_columns,\n",
    "            decimals=1\n",
    "        )\n",
    "\n",
    "        .tab_style(\n",
    "        style=[\n",
    "            style.text(color='white', weight=\"bold\"),\n",
    "            style.fill(color=\"#004d80\")\n",
    "        ],\n",
    "        locations=[\n",
    "            loc.body(rows=total_rows),\n",
    "            loc.stub(rows=total_rows)\n",
    "        ]\n",
    "    )\n",
    "    )\n",
    "    \n",
    "    return tbl\n",
    "\n",
    "\n",
    "def format_tables_effect_annex(df,table_colors=None, title = 'none'):\n",
    "    \"\"\"\n",
    "    Format TTP table with 3 spanners: Average Net Time to Pay, Average Gross Time to Pay, Target Paid on Time\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with TTP data\n",
    "        title: Table title\n",
    "        rowname_col: Column name for row names (default: \"Type of Payments\")\n",
    "        table_colors: Dictionary with custom colors\n",
    "    \"\"\"\n",
    "    \n",
    "    # Default colors if not provided\n",
    "    if table_colors is None:\n",
    "        table_colors = {}\n",
    "    \n",
    "    BLUE = table_colors.get(\"BLUE\", \"#004A99\")\n",
    "    LIGHT_BLUE = table_colors.get(\"LIGHT_BLUE\", \"#d6e6f4\")\n",
    "    DARK_BLUE = table_colors.get(\"DARK_BLUE\", \"#01244B\") \n",
    "    SUB_TOTAL_BACKGROUND = table_colors.get(\"subtotal_background_color\", \"#E6E6FA\")\n",
    "    \n",
    "    columns_cetered = df.columns[1:].tolist()\n",
    "\n",
    "    # Dynamic width calculation\n",
    "    ttp_columns = df.columns[1:].to_list()\n",
    "    num_data_columns = len(ttp_columns)\n",
    "    base_width_per_column = 120  # pixels per column\n",
    "    stub_width = 200  # width for the first column (Quarter)\n",
    "    \n",
    "    table_width = f\"{stub_width + (num_data_columns * base_width_per_column)}px\"\n",
    "\n",
    "    total_rows = df.index[df['call_type'].astype(str).str.contains('All Payments', case=False, na=False)].tolist()\n",
    "    \n",
    "    df = df.rename(columns={'call_type': 'Call Type'})\n",
    "    # Create and format table with 3 spanners\n",
    "    tbl = (\n",
    "        GT(df)\n",
    "\n",
    "        .tab_header(title=md(f'**{title}**'))\n",
    "        \n",
    "        # 4. Apply theme and basic styling\n",
    "        .opt_stylize(style=5, color='blue')\n",
    "        .opt_table_font(font=\"Arial\")\n",
    "       \n",
    "        # 5. Table options\n",
    "        .tab_options(\n",
    "            table_background_color=\"white\",\n",
    "            heading_background_color=\"white\",\n",
    "            table_font_size='small',\n",
    "            table_font_color=DARK_BLUE,\n",
    "            table_width=table_width,\n",
    "            heading_title_font_size=\"16px\",\n",
    "            heading_title_font_weight=\"bold\",\n",
    "            row_striping_include_table_body=False,\n",
    "            row_striping_include_stub=False,\n",
    "            # column_labels_background_color=\"#004d80\",\n",
    "            column_labels_font_weight='bold',\n",
    "        )\n",
    "    \n",
    "\n",
    "         # 11. Center align data columns\n",
    "        .cols_align(\n",
    "            align=\"center\",\n",
    "            columns=columns_cetered \n",
    "        )\n",
    "\n",
    "        .tab_style(\n",
    "                    style=[\n",
    "                        style.text(color='white', weight=\"bold\"),\n",
    "                        style.fill(color=\"#004d80\")\n",
    "                    ],\n",
    "                    locations=[\n",
    "                        loc.body(rows=total_rows),\n",
    "                        loc.stub(rows=total_rows)\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "    )\n",
    "   \n",
    "    return tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9516b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annex_tables(formatted_table, table_data, var_name, module):                 \n",
    "            \n",
    "    try:         \n",
    "        # Convert DataFrame to JSON-serializable format\n",
    "        if isinstance(table_data, pd.DataFrame):\n",
    "            # Reset index to avoid tuple keys and convert to records\n",
    "            df_copy = table_data.reset_index()\n",
    "            # Convert column names to strings if they're tuples\n",
    "            df_copy.columns = [str(col) if isinstance(col, tuple) else col for col in df_copy.columns]\n",
    "            table_value = df_copy.to_dict('records')\n",
    "        else:\n",
    "            table_value = table_data\n",
    "            \n",
    "        # Save to database         \n",
    "        insert_variable(             \n",
    "            report=report,             \n",
    "            module=module,             \n",
    "            var=var_name,             \n",
    "            value=table_value,             \n",
    "            db_path=db_path,             \n",
    "            anchor=var_name,             \n",
    "            gt_table=formatted_table         \n",
    "        )                                \n",
    "        \n",
    "        return True, f\"Successfully processed {var_name}\"                        \n",
    "        \n",
    "    except Exception as e:         \n",
    "        return False, f\"Error processing {var_name}: {str(e)}\"\n",
    "\n",
    "#generate TTP NET Tables for Annex\n",
    "h2020_net, heu_net, h2020_gross, heu_gross = generate_quarterly_tables_for_great_tables(df_paym, cutoff)\n",
    "\n",
    "h2020_net_formated = format_tables_ttp_annex(h2020_net, table_colors=table_colors, table_title='H2020')\n",
    "heu_net_formated = format_tables_ttp_annex(heu_net, table_colors=table_colors, table_title='HEU')\n",
    "\n",
    "#generate Effectiveness tables for Annex \n",
    "tables = generate_complete_ttp_suite(df_paym, cutoff)\n",
    "h2020_effect = tables['h2020_effectiveness']\n",
    "heu_effect = tables['heu_effectiveness']\n",
    "\n",
    "h2020_effect_formatted = format_tables_effect_annex(h2020_effect,table_colors=table_colors, title = 'H2020')\n",
    "heu_effect_formatted = format_tables_effect_annex(heu_effect,table_colors=table_colors, title = 'HEU')\n",
    "\n",
    "annex_tables = [(h2020_net_formated , h2020_net, 'Overview_h2020_tp_net'), (heu_net_formated , heu_net, 'Overview_heu_tp_net'),\n",
    "                (h2020_effect_formatted , h2020_effect, 'Overview_h2020_eff'), (heu_effect_formatted , heu_effect, 'Overview_heu_eff')\n",
    "                    ]\n",
    "\n",
    "\n",
    "for formatted_table, data_table, var_name in annex_tables:\n",
    "      create_annex_tables(formatted_table, data_table, var_name, module = 'AuriModule')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d0b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from datetime import datetime, date\n",
    "from typing import Tuple\n",
    "import locale\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set locale for number formatting (adjust as needed)\n",
    "try:\n",
    "    locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
    "except:\n",
    "    try:\n",
    "        locale.setlocale(locale.LC_ALL, 'C')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Configuration - Update these as needed\n",
    "colorScheme = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "title_color = '#333333'\n",
    "\n",
    "def get_current_reporting_date():\n",
    "    \"\"\"Get current reporting date - uses current timestamp\"\"\"\n",
    "    return pd.Timestamp.now()\n",
    "\n",
    "def get_call_type_column(df):\n",
    "    \"\"\"Identify the call type column in the dataframe\"\"\"\n",
    "    possible_columns = ['SCRS_CALL_TYPE', 'call_type', 'Call Type', 'v_call_type', 'Local Position', 'v_1_Program']\n",
    "    for col in possible_columns:\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def prepare_payment_data(df_paym, programme, call_type=None, cutoff_date=None):\n",
    "    \"\"\"\n",
    "    Prepare payment data for chart generation using existing date utilities\n",
    "    \n",
    "    Parameters:\n",
    "    - df_paym: Payment dataframe\n",
    "    - programme: 'H2020' or 'HEU' \n",
    "    - call_type: Specific call type (e.g., 'STG', 'ADG', etc.) or 'all' for all\n",
    "    - cutoff_date: Cutoff date for reporting (default: current timestamp)\n",
    "    \"\"\"\n",
    "    \n",
    "    if cutoff_date is None:\n",
    "        cutoff_date = get_current_reporting_date()\n",
    "    \n",
    "    # Ensure cutoff_date is a pandas Timestamp\n",
    "    if isinstance(cutoff_date, str):\n",
    "        cutoff_date = pd.to_datetime(cutoff_date)\n",
    "    elif hasattr(cutoff_date, 'date'):  # datetime object\n",
    "        cutoff_date = pd.Timestamp(cutoff_date)\n",
    "    elif not isinstance(cutoff_date, pd.Timestamp):\n",
    "        cutoff_date = pd.Timestamp(cutoff_date)\n",
    "    \n",
    "    print(f\"Preparing data for {programme} - {call_type} - Cutoff: {cutoff_date}\")\n",
    "    \n",
    "    # Use existing utilities to get scope\n",
    "    reporting_year = determine_epoch_year(cutoff_date)\n",
    "    scope_start, scope_end = get_scope_start_end(cutoff_date)\n",
    "    months_list = months_in_scope(cutoff_date)\n",
    "    \n",
    "    print(f\"Reporting year: {reporting_year}\")\n",
    "    print(f\"Scope: {scope_start} to {scope_end}\")\n",
    "    print(f\"Months in scope: {len(months_list)} months\")\n",
    "    \n",
    "    # Copy and filter data\n",
    "    df = df_paym.copy()\n",
    "    \n",
    "    # Filter by programme\n",
    "    df = df[df['Programme'] == programme].copy()\n",
    "    \n",
    "    # Parse dates if they're strings\n",
    "    if df['Pay Document Date (dd/mm/yyyy)'].dtype == 'object':\n",
    "        df['Pay Document Date (dd/mm/yyyy)'] = pd.to_datetime(df['Pay Document Date (dd/mm/yyyy)'], \n",
    "                                                              format='%d/%m/%Y', errors='coerce')\n",
    "    \n",
    "    # Filter by date scope (use scope_start and scope_end)\n",
    "    df = df[\n",
    "        (df['Pay Document Date (dd/mm/yyyy)'] >= scope_start) & \n",
    "        (df['Pay Document Date (dd/mm/yyyy)'] <= scope_end)\n",
    "    ].copy()\n",
    "    \n",
    "    # Filter by fund source (equivalent to old C1, E0 filter)\n",
    "    df = df[df['Fund Source'].notna()].copy()\n",
    "    \n",
    "    # Handle call type filtering\n",
    "    call_type_col = get_call_type_column(df)\n",
    "    \n",
    "    if call_type and call_type != 'all' and call_type_col:\n",
    "        df = df[df[call_type_col] == call_type].copy()\n",
    "        print(f\"Filtered by {call_type_col} = {call_type}: {len(df)} rows\")\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        print(\"No data after filtering\")\n",
    "        return create_dummy_payment_data(programme, call_type, cutoff_date, reporting_year)\n",
    "    \n",
    "    # Create month column\n",
    "    df['Month'] = df['Pay Document Date (dd/mm/yyyy)'].dt.month\n",
    "    df['Year'] = df['Pay Document Date (dd/mm/yyyy)'].dt.year\n",
    "    \n",
    "    # Filter for reporting year (already filtered by scope, but double-check)\n",
    "    df = df[df['Year'] == reporting_year].copy()\n",
    "    \n",
    "    # Aggregate by month (sum amounts)\n",
    "    monthly_payments = df.groupby(['Month'])['v_amount_to_sum'].sum().reset_index()\n",
    "    monthly_payments.rename(columns={'v_amount_to_sum': 'Paid'}, inplace=True)\n",
    "    \n",
    "    # Add programme and year info\n",
    "    monthly_payments['v_1_Program'] = programme\n",
    "    monthly_payments['Year'] = reporting_year\n",
    "    \n",
    "    print(f\"Monthly payments aggregated: {len(monthly_payments)} months\")\n",
    "    return monthly_payments\n",
    "\n",
    "def prepare_forecast_data(df_forecast, programme, call_type=None):\n",
    "    \"\"\"\n",
    "    Prepare forecast data to match payment data structure\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df_forecast.copy()\n",
    "    \n",
    "    # Map the actual column names from your forecast data\n",
    "    programme_col_map = {\n",
    "        'SCRS_FMWK': 'SCRS_FMWK',  # Your actual programme column\n",
    "        'Programme': 'Programme',\n",
    "        'v_1_Program': 'v_1_Program'\n",
    "    }\n",
    "    \n",
    "    call_type_col_map = {\n",
    "        'SCRS_CALL_TYPE': 'SCRS_CALL_TYPE',  # Your actual call type column\n",
    "        'call_type': 'call_type',\n",
    "        'Local Position': 'Local Position'\n",
    "    }\n",
    "    \n",
    "    forecast_amount_col_map = {\n",
    "        'Sum(SCRS_C1_MNT)': 'Sum(SCRS_C1_MNT)',  # Your actual forecast amount column\n",
    "        'Forecast': 'Forecast',\n",
    "        'v_amount_to_sum': 'v_amount_to_sum'\n",
    "    }\n",
    "    \n",
    "    month_col_map = {\n",
    "        'Month_Num': 'Month_Num',  # Your actual month number column\n",
    "        'Month': 'Month'\n",
    "    }\n",
    "    \n",
    "    # Find programme column\n",
    "    programme_col = None\n",
    "    for col in programme_col_map.keys():\n",
    "        if col in df.columns:\n",
    "            programme_col = col\n",
    "            break\n",
    "    \n",
    "    # Find call type column  \n",
    "    call_type_col = None\n",
    "    for col in call_type_col_map.keys():\n",
    "        if col in df.columns:\n",
    "            call_type_col = col\n",
    "            break\n",
    "    \n",
    "    # Find forecast amount column\n",
    "    forecast_col = None\n",
    "    for col in forecast_amount_col_map.keys():\n",
    "        if col in df.columns:\n",
    "            forecast_col = col\n",
    "            break\n",
    "            \n",
    "    # Find month column\n",
    "    month_col = None\n",
    "    for col in month_col_map.keys():\n",
    "        if col in df.columns:\n",
    "            month_col = col\n",
    "            break\n",
    "    \n",
    "    print(f\"Forecast data columns detected:\")\n",
    "    print(f\"  Programme: {programme_col}\")\n",
    "    print(f\"  Call Type: {call_type_col}\")  \n",
    "    print(f\"  Amount: {forecast_col}\")\n",
    "    print(f\"  Month: {month_col}\")\n",
    "    \n",
    "    # Filter by programme\n",
    "    if programme_col:\n",
    "        df = df[df[programme_col] == programme].copy()\n",
    "        print(f\"Filtered forecast by {programme_col} = {programme}: {len(df)} rows\")\n",
    "    else:\n",
    "        print(\"No programme column found in forecast data - using all data\")\n",
    "    \n",
    "    # Handle call type filtering\n",
    "    if call_type and call_type != 'all' and call_type_col:\n",
    "        df = df[df[call_type_col] == call_type].copy()\n",
    "        print(f\"Filtered forecast by {call_type_col} = {call_type}: {len(df)} rows\")\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        print(\"No forecast data after filtering - creating zero forecast\")\n",
    "        return pd.DataFrame({\n",
    "            'Month': range(1, 13),\n",
    "            'Forecast': [0] * 12,\n",
    "            'v_1_Program': programme\n",
    "        })\n",
    "    \n",
    "    if not forecast_col:\n",
    "        print(f\"No forecast amount column found. Available columns: {list(df.columns)}\")\n",
    "        print(\"Creating zero forecast\")\n",
    "        return pd.DataFrame({\n",
    "            'Month': range(1, 13),\n",
    "            'Forecast': [0] * 12,\n",
    "            'v_1_Program': programme\n",
    "        })\n",
    "    \n",
    "    # Aggregate by month if month column exists\n",
    "    if month_col:\n",
    "        forecast_monthly = df.groupby([month_col])[forecast_col].sum().reset_index()\n",
    "        forecast_monthly.rename(columns={\n",
    "            month_col: 'Month',\n",
    "            forecast_col: 'Forecast'\n",
    "        }, inplace=True)\n",
    "    else:\n",
    "        # Distribute forecast equally across 12 months\n",
    "        total_forecast = df[forecast_col].sum()\n",
    "        forecast_monthly = pd.DataFrame({\n",
    "            'Month': range(1, 13),\n",
    "            'Forecast': [total_forecast / 12] * 12\n",
    "        })\n",
    "    \n",
    "    forecast_monthly['v_1_Program'] = programme\n",
    "    \n",
    "    print(f\"Forecast monthly data prepared: {len(forecast_monthly)} months, total: {forecast_monthly['Forecast'].sum():,.0f}\")\n",
    "    return forecast_monthly\n",
    "\n",
    "def create_dummy_payment_data(programme, call_type, cutoff_date, reporting_year):\n",
    "    \"\"\"Create dummy data when no payments exist\"\"\"\n",
    "    \n",
    "    # Use the existing months_in_scope function to get the right months\n",
    "    months_list = months_in_scope(cutoff_date)\n",
    "    month_numbers = list(range(1, len(months_list) + 1))\n",
    "    \n",
    "    dummy_data = []\n",
    "    \n",
    "    for month in month_numbers:\n",
    "        dummy_data.append({\n",
    "            'Month': month,\n",
    "            'Paid': 0,\n",
    "            'v_1_Program': programme\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(dummy_data)\n",
    "\n",
    "def merge_payment_and_forecast_data(df_paid, df_forecast, programme, budget_amount=None):\n",
    "    \"\"\"\n",
    "    Merge payment and forecast data, calculate cumulative values and deviations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Merge on Month\n",
    "    df_merged = pd.merge(df_paid, df_forecast[['Month', 'Forecast']], \n",
    "                        on='Month', how='outer').fillna(0)\n",
    "    \n",
    "    # Ensure we have all months 1-12\n",
    "    all_months = pd.DataFrame({'Month': range(1, 13)})\n",
    "    df_merged = pd.merge(all_months, df_merged, on='Month', how='left').fillna(0)\n",
    "    df_merged['v_1_Program'] = programme\n",
    "    \n",
    "    # Sort by month\n",
    "    df_merged.sort_values('Month', inplace=True)\n",
    "    df_merged.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Calculate cumulative values\n",
    "    df_merged['Paid_Cumulative'] = df_merged['Paid'].cumsum()\n",
    "    df_merged['Forecast_Cumulative'] = df_merged['Forecast'].cumsum()\n",
    "    \n",
    "    # Add budget appropriations only if available\n",
    "    df_merged['Has_Budget'] = budget_amount is not None and budget_amount > 0\n",
    "    if df_merged['Has_Budget'].iloc[0]:\n",
    "        df_merged['Appropriations'] = budget_amount\n",
    "    else:\n",
    "        df_merged['Appropriations'] = None\n",
    "    \n",
    "    # Calculate total forecast for percentage calculations\n",
    "    total_forecast = df_merged['Forecast'].sum()\n",
    "    \n",
    "    if total_forecast > 0:\n",
    "        df_merged['Consumption_Pct'] = df_merged['Paid_Cumulative'] / total_forecast\n",
    "        df_merged['Forecast_Pct'] = df_merged['Forecast_Cumulative'] / total_forecast\n",
    "        df_merged['Deviation_Pct'] = df_merged['Consumption_Pct'] - df_merged['Forecast_Pct']\n",
    "    else:\n",
    "        df_merged['Consumption_Pct'] = 0\n",
    "        df_merged['Forecast_Pct'] = 0\n",
    "        df_merged['Deviation_Pct'] = 0\n",
    "    \n",
    "    # Calculate deviation in absolute terms\n",
    "    df_merged['Deviation_Amount'] = df_merged['Paid_Cumulative'] - df_merged['Forecast_Cumulative']\n",
    "    \n",
    "    # Calculate deviation vs budget percentage only if budget is available\n",
    "    if df_merged['Has_Budget'].iloc[0]:\n",
    "        df_merged['Deviation_vs_Budget_Pct'] = df_merged['Deviation_Amount'] / budget_amount\n",
    "    else:\n",
    "        df_merged['Deviation_vs_Budget_Pct'] = None\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "\n",
    "def create_payment_chart(df_merged, programme, call_type, year, cutoff_month):\n",
    "    \"\"\"\n",
    "    Create the payment consumption chart using Altair with proper legend\n",
    "    \"\"\"\n",
    "    BLUE = table_colors.get(\"BLUE\", \"#004A99\")\n",
    "    LIGHT_BLUE = table_colors.get(\"LIGHT_BLUE\", \"#d6e6f4\")\n",
    "    DARK_BLUE = table_colors.get(\"DARK_BLUE\", \"#01244B\") \n",
    "    SUB_TOTAL_BACKGROUND = table_colors.get(\"subtotal_background_color\", \"#E6E6FA\")\n",
    "\n",
    "    # Filter data up to cutoff month for actual payments\n",
    "    df_display = df_merged.copy()\n",
    "    df_current = df_display[df_display['Month'] <= cutoff_month].copy()\n",
    "    \n",
    "    # Check if budget data is available\n",
    "    has_budget = df_merged['Has_Budget'].iloc[0] if len(df_merged) > 0 else False\n",
    "    \n",
    "    title_text = 'Default'\n",
    "    # Chart title\n",
    "    if call_type == 'all':\n",
    "          title_text = f\"{programme} - Consumption All Calls {year}\"\n",
    "    else:\n",
    "          title_text = f\"{programme} - Consumption {call_type} {year}\"\n",
    "    \n",
    "    # Get current month deviation for annotation\n",
    "    if len(df_current) > 0:\n",
    "        current_deviation = df_current.iloc[-1]['Deviation_Pct']\n",
    "        current_month = df_current.iloc[-1]['Month']\n",
    "    else:\n",
    "        current_deviation = 0\n",
    "        current_month = cutoff_month\n",
    "    \n",
    "    # Determine deviation color and annotation\n",
    "    if current_deviation < -0.01:  # Less than -1%\n",
    "        deviation_color = 'red'\n",
    "        deviation_comment = 'Underconsumption'\n",
    "        arrow = '➟'\n",
    "        angle_value = 90\n",
    "        dx_arrow = -50\n",
    "        dy_arrow = -5\n",
    "        dy_spread = -90\n",
    "        dx_spread = -10\n",
    "        dy_comment=-70\n",
    "        dx_comment=-40\n",
    "\n",
    "    elif current_deviation > 0.01:  # Greater than 1%\n",
    "        deviation_color = 'green'\n",
    "        deviation_comment = 'Overconsumption'\n",
    "        arrow = '➟'\n",
    "        angle_value = 270\n",
    "        dx_arrow = 30\n",
    "        dy_arrow = 5\n",
    "        dy_spread = -80\n",
    "        dx_spread = -10\n",
    "        dy_comment=-50\n",
    "        dx_comment=-40\n",
    "  \n",
    "    else:\n",
    "        deviation_color = '#2b7a30'\n",
    "        deviation_comment = 'On Track'\n",
    "        arrow = ''\n",
    "        angle_value = 180\n",
    "        dx_arrow = -50\n",
    "        dy_arrow = -5\n",
    "        dy_spread = -100\n",
    "        dx_spread = -10\n",
    "        dy_comment=-70\n",
    "        dx_comment=-10\n",
    "   \n",
    "    \n",
    "    # Set up Altair theme\n",
    "    def my_theme():\n",
    "        return {\n",
    "            'config': {\n",
    "                'view': {'continuousHeight': 350, 'continuousWidth': 550},\n",
    "                'range': {'category': {'scheme': colorScheme}},\n",
    "                'title': {\n",
    "                    \"fontSize\": 18, \n",
    "                    \"font\": 'Lato', \n",
    "                    \"anchor\": \"center\",\n",
    "                    'color': BLUE,\n",
    "                    'fontWeight': 'bold'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    alt.themes.register('my_theme', my_theme)\n",
    "    alt.themes.enable('my_theme')\n",
    "    \n",
    "    # Prepare data for consumption bars with legend\n",
    "    df_current_renamed = df_current.copy()\n",
    "    df_current_renamed['Consumption'] = df_current_renamed['Paid_Cumulative']\n",
    "    \n",
    "    # Base chart for consumption bars WITH LEGEND\n",
    "    # bar_chart = alt.Chart(df_current_renamed).mark_bar(\n",
    "    #     size=45,\n",
    "    #     opacity=0.7\n",
    "    # ).transform_fold(\n",
    "    #     fold=['Consumption'],  # This creates the legend entry\n",
    "    #     as_=['Legend', 'value']\n",
    "    # ).encode(\n",
    "    #     x=alt.X('Month:O', title='Month'),\n",
    "    #     y=alt.Y('value:Q', title='Amount (€)', scale=alt.Scale(zero=True)),\n",
    "    #     color=alt.Color('Legend:N', \n",
    "    #                    scale=alt.Scale(domain=['Consumption', 'Forecast', 'Appropriations'],\n",
    "    #                                  range=['#1f77b4', '#ff7f0e', '#2ca02c']))\n",
    "    # ).properties(\n",
    "    #     width=550,\n",
    "    #     height=350\n",
    "    # )\n",
    "    bar_chart = alt.Chart(df_current_renamed).mark_bar(\n",
    "    size=45,\n",
    "    opacity=0.7,\n",
    "    color='#1f77b4'  # Fixed blue color for consumption bars\n",
    "        ).encode(\n",
    "            x=alt.X('Month:O', title='Month'),\n",
    "            y=alt.Y('Paid_Cumulative:Q', title='Amount (€)', scale=alt.Scale(zero=True))\n",
    "        )\n",
    "        # ).properties(\n",
    "        #     width=550,\n",
    "        #     height=350\n",
    "        # )\n",
    "    \n",
    "    # Prepare data for forecast line with legend\n",
    "    df_display_renamed = df_display.copy()\n",
    "    df_display_renamed['Forecast'] = df_display_renamed['Forecast_Cumulative']\n",
    "    \n",
    "    # # Forecast line WITH LEGEND\n",
    "    # forecast_line = alt.Chart(df_display_renamed).mark_line(\n",
    "    #     opacity=0.8,\n",
    "    #     strokeWidth=3\n",
    "    # ).transform_fold(\n",
    "    #     fold=['Forecast'],  # This creates the legend entry\n",
    "    #     as_=['Legend', 'value']\n",
    "    # ).encode(\n",
    "    #     x='Month:O',\n",
    "    #     y=alt.Y('value:Q', title=''),\n",
    "    #     color=alt.Color('Legend:N',\n",
    "    #                    scale=alt.Scale(domain=['Consumption', 'Forecast', 'Appropriations'],\n",
    "    #                                  range=['#1f77b4', '#ff7f0e', '#2ca02c']))\n",
    "    # )\n",
    "\n",
    "    forecast_line = alt.Chart(df_display_renamed).mark_line(\n",
    "    opacity=0.8,\n",
    "    strokeWidth=3,\n",
    "    color='#ff7f0e'  # Fixed orange color for forecast line\n",
    "        ).encode(\n",
    "            x='Month:O',\n",
    "            y=alt.Y('Forecast_Cumulative:Q', title='')\n",
    "        )\n",
    "    \n",
    "    # Start with base charts\n",
    "    charts_to_combine = [bar_chart, forecast_line]\n",
    "    \n",
    "    # Appropriations line - only if budget data is available WITH LEGEND\n",
    "    # if has_budget:\n",
    "    #     # Prepare appropriations data\n",
    "    #     df_display_renamed['Appropriations'] = df_display_renamed['Appropriations']\n",
    "        \n",
    "    #     appropriations_line = alt.Chart(df_display_renamed).mark_line(\n",
    "    #         opacity=0.8,\n",
    "    #         strokeWidth=3\n",
    "    #     ).transform_fold(\n",
    "    #         fold=['Appropriations'],  # This creates the legend entry\n",
    "    #         as_=['Legend', 'value']\n",
    "    #     ).encode(\n",
    "    #         x='Month:O',\n",
    "    #         y=alt.Y('value:Q', title=''),\n",
    "    #         color=alt.Color('Legend:N',\n",
    "    #                        scale=alt.Scale(domain=['Consumption', 'Forecast', 'Appropriations'],\n",
    "    #                                      range=['#1f77b4', '#ff7f0e', '#2ca02c']))\n",
    "    #     )\n",
    "    #     charts_to_combine.append(appropriations_line)\n",
    "\n",
    "    if has_budget:\n",
    "        # Appropriations line WITHOUT LEGEND\n",
    "        appropriations_line = alt.Chart(df_display_renamed).mark_line(\n",
    "            opacity=0.8,\n",
    "            strokeWidth=3,\n",
    "            color='#2ca02c'  # Fixed green color for appropriations line\n",
    "        ).encode(\n",
    "            x='Month:O',\n",
    "            y=alt.Y('Appropriations:Q', title='')\n",
    "        )\n",
    "        charts_to_combine.append(appropriations_line)\n",
    "    \n",
    "    # Percentage text on bars\n",
    "    percentage_text = alt.Chart(df_current).mark_text(\n",
    "        baseline='bottom',\n",
    "        dx=0,\n",
    "        dy=-5,\n",
    "        align='center',\n",
    "        fontSize=12,\n",
    "        fontWeight='bold',\n",
    "        color=DARK_BLUE\n",
    "    ).encode(\n",
    "        x='Month:O',\n",
    "        y='Paid_Cumulative:Q',\n",
    "        text=alt.Text('Consumption_Pct:Q', format='.1%')\n",
    "    )\n",
    "    \n",
    "    # Deviation annotation\n",
    "    deviation_base = alt.Chart(pd.DataFrame([{\n",
    "        'Month': current_month,\n",
    "        'Paid_Cumulative': df_current.iloc[-1]['Paid_Cumulative'] if len(df_current) > 0 else 0,\n",
    "        'Deviation_Pct': current_deviation,\n",
    "        'Comment': deviation_comment,\n",
    "        'Arrow': arrow\n",
    "    }]))\n",
    "    \n",
    "    deviation_text = deviation_base.mark_text(\n",
    "        dx=dx_spread,\n",
    "        dy=dy_spread,\n",
    "        fontSize=14,\n",
    "        fontWeight='bold',\n",
    "        color=deviation_color,\n",
    "        align='left'\n",
    "    ).encode(\n",
    "        x='Month:O',\n",
    "        y='Paid_Cumulative:Q',\n",
    "        text=alt.Text('Deviation_Pct:Q', format='.1%')\n",
    "    )\n",
    "    \n",
    "    deviation_comment_text = deviation_base.mark_text(\n",
    "        dx=dx_comment,\n",
    "        dy=dy_comment,\n",
    "        fontSize=11,\n",
    "        fontWeight='bold',\n",
    "        color=deviation_color,\n",
    "        align='left'\n",
    "    ).encode(\n",
    "        x='Month:O',\n",
    "        y='Paid_Cumulative:Q',\n",
    "        text='Comment:N'\n",
    "    )\n",
    "    \n",
    "    arrow_chart = deviation_base.mark_text(\n",
    "        dx=dx_arrow,\n",
    "        dy=dy_arrow,\n",
    "        angle=angle_value,\n",
    "        fontSize=35,\n",
    "        fontWeight='bold',\n",
    "        color=deviation_color,\n",
    "        align='center'\n",
    "    ).encode(\n",
    "        x='Month:O',\n",
    "        y='Paid_Cumulative:Q',\n",
    "        text='Arrow:N'\n",
    "    )\n",
    "\n",
    "      # Create unified legend data\n",
    "    legend_data = pd.DataFrame({\n",
    "        'Legend': ['Consumption', 'Forecast', 'Appropriations'],\n",
    "        'Month': [1, 1, 1],  # Dummy values for positioning\n",
    "        'Value': [0, 0, 0],   # Dummy values\n",
    "        'Color': ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "    })\n",
    "\n",
    "     # Create legend as separate marks\n",
    "    legend_bars = alt.Chart(legend_data).mark_rect(\n",
    "        width=15,\n",
    "        height=15\n",
    "    ).encode(\n",
    "        x=alt.X('Legend:N', title=None, axis=alt.Axis(labelAngle=0)),\n",
    "        color=alt.Color('Color:N', scale=None, legend=None)\n",
    "    ).properties(\n",
    "        width=400,\n",
    "        height=30\n",
    "    ).resolve_scale(color='independent')\n",
    "    \n",
    "    # Add percentage text and deviation annotations\n",
    "    # charts_to_combine.extend([percentage_text, deviation_text, deviation_comment_text, arrow_chart])\n",
    "    \n",
    "    # # Combine all chart elements\n",
    "    # final_chart = alt.layer(*charts_to_combine)\n",
    "\n",
    "    # Main chart\n",
    "    if has_budget:\n",
    "        main_chart = (bar_chart + appropriations_line + forecast_line + percentage_text + deviation_text +  deviation_comment_text + arrow_chart).properties(\n",
    "            width=600,\n",
    "            height=300,\n",
    "            title=alt.TitleParams(\n",
    "                text=title_text,\n",
    "                fontSize=16,\n",
    "                fontWeight='bold',\n",
    "                anchor='start',\n",
    "                color='#1B5390'\n",
    "            )\n",
    "        ).resolve_scale(\n",
    "            color='independent'\n",
    "        )\n",
    "    else:\n",
    "        main_chart = (bar_chart + forecast_line + percentage_text + deviation_text + deviation_comment_text + arrow_chart).properties(\n",
    "            width=600,\n",
    "            height=450,\n",
    "            title=alt.TitleParams(\n",
    "                text= title_text,\n",
    "                fontSize=16,\n",
    "                fontWeight='bold',\n",
    "                anchor='start',\n",
    "                color='#1B5390'\n",
    "            )\n",
    "        ).resolve_scale(\n",
    "            color='independent'\n",
    "        )\n",
    "\n",
    "        \n",
    "    # Combine main chart with legend\n",
    "    final_chart = alt.vconcat(\n",
    "        main_chart,\n",
    "        legend_bars\n",
    "    ).resolve_scale(\n",
    "        color='independent'\n",
    "    )\n",
    "   \n",
    "    return final_chart\n",
    "\n",
    "\n",
    "\n",
    "# Final working function with complete styling\n",
    "def format_tables_payments_complete(df, table_colors=None, program = 'HEU', call='STG', table_subtitle='Monthly Overview', stub_width=300):\n",
    "    \"\"\"\n",
    "    Complete working version with all styling properly applied\n",
    "    \"\"\"\n",
    "    \n",
    "    if table_colors is None:\n",
    "        table_colors = {}\n",
    "    \n",
    "    BLUE = table_colors.get(\"BLUE\", \"#004A99\")\n",
    "    DARK_BLUE = table_colors.get(\"DARK_BLUE\", \"#01244B\")\n",
    "    LIGHT_BLUE = table_colors.get(\"LIGHT_BLUE\", \"#d6e6f4\")\n",
    "    \n",
    "    # Process dataframe\n",
    "    df_formatted = df.copy()\n",
    "    first_col = df_formatted.columns[0]\n",
    "    df_formatted = df_formatted.rename(columns={first_col: \"\"})\n",
    "    \n",
    "    data_columns = df_formatted.columns[1:].tolist()\n",
    "    last_month_col = data_columns[-1] if data_columns else None\n",
    "    \n",
    "    # Calculate table width\n",
    "    base_width_per_column = 80\n",
    "    table_width = f\"{stub_width + (len(data_columns) * base_width_per_column)}px\"\n",
    "    \n",
    "    # Find deviation rows\n",
    "    money_rows = []\n",
    "    pct_rows = []\n",
    "    \n",
    "    for idx, row in df_formatted.iterrows():\n",
    "        row_text = str(row.iloc[0]).lower()\n",
    "        if 'deviation' in row_text and 'million' in row_text:\n",
    "            money_rows.append(idx)\n",
    "        elif 'deviation' in row_text and '%' in row_text:\n",
    "            pct_rows.append(idx)\n",
    "    \n",
    "    table_title = f'{program} {call} - Payment Analysis'\n",
    "\n",
    "    # Create table with comprehensive styling\n",
    "    tbl = (\n",
    "        GT(df_formatted)\n",
    "        .tab_header(title=md(f'**{table_title}**'), subtitle=md(f'**{table_subtitle}**'))\n",
    "        \n",
    "        # Basic table options\n",
    "        .tab_options(\n",
    "            table_background_color=\"white\",\n",
    "            table_font_size='small',\n",
    "            table_font_color = DARK_BLUE,\n",
    "            table_width=table_width,\n",
    "            heading_title_font_size=\"16px\",\n",
    "            heading_subtitle_font_size=\"12px\",\n",
    "            heading_title_font_weight=\"bold\",\n",
    "            row_striping_include_table_body=False,\n",
    "            row_striping_include_stub=False,\n",
    "            column_labels_background_color=\"#004d80\"\n",
    "        )\n",
    "        .opt_table_font(\n",
    "                font='Arial',\n",
    "            )\n",
    "        \n",
    "        # Style ALL stub cells (row labels) - DARK BLUE background\n",
    "        .tab_style(\n",
    "            style=[\n",
    "                style.fill(color=DARK_BLUE),\n",
    "                style.text(color=\"white\", weight=\"bold\", size=\"small\"),\n",
    "                style.borders(sides=\"all\", color=\"white\", weight=\"1px\")\n",
    "            ],\n",
    "            locations=loc.stub()\n",
    "        )\n",
    "        \n",
    "        # Style ALL column headers - BLUE background\n",
    "        .tab_style(\n",
    "            style=[\n",
    "                style.fill(color=BLUE),\n",
    "                style.text(color=\"white\", weight=\"bold\", size=\"small\"),\n",
    "                style.borders(sides=\"all\", color=\"white\", weight=\"1px\")\n",
    "            ],\n",
    "            locations=loc.column_labels()\n",
    "        )\n",
    "        \n",
    "        # Style ALL body cells - basic formatting\n",
    "        .tab_style(\n",
    "            style=[\n",
    "                style.text(size=\"small\"),\n",
    "                style.borders(sides=\"all\", color=\"#cccccc\", weight=\"1px\")\n",
    "            ],\n",
    "            locations=loc.body()\n",
    "        )\n",
    "        \n",
    "        # Center align all data columns\n",
    "        .cols_align(align='center', columns=data_columns)\n",
    "        \n",
    "        # Set column widths\n",
    "        .cols_width({col: f\"{base_width_per_column}px\" for col in data_columns})\n",
    "    )\n",
    "    \n",
    "    # Apply conditional coloring using tab_style (more reliable than data_color)\n",
    "    if last_month_col:\n",
    "        \n",
    "        # Color money deviations\n",
    "        for row_idx in money_rows:\n",
    "            value = df_formatted.loc[row_idx, last_month_col]\n",
    "            try:\n",
    "                numeric_value = float(value)\n",
    "                if numeric_value < -10:\n",
    "                    color = \"#cc0000\"  # Dark red\n",
    "                    text_color = \"white\"\n",
    "                elif numeric_value < -1:\n",
    "                    color = \"#ff6666\"  # Light red\n",
    "                    text_color = \"white\"\n",
    "                elif numeric_value < 1:\n",
    "                    color = \"#ffff99\"  # Yellow\n",
    "                    text_color = \"black\"\n",
    "                elif numeric_value < 50:\n",
    "                    color = \"#99ff99\"  # Light green\n",
    "                    text_color = \"black\"\n",
    "                else:\n",
    "                    color = \"#00cc00\"  # Dark green\n",
    "                    text_color = \"white\"\n",
    "                \n",
    "                tbl = tbl.tab_style(\n",
    "                    style=[\n",
    "                        style.fill(color=color),\n",
    "                        style.text(color=text_color, weight=\"bold\"),\n",
    "                        style.borders(sides=\"all\", color=\"white\", weight=\"1px\")\n",
    "                    ],\n",
    "                    locations=loc.body(columns=[last_month_col], rows=[row_idx])\n",
    "                )\n",
    "                print(f\"Colored money row {row_idx} with value {numeric_value} as {color}\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Color percentage deviations\n",
    "        for row_idx in pct_rows:\n",
    "            value = str(df_formatted.loc[row_idx, last_month_col])\n",
    "            try:\n",
    "                # Remove % sign and convert to float\n",
    "                numeric_value = float(value.replace('%', ''))\n",
    "                if numeric_value < -5:\n",
    "                    color = \"#cc0000\"  # Dark red\n",
    "                    text_color = \"white\"\n",
    "                elif numeric_value < -1:\n",
    "                    color = \"#ff6666\"  # Light red\n",
    "                    text_color = \"white\"\n",
    "                elif numeric_value < 1:\n",
    "                    color = \"#ffff99\"  # Yellow\n",
    "                    text_color = \"black\"\n",
    "                elif numeric_value < 10:\n",
    "                    color = \"#99ff99\"  # Light green\n",
    "                    text_color = \"black\"\n",
    "                else:\n",
    "                    color = \"#00cc00\"  # Dark green\n",
    "                    text_color = \"white\"\n",
    "                \n",
    "                tbl = tbl.tab_style(\n",
    "                    style=[\n",
    "                        style.fill(color=color),\n",
    "                        style.text(color=text_color, weight=\"bold\"),\n",
    "                        style.borders(sides=\"all\", color=\"white\", weight=\"1px\")\n",
    "                    ],\n",
    "                    locations=loc.body(columns=[last_month_col], rows=[row_idx])\n",
    "                )\n",
    "                print(f\"Colored percentage row {row_idx} with value {numeric_value}% as {color}\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return tbl\n",
    "\n",
    "\n",
    "def create_summary_table(df_merged, cutoff_month):\n",
    "    \"\"\"\n",
    "    Create the summary table below the chart - excludes budget rows when no budget data available\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter to current data\n",
    "    df_table = df_merged[df_merged['Month'] <= cutoff_month].copy()\n",
    "    \n",
    "    # Check if budget data is available\n",
    "    has_budget = df_merged['Has_Budget'].iloc[0] if len(df_merged) > 0 else False\n",
    "    \n",
    "    # Convert to millions for display\n",
    "    df_table = df_table.copy()\n",
    "    df_table['Paid_M'] = df_table['Paid_Cumulative'] / 1_000_000\n",
    "    df_table['Forecast_M'] = df_table['Forecast_Cumulative'] / 1_000_000\n",
    "    df_table['Deviation_M'] = df_table['Deviation_Amount'] / 1_000_000\n",
    "    \n",
    "    # Format numbers\n",
    "    df_table['Paid_Formatted'] = df_table['Paid_M'].map('{:,.3f}'.format)\n",
    "    df_table['Forecast_Formatted'] = df_table['Forecast_M'].map('{:,.3f}'.format)\n",
    "    df_table['Consumption_Pct_Formatted'] = df_table['Consumption_Pct'].map('{:.1%}'.format)\n",
    "    df_table['Forecast_Pct_Formatted'] = df_table['Forecast_Pct'].map('{:.1%}'.format)\n",
    "    df_table['Deviation_Pct_Formatted'] = df_table['Deviation_Pct'].map('{:.1%}'.format)\n",
    "    df_table['Deviation_M_Formatted'] = df_table['Deviation_M'].map('{:,.1f}'.format)\n",
    "    \n",
    "    # Define base columns for output table\n",
    "    output_cols = [\n",
    "        'Month', 'Paid_Formatted', 'Forecast_Formatted',\n",
    "        'Deviation_M_Formatted', 'Deviation_Pct_Formatted'\n",
    "    ]\n",
    "    \n",
    "    # Add budget-related columns only if budget data is available\n",
    "    if has_budget:\n",
    "        df_table['Budget_M'] = df_table['Appropriations'] / 1_000_000\n",
    "        df_table['Budget_Formatted'] = df_table['Budget_M'].map('{:,.1f}'.format)\n",
    "        df_table['Deviation_vs_Budget_Formatted'] = df_table['Deviation_vs_Budget_Pct'].map('{:.1%}'.format)\n",
    "        \n",
    "        # Insert budget column at the beginning and deviation vs budget at the end\n",
    "        output_cols.insert(1, 'Budget_Formatted')\n",
    "        output_cols.append('Deviation_vs_Budget_Formatted')\n",
    "    \n",
    "    # Create output table\n",
    "    table_output = df_table[output_cols].copy()\n",
    "    table_output.set_index('Month', inplace=True)\n",
    "    \n",
    "    # Transpose for month columns\n",
    "    table_transposed = table_output.T\n",
    "    table_transposed.reset_index(inplace=True)\n",
    "    table_transposed.rename(columns={'index': 'Metric'}, inplace=True)\n",
    "    \n",
    "    # Define metric names based on whether budget data is available\n",
    "    if has_budget:\n",
    "        metric_names = {\n",
    "            'Budget_Formatted': 'Current Inscribed Budget',\n",
    "            'Paid_Formatted': 'Cumulative Consumption (€ million)',\n",
    "            'Forecast_Formatted': 'Cumulative Forecast (€ million)',\n",
    "            'Deviation_M_Formatted': 'Deviation vs. Cumulative Forecast (€ million)',\n",
    "            'Deviation_Pct_Formatted': 'Deviation vs. Cumulative Forecast (%)',\n",
    "            'Deviation_vs_Budget_Formatted': 'Deviation vs. Budget (%)'\n",
    "        }\n",
    "    else:\n",
    "        metric_names = {\n",
    "            'Paid_Formatted': 'Cumulative Consumption (€ million)',\n",
    "            'Forecast_Formatted': 'Cumulative Forecast (€ million)',\n",
    "            'Deviation_M_Formatted': 'Deviation vs. Cumulative Forecast (€ million)',\n",
    "            'Deviation_Pct_Formatted': 'Deviation vs. Cumulative Forecast (%)'\n",
    "        }\n",
    "    \n",
    "    table_transposed['Metric'] = table_transposed['Metric'].map(metric_names)\n",
    "    \n",
    "    # Rename month columns\n",
    "    month_names = {\n",
    "        1: 'JAN', 2: 'FEB', 3: 'MAR', 4: 'APR', 5: 'MAY', 6: 'JUN',\n",
    "        7: 'JUL', 8: 'AUG', 9: 'SEP', 10: 'OCT', 11: 'NOV', 12: 'DEC'\n",
    "    }\n",
    "    \n",
    "    table_transposed.columns = ['Metric'] + [month_names.get(col, str(col)) for col in table_transposed.columns[1:]]\n",
    "    \n",
    "    return table_transposed\n",
    "\n",
    "\n",
    "def create_budget_config():\n",
    "    \"\"\"\n",
    "    Create budget configuration by fetching the latest budget data\n",
    "    This should be called once when setting up the charts\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get budget data (assuming vars_all is available globally)\n",
    "    if 'vars_all' not in globals():\n",
    "        print(\"Warning: vars_all not found - budget data will not be available\")\n",
    "        return {\n",
    "            'H2020': {'all': None},\n",
    "            'HEU': {'all': None, 'EXPERTS': None}\n",
    "        }\n",
    "    \n",
    "    vars_data = vars_all.get('table_2a_HE')\n",
    "    h2020_vars_data = vars_all.get('table_2a_H2020')\n",
    "\n",
    "    # Extract Total Available Payment Appropriations\n",
    "    heu_total_appropriations = next(\n",
    "        (item['Available_Payment_Appropriations'] for item in vars_data \n",
    "         if item['Budget Address Type'] == 'Total'), \n",
    "        None\n",
    "    ) if vars_data else None\n",
    "    \n",
    "    heu_total_appropriations_expt = next(\n",
    "        (item['Available_Payment_Appropriations'] for item in vars_data \n",
    "         if item['Budget Address Type'] == 'Experts'), \n",
    "        None\n",
    "    ) if vars_data else None\n",
    "\n",
    "    h2020_total_appropriations = next(\n",
    "        (item['Available_Payment_Appropriations'] for item in h2020_vars_data \n",
    "         if item['Budget Address Type'] == 'Total'), \n",
    "        None\n",
    "    ) if h2020_vars_data else None\n",
    "\n",
    "    # Budget configuration - Only available for specific cases\n",
    "    budget_config = {\n",
    "        'H2020': {\n",
    "            'all': h2020_total_appropriations  # Total H2020 budget - ONLY available for 'all' call types\n",
    "        },\n",
    "        'HEU': {\n",
    "            'all': heu_total_appropriations,    # Total HEU budget - available for 'all' call types\n",
    "            'EXPERTS': heu_total_appropriations_expt   # HEU Experts budget - ONLY individual call type with budget\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"Budget configuration created:\")\n",
    "    for programme, budgets in budget_config.items():\n",
    "        for call_type, amount in budgets.items():\n",
    "            if amount:\n",
    "                print(f\"  {programme} {call_type}: €{amount:,.0f}\")\n",
    "            else:\n",
    "                print(f\"  {programme} {call_type}: No budget data\")\n",
    "    \n",
    "    return budget_config\n",
    "\n",
    "# Create global budget configuration\n",
    "AVAILABLE_BUDGET_CONFIG = create_budget_config()\n",
    "\n",
    "def check_budget_availability(programme, call_type):\n",
    "    \"\"\"\n",
    "    Check if budget appropriations are available for the given programme/call_type combination\n",
    "    \"\"\"\n",
    "    if programme == 'H2020':\n",
    "        return call_type == 'all'\n",
    "    elif programme == 'HEU':\n",
    "        return call_type in ['all', 'EXPERTS']\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_budget_amount(programme, call_type, budget_config=None):\n",
    "    \"\"\"\n",
    "    Get budget amount for programme/call_type if available\n",
    "    \"\"\"\n",
    "    if budget_config is None:\n",
    "        budget_config = AVAILABLE_BUDGET_CONFIG\n",
    "    \n",
    "    if not check_budget_availability(programme, call_type):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        return budget_config[programme][call_type]\n",
    "    except (KeyError, TypeError):\n",
    "        return None\n",
    "\n",
    "def generate_payment_chart_and_table(df_paym, df_forecast, programme, call_type='all', \n",
    "                                   budget_amount=None, cutoff_date=None):\n",
    "    \"\"\"\n",
    "    Main function to generate both chart and table for a specific programme/call type\n",
    "    \n",
    "    Parameters:\n",
    "    - df_paym: Payment dataframe\n",
    "    - df_forecast: Forecast dataframe  \n",
    "    - programme: 'H2020' or 'HEU'\n",
    "    - call_type: Specific call type or 'all'\n",
    "    - budget_amount: Budget appropriation amount (if None, will try to auto-lookup)\n",
    "    - cutoff_date: Reporting cutoff date\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with 'chart' and 'table' keys\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Auto-lookup budget if not provided\n",
    "        if budget_amount is None:\n",
    "            try:\n",
    "                budget_amount = get_budget_amount(programme, call_type, AVAILABLE_BUDGET_CONFIG)\n",
    "                if budget_amount:\n",
    "                    print(f\"Auto-detected budget for {programme} {call_type}: €{budget_amount:,.0f}\")\n",
    "                else:\n",
    "                    print(f\"No budget available for {programme} {call_type}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error looking up budget: {e}\")\n",
    "                budget_amount = None\n",
    "        \n",
    "        # Get cutoff date\n",
    "        if cutoff_date is None:\n",
    "            cutoff_date = get_current_reporting_date()\n",
    "        \n",
    "        # Ensure cutoff_date is a pandas Timestamp\n",
    "        if isinstance(cutoff_date, str):\n",
    "            cutoff_date = pd.to_datetime(cutoff_date)\n",
    "        elif not isinstance(cutoff_date, pd.Timestamp):\n",
    "            cutoff_date = pd.Timestamp(cutoff_date)\n",
    "        \n",
    "        # Use existing date utilities\n",
    "        reporting_year = determine_epoch_year(cutoff_date)\n",
    "        scope_start, scope_end = get_scope_start_end(cutoff_date)\n",
    "        months_list = months_in_scope(cutoff_date)\n",
    "        cutoff_month = len(months_list)  # Number of months in scope\n",
    "        \n",
    "        print(f\"\\n=== Generating chart for {programme} - {call_type} ===\")\n",
    "        print(f\"Cutoff date: {cutoff_date}\")\n",
    "        print(f\"Reporting year: {reporting_year}\")\n",
    "        print(f\"Scope: {scope_start} to {scope_end}\")\n",
    "        print(f\"Months in scope: {cutoff_month}\")\n",
    "        if budget_amount:\n",
    "            print(f\"Budget amount: €{budget_amount:,.0f}\")\n",
    "        else:\n",
    "            print(\"No budget amount - appropriations line will not be shown\")\n",
    "        \n",
    "        # Prepare payment data\n",
    "        df_paid = prepare_payment_data(df_paym, programme, call_type, cutoff_date)\n",
    "        \n",
    "        # Prepare forecast data\n",
    "        df_forecast_prep = prepare_forecast_data(df_forecast, programme, call_type)\n",
    "        \n",
    "        # Merge and calculate\n",
    "        df_merged = merge_payment_and_forecast_data(df_paid, df_forecast_prep, programme, budget_amount)\n",
    "        \n",
    "        # Create chart\n",
    "        chart = create_payment_chart(df_merged, programme, call_type, reporting_year, cutoff_month)\n",
    "        \n",
    "        # Create table\n",
    "        table = create_summary_table(df_merged, cutoff_month)\n",
    "        \n",
    "        return {\n",
    "            'chart': chart,\n",
    "            'table': table,\n",
    "            'data': df_merged,\n",
    "            'success': True,\n",
    "            'metadata': {\n",
    "                'reporting_year': reporting_year,\n",
    "                'scope_start': scope_start,\n",
    "                'scope_end': scope_end,\n",
    "                'cutoff_month': cutoff_month,\n",
    "                'months_in_scope': months_list,\n",
    "                'budget_amount': budget_amount,\n",
    "                'has_budget': budget_amount is not None and budget_amount > 0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating chart for {programme} - {call_type}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {\n",
    "            'chart': None,\n",
    "            'table': None,\n",
    "            'data': None,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "def generate_all_charts_tables(df_paym, df_forecast, programme_budgets=None, cutoff_date=None):\n",
    "    \"\"\"\n",
    "    Generate charts for all available call types in both programmes\n",
    "    Only applies budget appropriations where available (H2020 'all', HEU 'all' and 'EXPERTS')\n",
    "    \"\"\"\n",
    "    \n",
    "    if programme_budgets is None:\n",
    "        programme_budgets = AVAILABLE_BUDGET_CONFIG\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Get available call types\n",
    "    call_type_col = get_call_type_column(df_paym)\n",
    "    \n",
    "    if call_type_col:\n",
    "        # Get unique call types per programme\n",
    "        programmes = ['H2020', 'HEU']\n",
    "        \n",
    "        for programme in programmes:\n",
    "            prog_data = df_paym[df_paym['Programme'] == programme]\n",
    "            call_types = prog_data[call_type_col].dropna().unique().tolist()\n",
    "            call_types.append('all')  # Add overall summary\n",
    "            \n",
    "            results[programme] = {}\n",
    "            \n",
    "            for call_type in call_types:\n",
    "                # Get budget only if available for this combination\n",
    "                budget = get_budget_amount(programme, call_type, programme_budgets)\n",
    "                \n",
    "                result = generate_payment_chart_and_table(\n",
    "                    df_paym, df_forecast, programme, call_type, budget, cutoff_date\n",
    "                )\n",
    "                \n",
    "                results[programme][call_type] = result\n",
    "                \n",
    "                if result['success']:\n",
    "                    budget_status = \"with budget\" if budget else \"without budget\"\n",
    "                    \n",
    "                    chart = result['chart']\n",
    "                    table = result['table']\n",
    "                    data = result['data']\n",
    "                    \n",
    "                    formatted_table = format_tables_payments_complete(table, table_colors=table_colors, program = programme, call=call_type, table_subtitle='Monthly Overview', stub_width=300)\n",
    "           \n",
    "                    var_name_chart = f'{programme}_{call_type}_paym_analysis_chart'\n",
    "                    var_name_table = f'{programme}_{call_type}_paym_analysis_table'\n",
    "\n",
    "                    try:\n",
    "                        logger.debug(f\"Saving {var_name_chart} and {var_name_table} to database\")\n",
    "                        insert_variable(\n",
    "                            report=report, module=\"PaymentsModule\", var=var_name_chart,\n",
    "                            value=data,\n",
    "                            db_path=db_path, anchor=var_name_chart, altair_chart=chart\n",
    "                        )\n",
    "                        insert_variable(\n",
    "                            report=report, module=\"PaymentsModule\", var=var_name_table,\n",
    "                            value=data,\n",
    "                            db_path=db_path, anchor=var_name_table, gt_table=formatted_table\n",
    "                        )\n",
    "                        logger.debug(f\"Saved {var_name} and {var_name_table} to database\")\n",
    "                       \n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Failed to save {var_name}: {str(e)}\")\n",
    "                        \n",
    "                    print(f\"✓ Generated: {programme} - {call_type} ({budget_status})\")\n",
    "                else:\n",
    "                    print(f\"✗ Failed: {programme} - {call_type}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Helper function to refresh budget configuration if needed\n",
    "def refresh_budget_config():\n",
    "    \"\"\"\n",
    "    Refresh the global budget configuration with latest data\n",
    "    Call this if vars_all has been updated\n",
    "    \"\"\"\n",
    "    global AVAILABLE_BUDGET_CONFIG\n",
    "    AVAILABLE_BUDGET_CONFIG = create_budget_config()\n",
    "    return AVAILABLE_BUDGET_CONFIG\n",
    "\n",
    "# Helper function to manually set budget configuration\n",
    "def set_budget_config(config):\n",
    "    \"\"\"\n",
    "    Manually set the budget configuration\n",
    "    Useful for testing or when vars_all is not available\n",
    "    \"\"\"\n",
    "    global AVAILABLE_BUDGET_CONFIG\n",
    "    AVAILABLE_BUDGET_CONFIG = config\n",
    "    return AVAILABLE_BUDGET_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d8c92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_all_charts_tables(df_paym, df_forecast, programme_budgets=None, cutoff_date=cutoff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6560b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reporting.quarterly_report.report_utils.payments_m_builder import paym_charts_summary_tables\n",
    "\n",
    "paym_charts_summary_tables (df_paym, cutoff, db_path, report, table_colors, report_params, df_forecast )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a483b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37266f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
