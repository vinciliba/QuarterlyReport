{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e002fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reporting/quarterly_report/modules/granting.py\n",
    "from __future__ import annotations\n",
    "\n",
    "import logging, sqlite3, datetime\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import calendar\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from typing import List, Tuple,Union\n",
    "import numpy as np\n",
    "from great_tables import GT, loc, style, html\n",
    "import re\n",
    "import logging\n",
    "\n",
    "from ingestion.db_utils import (\n",
    "    fetch_latest_table_data,\n",
    "    insert_variable,\n",
    "    load_report_params,\n",
    "    fetch_vars_for_report\n",
    ")\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('amendments_report.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(\"Payments\")\n",
    "\n",
    "\n",
    "\n",
    "# our project\n",
    "from ingestion.db_utils import (\n",
    "    init_db,                                 # create tables if missing\n",
    "    fetch_latest_table_data,                 # new version!\n",
    "    get_alias_last_load,\n",
    "    get_variable_status, \n",
    "    load_report_params                   # to inspect results\n",
    ")\n",
    "\n",
    "from reporting.quarterly_report.utils import RenderContext, BaseModule\n",
    "from reporting.quarterly_report.report_utils.granting_utils import enrich_grants, _ensure_timedelta_cols, _coerce_date_columns\n",
    "from reporting.quarterly_report.utils import Database, RenderContext\n",
    "\n",
    "\n",
    "import altair as alt\n",
    "from altair_saver import save\n",
    "import selenium.webdriver\n",
    "\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 2) open DB – change path if you work on a copy\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "db_path = \"database/reporting.db\"\n",
    "DB_PATH = Path(\"database/reporting.db\")\n",
    "\n",
    "init_db(db_path=DB_PATH)            # no-op if tables already exist\n",
    "\n",
    "db = Database(str(DB_PATH))         # thin sqlite3 wrapper\n",
    "conn = db.conn\n",
    "report = 'Quarterly_Report'\n",
    "\n",
    "CALLS_TYPES_LIST = ['STG', 'ADG', 'POC', 'COG', 'SYG', 'StG', 'CoG', 'AdG', 'SyG', 'PoC', 'CSA']\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# HELPERS\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "def determine_epoch_year(cutoff_date: pd.Timestamp) -> int:\n",
    "    \"\"\"\n",
    "    Returns the correct reporting year.\n",
    "    If the cutoff is in January, then we are reporting for the *previous* year.\n",
    "    \"\"\"\n",
    "    return cutoff_date.year - 1 if cutoff_date.month == 1 else cutoff_date.year\n",
    "\n",
    "\n",
    "\n",
    "def get_scope_start_end(cutoff: pd.Timestamp) -> Tuple[pd.Timestamp, pd.Timestamp]:\n",
    "    \"\"\"\n",
    "    Unified scope logic with year transition:\n",
    "    • If cutoff is in January → report full previous year\n",
    "    • Otherwise → return start of year to quarter-end\n",
    "    \"\"\"\n",
    "    if cutoff.month == 1:\n",
    "        year = cutoff.year - 1\n",
    "        return pd.Timestamp(year=year, month=1, day=1), pd.Timestamp(year=year, month=12, day=31)\n",
    "\n",
    "    def quarter_end(cutoff: pd.Timestamp) -> pd.Timestamp:\n",
    "        first_day = cutoff.replace(day=1)\n",
    "        last_month = first_day - pd.offsets.MonthBegin()\n",
    "        m = last_month.month\n",
    "\n",
    "        if m <= 3:\n",
    "            return pd.Timestamp(year=cutoff.year, month=3, day=31)\n",
    "        elif m <= 6:\n",
    "            return pd.Timestamp(year=cutoff.year, month=6, day=30)\n",
    "        elif m <= 9:\n",
    "            return pd.Timestamp(year=cutoff.year, month=9, day=30)\n",
    "        else:\n",
    "            return pd.Timestamp(year=cutoff.year, month=12, day=31)\n",
    "\n",
    "    return pd.Timestamp(year=cutoff.year, month=1, day=1), quarter_end(cutoff)\n",
    "\n",
    "\n",
    "\n",
    "def months_in_scope(cutoff: pd.Timestamp) -> list[str]:\n",
    "    \"\"\"\n",
    "    Returns list of month names from January to last *full* month before cutoff.\n",
    "    Handles year rollover if cutoff is in January.\n",
    "    \"\"\"\n",
    "    if cutoff.month == 1:\n",
    "        year = cutoff.year - 1\n",
    "        end_month = 12\n",
    "    else:\n",
    "        year = cutoff.year\n",
    "        end_month = cutoff.month - 1\n",
    "\n",
    "    months = pd.date_range(\n",
    "        start=pd.Timestamp(year=year, month=1, day=1),\n",
    "        end=pd.Timestamp(year=year, month=end_month, day=1),\n",
    "        freq=\"MS\"\n",
    "    ).strftime(\"%B\").tolist()\n",
    "\n",
    "    return months\n",
    "\n",
    "def determine_po_category(row):\n",
    "\n",
    "    instrument = str(row.get('Instrument', '')).strip()\n",
    "    topic = str(row.get('Topic', '')).strip()\n",
    "\n",
    "    try:\n",
    "        if topic and any(call_type in topic for call_type in CALLS_TYPES_LIST):\n",
    "            category = next(call_type for call_type in CALLS_TYPES_LIST if call_type in topic).upper()\n",
    "            return category\n",
    "        elif instrument and any(call_type in instrument for call_type in CALLS_TYPES_LIST):\n",
    "            category = next(call_type for call_type in CALLS_TYPES_LIST if call_type in instrument).upper()\n",
    "            return category\n",
    "        return ''\n",
    "    except Exception as e:\n",
    "        raise\n",
    "\n",
    "def determine_po_category_po_list(row):\n",
    "\n",
    "    summa = str(row.get('PO Purchase Order Item Desc', '')).strip()\n",
    "    abac = str(row.get('PO ABAC SAP Reference', '')).strip()\n",
    "\n",
    "    try:\n",
    "        if summa and any(call_type in summa for call_type in CALLS_TYPES_LIST):\n",
    "            category = next(call_type for call_type in CALLS_TYPES_LIST if call_type in summa).upper()\n",
    "            return category\n",
    "        elif abac and any(call_type in abac for call_type in CALLS_TYPES_LIST):\n",
    "            category = next(call_type for call_type in CALLS_TYPES_LIST if call_type in abac).upper()\n",
    "            return category\n",
    "        return ''\n",
    "    except Exception as e:\n",
    "        raise\n",
    "\n",
    "def extract_project_number(row):\n",
    "    \"\"\"\n",
    "    Extract project number from 'Inv Text' if 'v_check_payment_type' contains RP patterns,\n",
    "    otherwise return original 'v_check_payment_type' value\n",
    "    \"\"\"\n",
    "    payment_type = row['v_check_payment_type']\n",
    "    inv_text = row['Inv Text']\n",
    "    \n",
    "    # Handle NaN values\n",
    "    if pd.isna(payment_type):\n",
    "        return payment_type\n",
    "    \n",
    "    # Convert to string to handle any data type\n",
    "    payment_type_str = str(payment_type)\n",
    "    \n",
    "    # Check if the payment_type contains RP patterns:\n",
    "    # - Original pattern: RP + number + = + FP/IP (e.g., RP4=FP, RP2=IP)\n",
    "    # - New pattern: RP + number + - + FP/IP (e.g., RP4-FP, RP2-IP)\n",
    "    rp_patterns = [\n",
    "        r'RP\\d+=(?:FP|IP)',  # Original pattern: RP4=FP, RP2=IP, etc.\n",
    "        r'RP\\d+-(?:FP|IP)'   # New pattern: RP4-FP, RP2-IP, etc.\n",
    "    ]\n",
    "    \n",
    "    # Check if any of the RP patterns match\n",
    "    has_rp_pattern = any(re.search(pattern, payment_type_str) for pattern in rp_patterns)\n",
    "    \n",
    "    if has_rp_pattern:\n",
    "        # Extract the numerical part from Inv Text column\n",
    "        if pd.notna(inv_text):\n",
    "            inv_text_str = str(inv_text).strip()\n",
    "            # Extract leading digits from Inv Text\n",
    "            number_match = re.match(r'^(\\d+)', inv_text_str)\n",
    "            if number_match:\n",
    "                return number_match.group(1)\n",
    "        \n",
    "        # If no number found in Inv Text, return original payment_type\n",
    "        return payment_type\n",
    "    \n",
    "    # Return original v_check_payment_type if no RP pattern found\n",
    "    return payment_type\n",
    "\n",
    "\n",
    "def map_project_to_call_type(project_num, mapping_dict):\n",
    "    # If it's a numeric string, try to convert and lookup\n",
    "    try:\n",
    "        # Try to convert to int for lookup\n",
    "        numeric_key = int(project_num)\n",
    "        if numeric_key in mapping_dict:\n",
    "            return mapping_dict[numeric_key]\n",
    "    except (ValueError, TypeError):\n",
    "        # If conversion fails, it's a non-numeric string like 'EXPERTS'\n",
    "        pass\n",
    "    \n",
    "    # Return original value if no match found\n",
    "    return project_num\n",
    "\n",
    "def map_call_type_with_experts(row, grant_map):\n",
    "    \"\"\"\n",
    "    Map call_type based on project_number and Inv Parking Person Id\n",
    "    \"\"\"\n",
    "    project_num = row['project_number']\n",
    "    contract_type = row['v_payment_type']\n",
    "    \n",
    "    # First, try to map using grant_map (convert project_num to int if possible)\n",
    "    try:\n",
    "        numeric_key = int(project_num)\n",
    "        if numeric_key in grant_map:\n",
    "            return grant_map[numeric_key]\n",
    "    except (ValueError, TypeError):\n",
    "        pass\n",
    "    \n",
    "    # If project_number is 'EXPERTS', keep it as 'EXPERTS'\n",
    "    if str(project_num).upper() == 'EXPERTS' or str(contract_type).upper() == 'EXPERTS':\n",
    "        return 'EXPERTS'\n",
    "    \n",
    "    # Return original project_number if no conditions are met\n",
    "    return project_num\n",
    "\n",
    "def map_payment_type(row):\n",
    "    if row['v_payment_type'] == 'Other' and row['Pay Workflow Last AOS Person Id'] == 'WALASOU':\n",
    "        return 'EXPERTS'\n",
    "    return row['v_payment_type']\n",
    "\n",
    "# Instead, handle conversion in the mapping function\n",
    "def safe_map_project_to_call_type(project_num, mapping_dict):\n",
    "    \"\"\"\n",
    "    Maps project number to call type, handles all data type issues internally\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Handle NaN values\n",
    "        if pd.isna(project_num):\n",
    "            return None\n",
    "            \n",
    "        # Convert whatever format to integer for lookup\n",
    "        if isinstance(project_num, str):\n",
    "            # Handle strings like '4500053782.0'\n",
    "            if project_num.endswith('.0'):\n",
    "                numeric_key = int(project_num[:-2])\n",
    "            else:\n",
    "                numeric_key = int(float(project_num))\n",
    "        else:\n",
    "            # Handle numeric values (float/int)\n",
    "            numeric_key = int(float(project_num))\n",
    "            \n",
    "        # Lookup in mapping dictionary\n",
    "        if numeric_key in mapping_dict:\n",
    "            result = mapping_dict[numeric_key]\n",
    "            if pd.notna(result) and result != '':\n",
    "                return result\n",
    "                \n",
    "    except (ValueError, TypeError, OverflowError):\n",
    "        # Any conversion error, return None\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Apply mapping without converting the whole column\n",
    "def apply_conditional_mapping(row):\n",
    "    current_call_type = row['call_type']\n",
    "    po_key = row['PO Purchase Order Key']  # Use as-is, no conversion\n",
    "    \n",
    "    should_map = (\n",
    "        pd.isna(current_call_type) or \n",
    "        current_call_type == '' or \n",
    "        current_call_type not in CALLS_TYPES_LIST or \n",
    "        current_call_type in ['EXPERTS', 'CSA']\n",
    "    )\n",
    "    \n",
    "    if should_map:\n",
    "        mapped_value = safe_map_project_to_call_type(po_key, po_map)\n",
    "        return mapped_value if mapped_value is not None else current_call_type\n",
    "    else:\n",
    "        return current_call_type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7118e737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Fetching latest data for table_alias: payments_summa, cutoff: 2025-06-01T00:00:00\n",
      "DEBUG:root:Upload log query results for payments_summa: [('2025-06-04T09:38:45.291982', 16)]\n",
      "DEBUG:root:Checking upload_id: 16, uploaded_at: 2025-06-04T09:38:45.291982\n",
      "DEBUG:root:Fetched 6391 rows from payments_summa with upload_id 16\n",
      "DEBUG:root:Fetching latest data for table_alias: payments_summa_time, cutoff: 2025-06-01T00:00:00\n",
      "DEBUG:root:Upload log query results for payments_summa_time: [('2025-06-04T09:39:00.815408', 17)]\n",
      "DEBUG:root:Checking upload_id: 17, uploaded_at: 2025-06-04T09:39:00.815408\n",
      "DEBUG:root:Fetched 4992 rows from payments_summa_time with upload_id 17\n",
      "DEBUG:root:Fetching latest data for table_alias: call_overview, cutoff: 2025-06-01T00:00:00\n",
      "DEBUG:root:Upload log query results for call_overview: [('2025-06-04T09:43:14.796908', 18)]\n",
      "DEBUG:root:Checking upload_id: 18, uploaded_at: 2025-06-04T09:43:14.796908\n",
      "DEBUG:root:Fetched 13295 rows from call_overview with upload_id 18\n",
      "DEBUG:root:Fetching latest data for table_alias: c0_po_summa, cutoff: 2025-06-01T00:00:00\n",
      "DEBUG:root:Upload log query results for c0_po_summa: [('2025-06-04T09:38:09.286923', 15)]\n",
      "DEBUG:root:Checking upload_id: 15, uploaded_at: 2025-06-04T09:38:09.286923\n",
      "DEBUG:root:Fetched 16309 rows from c0_po_summa with upload_id 15\n",
      "DEBUG:root:Fetching latest data for table_alias: forecast, cutoff: 2025-06-01T00:00:00\n",
      "DEBUG:root:Upload log query results for forecast: [('2025-06-04T16:58:18.396646', 19)]\n",
      "DEBUG:root:Checking upload_id: 19, uploaded_at: 2025-06-04T16:58:18.396646\n",
      "DEBUG:root:Fetched 123 rows from forecast with upload_id 19\n"
     ]
    }
   ],
   "source": [
    "PAYMENTS_ALIAS = \"payments_summa\"\n",
    "CALLS_ALIAS = 'call_overview'\n",
    "PAYMENTS_TIMES_ALIAS = 'payments_summa_time'\n",
    "PO_ALIAS = 'c0_po_summa'\n",
    "FORECAST_ALIAS = 'forecast'\n",
    "\n",
    "cutoff = pd.to_datetime(\"2025-06-01\")\n",
    "report_params = load_report_params(report_name=report, db_path=db_path)\n",
    "\n",
    "\n",
    "table_colors = report_params.get('TABLE_COLORS', {})\n",
    "BLUE = table_colors.get(\"BLUE\", \"#004A99\")\n",
    "LIGHT_BLUE = table_colors.get(\"LIGHT_BLUE\", \"#d6e6f4\")\n",
    "DARK_BLUE = table_colors.get(\"DARK_BLUE\", \"#01244B\")\n",
    "SUB_TOTAL_BACKGROUND = table_colors.get(\"subtotal_background_color\", \"#E6E6FA\")\n",
    "\n",
    "df_paym = fetch_latest_table_data(conn, PAYMENTS_ALIAS, cutoff)\n",
    "df_paym_times = fetch_latest_table_data(conn, PAYMENTS_TIMES_ALIAS, cutoff)\n",
    "df_calls =  fetch_latest_table_data(conn, CALLS_ALIAS , cutoff)\n",
    "df_po = fetch_latest_table_data(conn, PO_ALIAS, cutoff)\n",
    "df_forecast = fetch_latest_table_data(conn, FORECAST_ALIAS, cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5aca135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paym['v_payment_type'] = df_paym.apply(map_payment_type, axis=1)\n",
    "# Filter the dataframe\n",
    "df_paym = df_paym[df_paym['Pay Document Type Desc'].isin(['Payment Directive', 'Exp Pre-financing'])]\n",
    "# Keep all rows where v_payment_type is not 'Other'\n",
    "df_paym = df_paym[df_paym['v_payment_type'] != 'Other']\n",
    "df_paym = df_paym[df_paym['Pay Payment Key'].notnull()]\n",
    "\n",
    "df_paym['project_number'] = df_paym.apply(extract_project_number, axis=1)\n",
    "\n",
    "# Assuming your DataFrame is called 'df'\n",
    "df_calls['CALL_TYPE'] = df_calls.apply(determine_po_category, axis=1)\n",
    "grant_map = df_calls.set_index('Grant Number')['CALL_TYPE'].to_dict()\n",
    "\n",
    "#PO ORDERS MAP\n",
    "df_po['CALL_TYPE']  = df_po.apply(determine_po_category_po_list, axis=1)\n",
    "\n",
    "po_map = df_po[\n",
    "    df_po['CALL_TYPE'].notna() & \n",
    "    (df_po['CALL_TYPE'].str.strip() != '')\n",
    "].set_index('PO Purchase Order Key')['CALL_TYPE'].to_dict()\n",
    "\n",
    "# Apply the mapping\n",
    "df_paym['call_type'] = df_paym['project_number'].apply(lambda x: map_project_to_call_type(x, grant_map))\n",
    "df_paym['call_type'] = df_paym.apply(lambda row: map_call_type_with_experts(row, grant_map), axis=1)\n",
    "\n",
    "\n",
    "# Clean call_type column only (not PO keys)\n",
    "df_paym['call_type'] = df_paym['call_type'].astype(str).str.strip().replace(['nan', ''], np.nan)\n",
    "# Apply the mapping\n",
    "df_paym['call_type'] = df_paym.apply(apply_conditional_mapping, axis=1)\n",
    "# This preserves NaN values as NaN instead of causing errors\n",
    "df_paym['PO Purchase Order Key'] = pd.to_numeric(df_paym['PO Purchase Order Key'], errors='coerce').astype('Int64')\n",
    "\n",
    "df_paym['Pay Document Date (dd/mm/yyyy)'] = pd.to_datetime(\n",
    "    df_paym['Pay Document Date (dd/mm/yyyy)'], \n",
    "    format='%Y-%m-%d %H:%M:%S',\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "last_valid_date = quarter_dates[1]\n",
    "\n",
    "df_paym = df_paym[\n",
    "    df_paym['Pay Document Date (dd/mm/yyyy)'] <= last_valid_date\n",
    "].copy()\n",
    "\n",
    "df_paym = df_paym[df_paym['call_type'] != 'CSA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5229e893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 1: Creating v_payment_in_time column ===\n",
      "v_payment_in_time value counts:\n",
      "v_payment_in_time\n",
      "1    4776\n",
      "0     216\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Original flag vs new column:\n",
      "Pay Delay Late Payment Flag (Y/N)  v_payment_in_time\n",
      "N                                  1                    4776\n",
      "Y                                  0                     216\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== STEP 2: Creating payment mappings ===\n",
      "Payment key conversions - Success: 4992, Failed: 0\n",
      "Payment times data: 4992 total rows, 4992 usable for mapping\n",
      "TTP Gross mapping created: 4992 entries\n",
      "TTP Net mapping created: 4992 entries\n",
      "Payment in time mapping created: 4992 entries\n",
      "\n",
      "=== STEP 3: Split, Map, and Merge Strategy ===\n",
      "Rows with 'Exp Pre-financing': 581\n",
      "Rows with 'Payment Directive': 4309\n",
      "Other document types: 0\n",
      "Total rows in df_paym: 4890\n",
      "\n",
      "Dataframes split:\n",
      "- Exp Pre-financing: 581 rows\n",
      "- Payment Directive: 4309 rows\n",
      "- Other types: 0 rows\n",
      "\n",
      "Applying mappings to Exp Pre-financing dataframe...\n",
      "Mapping applied to Exp Pre-financing rows!\n",
      "Sample mapped rows:\n",
      "      Pay Payment Key Pay Document Type Desc  v_TTP_GROSS  v_TTP_NET  \\\n",
      "1699       2551003753      Exp Pre-financing           29         29   \n",
      "1700       2551003714      Exp Pre-financing           29         29   \n",
      "1701       2551003700      Exp Pre-financing           29         29   \n",
      "1702       2551003698      Exp Pre-financing           29         29   \n",
      "1703       2551003763      Exp Pre-financing           29         29   \n",
      "\n",
      "      v_payment_in_time  \n",
      "1699                  1  \n",
      "1700                  1  \n",
      "1701                  1  \n",
      "1702                  1  \n",
      "1703                  1  \n",
      "\n",
      "Preserving Payment Directive dataframe completely...\n",
      "v_TTP_GROSS already exists in Payment Directive - preserving original values\n",
      "v_TTP_NET already exists in Payment Directive - preserving original values\n",
      "v_payment_in_time already exists in Payment Directive - preserving original values\n",
      "Payment Directive rows completely preserved!\n",
      "\n",
      "Merging dataframes back together...\n",
      "Dataframes merged successfully! Final shape: (4890, 52)\n",
      "\n",
      "=== STEP 4: Results ===\n",
      "v_TTP_GROSS value counts:\n",
      "v_TTP_GROSS\n",
      "14.0     325\n",
      "6.0      316\n",
      "9.0      256\n",
      "7.0      256\n",
      "16.0     254\n",
      "        ... \n",
      "165.0      1\n",
      "119.0      1\n",
      "157.0      1\n",
      "232.0      1\n",
      "134.0      1\n",
      "Name: count, Length: 224, dtype: int64\n",
      "\n",
      "v_TTP_NET value counts:\n",
      "v_TTP_NET\n",
      "14     340\n",
      "6      320\n",
      "9      269\n",
      "7      264\n",
      "16     257\n",
      "      ... \n",
      "257      1\n",
      "91       1\n",
      "407      1\n",
      "89       1\n",
      "232      1\n",
      "Name: count, Length: 146, dtype: int64\n",
      "\n",
      "v_payment_in_time value counts:\n",
      "v_payment_in_time\n",
      "1    4181\n",
      "1     579\n",
      "0     128\n",
      "0       2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of mapped rows:\n",
      "      Pay Payment Key Pay Document Type Desc  v_TTP_GROSS  v_TTP_NET  \\\n",
      "1699       2552009667      Payment Directive         15.0         15   \n",
      "1700       2552009645      Payment Directive         14.0         14   \n",
      "1701       2552010543      Payment Directive         14.0         14   \n",
      "1702       2552009481      Payment Directive         13.0         13   \n",
      "1703       2552009138      Payment Directive         22.0         22   \n",
      "\n",
      "     v_payment_in_time  \n",
      "1699                 1  \n",
      "1700                 1  \n",
      "1701                 1  \n",
      "1702                 1  \n",
      "1703                 1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinci\\AppData\\Local\\Temp\\ipykernel_32600\\632175654.py:194: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mapped_sample = df_paym[exp_prefi_mask & df_paym['v_TTP_GROSS'].notna()][\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create v_payment_in_time column in df_paym_times\n",
    "print(\"=== STEP 1: Creating v_payment_in_time column ===\")\n",
    "\n",
    "# Convert Pay Delay Late Payment Flag (Y/N) to 1/0\n",
    "df_paym_times['v_payment_in_time'] = df_paym_times['Pay Delay Late Payment Flag (Y/N)'].apply(\n",
    "    lambda x: 1 if x == 'N' else 0\n",
    ")\n",
    "\n",
    "print(\"v_payment_in_time value counts:\")\n",
    "print(df_paym_times['v_payment_in_time'].value_counts())\n",
    "print(\"\\nOriginal flag vs new column:\")\n",
    "print(df_paym_times[['Pay Delay Late Payment Flag (Y/N)', 'v_payment_in_time']].value_counts())\n",
    "\n",
    "# Step 2: Clean Pay Payment Key and create mappings\n",
    "print(\"\\n=== STEP 2: Creating payment mappings ===\")\n",
    "\n",
    "# Filter df_paym_times to only include rows we need for mapping\n",
    "df_times_clean = df_paym_times.dropna(subset=['Pay Payment Key']).copy()\n",
    "\n",
    "# Clean Pay Payment Key for mapping (convert to integers)\n",
    "def safe_convert_to_int(value):\n",
    "    \"\"\"Safely convert payment key to integer\"\"\"\n",
    "    try:\n",
    "        if pd.isna(value):\n",
    "            return None\n",
    "        if isinstance(value, str):\n",
    "            # Handle strings like '2551003294.0'\n",
    "            if value.endswith('.0'):\n",
    "                return int(value[:-2])\n",
    "            else:\n",
    "                return int(float(value))\n",
    "        else:\n",
    "            return int(float(value))\n",
    "    except (ValueError, TypeError, OverflowError):\n",
    "        return None\n",
    "\n",
    "# Convert Pay Payment Key to integers for mapping (keep all rows)\n",
    "df_times_clean['Pay_Payment_Key_Int'] = df_times_clean['Pay Payment Key'].apply(safe_convert_to_int)\n",
    "\n",
    "# Count conversion issues but don't drop rows\n",
    "conversion_failed = df_times_clean['Pay_Payment_Key_Int'].isna().sum()\n",
    "conversion_success = df_times_clean['Pay_Payment_Key_Int'].notna().sum()\n",
    "\n",
    "print(f\"Payment key conversions - Success: {conversion_success}, Failed: {conversion_failed}\")\n",
    "\n",
    "# Create mappings only from successfully converted keys (but keep all rows in dataframe)\n",
    "valid_conversions = df_times_clean['Pay_Payment_Key_Int'].notna()\n",
    "mapping_data = df_times_clean[valid_conversions].copy()\n",
    "mapping_data['Pay_Payment_Key_Int'] = mapping_data['Pay_Payment_Key_Int'].astype(int)\n",
    "\n",
    "print(f\"Payment times data: {len(df_times_clean)} total rows, {len(mapping_data)} usable for mapping\")\n",
    "\n",
    "# Create the three mappings (only from rows with valid conversions)\n",
    "payment_key_to_ttp_gross = mapping_data.set_index('Pay_Payment_Key_Int')['Pay Delay With Suspension'].to_dict()\n",
    "payment_key_to_ttp_net = mapping_data.set_index('Pay_Payment_Key_Int')['Pay Delay Without Suspension'].to_dict()\n",
    "payment_key_to_payment_in_time = mapping_data.set_index('Pay_Payment_Key_Int')['v_payment_in_time'].to_dict()\n",
    "\n",
    "print(f\"TTP Gross mapping created: {len(payment_key_to_ttp_gross)} entries\")\n",
    "print(f\"TTP Net mapping created: {len(payment_key_to_ttp_net)} entries\")\n",
    "print(f\"Payment in time mapping created: {len(payment_key_to_payment_in_time)} entries\")\n",
    "\n",
    "# Step 3: Split dataframe and apply mappings selectively\n",
    "print(\"\\n=== STEP 3: Split, Map, and Merge Strategy ===\")\n",
    "\n",
    "# Check conditions in df_paym\n",
    "exp_prefi_mask = df_paym['Pay Document Type Desc'] == 'Exp Pre-financing'\n",
    "payment_directive_mask = df_paym['Pay Document Type Desc'] == 'Payment Directive'\n",
    "other_mask = ~(exp_prefi_mask | payment_directive_mask)\n",
    "\n",
    "print(f\"Rows with 'Exp Pre-financing': {exp_prefi_mask.sum()}\")\n",
    "print(f\"Rows with 'Payment Directive': {payment_directive_mask.sum()}\")\n",
    "print(f\"Other document types: {other_mask.sum()}\")\n",
    "print(f\"Total rows in df_paym: {len(df_paym)}\")\n",
    "\n",
    "# Step 3.1: Split the dataframe\n",
    "df_exp_prefi = df_paym[exp_prefi_mask].copy()\n",
    "df_payment_directive = df_paym[payment_directive_mask].copy()\n",
    "df_other = df_paym[other_mask].copy()\n",
    "\n",
    "print(f\"\\nDataframes split:\")\n",
    "print(f\"- Exp Pre-financing: {len(df_exp_prefi)} rows\")\n",
    "print(f\"- Payment Directive: {len(df_payment_directive)} rows\")\n",
    "print(f\"- Other types: {len(df_other)} rows\")\n",
    "\n",
    "# Step 3.2: Apply mapping ONLY to Exp Pre-financing dataframe\n",
    "if len(df_exp_prefi) > 0:\n",
    "    print(\"\\nApplying mappings to Exp Pre-financing dataframe...\")\n",
    "    \n",
    "    # Mapping function for payment data\n",
    "    def map_payment_data(pay_key, mapping_dict):\n",
    "        \"\"\"Map payment key to corresponding value\"\"\"\n",
    "        try:\n",
    "            if pd.isna(pay_key):\n",
    "                return np.nan\n",
    "                \n",
    "            # Convert pay_key to int for lookup\n",
    "            if isinstance(pay_key, str):\n",
    "                if pay_key.endswith('.0'):\n",
    "                    numeric_key = int(pay_key[:-2])\n",
    "                else:\n",
    "                    numeric_key = int(float(pay_key))\n",
    "            else:\n",
    "                numeric_key = int(float(pay_key))\n",
    "                \n",
    "            # Lookup in mapping\n",
    "            if numeric_key in mapping_dict:\n",
    "                return mapping_dict[numeric_key]\n",
    "            else:\n",
    "                return np.nan\n",
    "                \n",
    "        except (ValueError, TypeError, OverflowError):\n",
    "            return np.nan\n",
    "    \n",
    "    # Add the three new columns to Exp Pre-financing dataframe ONLY\n",
    "    df_exp_prefi['v_TTP_GROSS'] = df_exp_prefi['Pay Payment Key'].apply(\n",
    "        lambda x: map_payment_data(x, payment_key_to_ttp_gross)\n",
    "    )\n",
    "    \n",
    "    df_exp_prefi['v_TTP_NET'] = df_exp_prefi['Pay Payment Key'].apply(\n",
    "        lambda x: map_payment_data(x, payment_key_to_ttp_net)\n",
    "    )\n",
    "    \n",
    "    df_exp_prefi['v_payment_in_time'] = df_exp_prefi['Pay Payment Key'].apply(\n",
    "        lambda x: map_payment_data(x, payment_key_to_payment_in_time)\n",
    "    )\n",
    "    \n",
    "    print(\"Mapping applied to Exp Pre-financing rows!\")\n",
    "    \n",
    "    # Show sample of what was mapped\n",
    "    sample_mapped = df_exp_prefi[['Pay Payment Key', 'Pay Document Type Desc', 'v_TTP_GROSS', 'v_TTP_NET', 'v_payment_in_time']].head()\n",
    "    print(\"Sample mapped rows:\")\n",
    "    print(sample_mapped)\n",
    "else:\n",
    "    print(\"No Exp Pre-financing rows to map!\")\n",
    "\n",
    "# Step 3.3: Payment Directive dataframe - ADD columns but DON'T change any existing values\n",
    "if len(df_payment_directive) > 0:\n",
    "    print(\"\\nPreserving Payment Directive dataframe completely...\")\n",
    "    \n",
    "    # Check if these columns already exist in Payment Directive rows\n",
    "    if 'v_TTP_GROSS' in df_payment_directive.columns:\n",
    "        print(\"v_TTP_GROSS already exists in Payment Directive - preserving original values\")\n",
    "    else:\n",
    "        # Only add columns if they don't exist, with NaN values\n",
    "        df_payment_directive['v_TTP_GROSS'] = np.nan\n",
    "        \n",
    "    if 'v_TTP_NET' in df_payment_directive.columns:\n",
    "        print(\"v_TTP_NET already exists in Payment Directive - preserving original values\")\n",
    "    else:\n",
    "        df_payment_directive['v_TTP_NET'] = np.nan\n",
    "        \n",
    "    if 'v_payment_in_time' in df_payment_directive.columns:\n",
    "        print(\"v_payment_in_time already exists in Payment Directive - preserving original values\")\n",
    "    else:\n",
    "        df_payment_directive['v_payment_in_time'] = np.nan\n",
    "    \n",
    "    print(\"Payment Directive rows completely preserved!\")\n",
    "\n",
    "# Step 3.4: Handle other document types\n",
    "if len(df_other) > 0:\n",
    "    print(\"Adding columns to other document types with NaN values...\")\n",
    "    df_other['v_TTP_GROSS'] = np.nan\n",
    "    df_other['v_TTP_NET'] = np.nan\n",
    "    df_other['v_payment_in_time'] = np.nan\n",
    "\n",
    "# Step 3.5: Merge all dataframes back together\n",
    "print(\"\\nMerging dataframes back together...\")\n",
    "\n",
    "dataframes_to_merge = []\n",
    "if len(df_exp_prefi) > 0:\n",
    "    dataframes_to_merge.append(df_exp_prefi)\n",
    "if len(df_payment_directive) > 0:\n",
    "    dataframes_to_merge.append(df_payment_directive)\n",
    "if len(df_other) > 0:\n",
    "    dataframes_to_merge.append(df_other)\n",
    "\n",
    "if dataframes_to_merge:\n",
    "    df_paym = pd.concat(dataframes_to_merge, ignore_index=True)\n",
    "    print(f\"Dataframes merged successfully! Final shape: {df_paym.shape}\")\n",
    "else:\n",
    "    print(\"Warning: No dataframes to merge!\")\n",
    "\n",
    "# Step 4: Check results\n",
    "print(\"\\n=== STEP 4: Results ===\")\n",
    "print(\"v_TTP_GROSS value counts:\")\n",
    "print(df_paym['v_TTP_GROSS'].value_counts(dropna=False))\n",
    "print(\"\\nv_TTP_NET value counts:\")\n",
    "print(df_paym['v_TTP_NET'].value_counts(dropna=False))\n",
    "print(\"\\nv_payment_in_time value counts:\")\n",
    "print(df_paym['v_payment_in_time'].value_counts(dropna=False))\n",
    "\n",
    "# Show sample of mapped rows\n",
    "print(\"\\nSample of mapped rows:\")\n",
    "mapped_sample = df_paym[exp_prefi_mask & df_paym['v_TTP_GROSS'].notna()][\n",
    "    ['Pay Payment Key', 'Pay Document Type Desc', 'v_TTP_GROSS', 'v_TTP_NET', 'v_payment_in_time']\n",
    "].head()\n",
    "print(mapped_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7224e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paym.to_excel('paym.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e86486e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== HOW TO USE THE QUARTERLY TABLES (Two Format Options) ===\n",
      "\n",
      "1. GENERATE TABLES:\n",
      "   quarterly_tables = generate_all_quarterly_tables(df_paym, cutoff)\n",
      "\n",
      "2. ACCESS INDIVIDUAL PAYMENT TYPE TABLES:\n",
      "\n",
      "   # OPTION A: Repeated quarters (RECOMMENDED for great_tables)\n",
      "   heu_prefinancing = get_great_table(quarterly_tables, 'HEU', 'Pre-financing', repeat_quarter=True)\n",
      "   heu_interim = get_great_table(quarterly_tables, 'HEU', 'Interim Payments', repeat_quarter=True)\n",
      "\n",
      "   # OPTION B: Grouped quarters (Excel visual style)\n",
      "   heu_prefinancing_grouped = get_great_table(quarterly_tables, 'HEU', 'Pre-financing', repeat_quarter=False)\n",
      "\n",
      "   # Shortcut functions:\n",
      "   heu_prefinancing = get_great_table_repeated(quarterly_tables, 'HEU', 'Pre-financing')  # Same as Option A\n",
      "   heu_prefinancing_grouped = get_great_table_grouped(quarterly_tables, 'HEU', 'Pre-financing')  # Same as Option B\n",
      "\n",
      "3. ACCESS SUMMARY TABLES (ALL PAYMENT TYPES INCLUDING EXPERTS):\n",
      "\n",
      "   # Summary table with repeated quarters (recommended for great_tables)\n",
      "   heu_summary = get_summary_table(quarterly_tables, 'HEU', repeat_quarter=True)\n",
      "\n",
      "   # Summary table with grouped quarters (Excel visual style)\n",
      "   heu_summary_grouped = get_summary_table(quarterly_tables, 'HEU', repeat_quarter=False)\n",
      "\n",
      "   # Alternative access\n",
      "   heu_summary_alt = create_comprehensive_summary_table(quarterly_tables, 'HEU', repeat_quarter=True)\n",
      "\n",
      "   # Quick comparison table (different format - just totals by payment type)\n",
      "   heu_comparison = create_payment_type_comparison_table(quarterly_tables, 'HEU')\n",
      "\n",
      "4. LIST ALL AVAILABLE TABLES:\n",
      "   list_available_tables(quarterly_tables)\n",
      "\n",
      "5. USE WITH GREAT_TABLES:\n",
      "   from great_tables import GT\n",
      "\n",
      "   # Individual payment type (using repeated format)\n",
      "   gt_table = (\n",
      "       GT(heu_prefinancing)\n",
      "       .tab_header(title=\"HEU Pre-financing\", subtitle=\"Q1 2025\")\n",
      "       .fmt_currency(columns=['ADG', 'COG', 'POC', 'STG', 'SYG', 'Total'], currency='EUR')\n",
      "       .tab_row_group(label=\"2024Q1\", rows=[\"2024Q1\"])  # Can group by Quarter if using repeated format\n",
      "   )\n",
      "\n",
      "FORMAT OPTIONS:\n",
      "\n",
      "OPTION A - Repeated Quarters (RECOMMENDED for great_tables):\n",
      "Quarter | Metric                  | ADG | COG | POC | STG | SYG | Total\n",
      "2024Q1  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
      "2024Q1  | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
      "2024Q1  | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
      "2024Q2  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
      "2024Q2  | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
      "2024Q2  | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
      "\n",
      "OPTION B - Grouped Quarters (Excel visual style):\n",
      "Quarter | Metric                  | ADG | COG | POC | STG | SYG | Total\n",
      "2024Q1  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
      "        | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
      "        | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
      "2024Q2  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
      "        | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
      "        | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
      "\n",
      "RECOMMENDATION:\n",
      "✅ Use repeat_quarter=True (Option A) for great_tables - better for:\n",
      "  - Data processing and filtering\n",
      "  - Row grouping operations\n",
      "  - Exporting to other formats\n",
      "  - Table manipulation\n",
      "\n",
      "Use repeat_quarter=False (Option B) for:\n",
      "  - Pure visual presentation matching Excel\n",
      "  - When you want minimal visual clutter\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "=== SUMMARY TABLE EXAMPLES (Both Format Options) ===\n",
      "\n",
      "# 1a. Summary table with repeated quarters (RECOMMENDED for great_tables)\n",
      "heu_summary = get_summary_table(quarterly_tables, 'HEU', repeat_quarter=True)\n",
      "# Quarter | Metric                  | ADG | COG | POC | STG | SYG | Total\n",
      "# 2024Q1  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
      "# 2024Q1  | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
      "# 2024Q1  | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
      "# Total   | Total Amount            | ... | ... | ... | ... | ... | ...\n",
      "# Total   | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
      "# Total   | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
      "\n",
      "# 1b. Summary table with grouped quarters (Excel visual style)\n",
      "heu_summary_grouped = get_summary_table(quarterly_tables, 'HEU', repeat_quarter=False)\n",
      "# Quarter | Metric                  | ADG | COG | POC | STG | SYG | Total\n",
      "# 2024Q1  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
      "#         | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
      "#         | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
      "# Total   | Total Amount            | ... | ... | ... | ... | ... | ...\n",
      "#         | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
      "#         | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
      "\n",
      "# 2. Quick comparison (different format - by payment type)\n",
      "heu_comparison = create_payment_type_comparison_table(quarterly_tables, 'HEU')\n",
      "# Payment_Type | Total_Amount | VOBU_EFTA_Amount | No_of_Transactions\n",
      "# Pre-financing | 352,568,326 | 336,797,403 | 309\n",
      "# Interim Payments | 185,710,686 | 175,320,845 | 115\n",
      "# TOTAL ALL TYPES | 1,628,225,910 | 1,398,938,052 | 1,573\n",
      "\n",
      "BOTH formats contain the same data, just different visual presentation!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from typing import Tuple\n",
    "\n",
    "# Existing periodicity functions\n",
    "def determine_epoch_year(cutoff_date: pd.Timestamp) -> int:\n",
    "    \"\"\"\n",
    "    Returns the correct reporting year.\n",
    "    If the cutoff is in January, then we are reporting for the *previous* year.\n",
    "    \"\"\"\n",
    "    return cutoff_date.year - 1 if cutoff_date.month == 1 else cutoff_date.year\n",
    "\n",
    "def get_scope_start_end(cutoff: pd.Timestamp) -> Tuple[pd.Timestamp, pd.Timestamp]:\n",
    "    \"\"\"\n",
    "    Unified scope logic with year transition:\n",
    "    • If cutoff is in January → report full previous year\n",
    "    • Otherwise → return start of year to quarter-end\n",
    "    \"\"\"\n",
    "    if cutoff.month == 1:\n",
    "        year = cutoff.year - 1\n",
    "        return pd.Timestamp(year=year, month=1, day=1), pd.Timestamp(year=year, month=12, day=31)\n",
    "\n",
    "    def quarter_end(cutoff: pd.Timestamp) -> pd.Timestamp:\n",
    "        first_day = cutoff.replace(day=1)\n",
    "        last_month = first_day - pd.offsets.MonthBegin()\n",
    "        m = last_month.month\n",
    "\n",
    "        if m <= 3:\n",
    "            return pd.Timestamp(year=cutoff.year, month=3, day=31)\n",
    "        elif m <= 6:\n",
    "            return pd.Timestamp(year=cutoff.year, month=6, day=30)\n",
    "        elif m <= 9:\n",
    "            return pd.Timestamp(year=cutoff.year, month=9, day=30)\n",
    "        else:\n",
    "            return pd.Timestamp(year=cutoff.year, month=12, day=31)\n",
    "\n",
    "    return pd.Timestamp(year=cutoff.year, month=1, day=1), quarter_end(cutoff)\n",
    "\n",
    "def months_in_scope(cutoff: pd.Timestamp) -> list[str]:\n",
    "    \"\"\"\n",
    "    Returns list of month names from January to last *full* month before cutoff.\n",
    "    Handles year rollover if cutoff is in January.\n",
    "    \"\"\"\n",
    "    if cutoff.month == 1:\n",
    "        year = cutoff.year - 1\n",
    "        end_month = 12\n",
    "    else:\n",
    "        year = cutoff.year\n",
    "        end_month = cutoff.month - 1\n",
    "\n",
    "    months = pd.date_range(\n",
    "        start=pd.Timestamp(year=year, month=1, day=1),\n",
    "        end=pd.Timestamp(year=year, month=end_month, day=1),\n",
    "        freq=\"MS\"\n",
    "    ).strftime(\"%B\").tolist()\n",
    "\n",
    "    return months\n",
    "\n",
    "def create_quarterly_payment_tables(df_paym, cutoff_date=None):\n",
    "    \"\"\"\n",
    "    Create quarterly payment tables matching the format from the Excel file\n",
    "    - Amount summing: All v_amount_to_sum per payment key, regrouped by fund source\n",
    "    - Number of payments: Count unique Pay Payment Key occurrences (deduplicated)\n",
    "    - Assumes df_paym is already filtered for the correct time scope\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== QUARTERLY PAYMENT TABLES GENERATION ===\")\n",
    "    \n",
    "    # Step 1: Set cutoff date for metadata\n",
    "    if cutoff_date is None:\n",
    "        cutoff_date = pd.Timestamp.now()\n",
    "    elif isinstance(cutoff_date, str):\n",
    "        cutoff_date = pd.Timestamp(cutoff_date)\n",
    "    \n",
    "    print(f\"Cutoff date: {cutoff_date}\")\n",
    "    \n",
    "    # Step 2: Get reporting metadata (for reference)\n",
    "    reporting_year = determine_epoch_year(cutoff_date)\n",
    "    scope_start, scope_end = get_scope_start_end(cutoff_date)\n",
    "    months_in_report = months_in_scope(cutoff_date)\n",
    "    \n",
    "    print(f\"Reporting year: {reporting_year}\")\n",
    "    print(f\"Expected scope: {scope_start} to {scope_end}\")\n",
    "    print(f\"Note: Assuming df_paym is already filtered for this scope\")\n",
    "    \n",
    "    # Step 3: Validate required columns\n",
    "    required_columns = [\n",
    "        'Pay Payment Key', \n",
    "        'v_amount_to_sum', \n",
    "        'Fund Source',\n",
    "        'v_payment_type', \n",
    "        'Pay Document Date (dd/mm/yyyy)',\n",
    "        'Programme'\n",
    "    ]\n",
    "    \n",
    "    # Check for optional call_type column\n",
    "    optional_columns = ['call_type', 'Call Type', 'v_call_type']\n",
    "    call_type_col = None\n",
    "    for col in optional_columns:\n",
    "        if col in df_paym.columns:\n",
    "            call_type_col = col\n",
    "            print(f\"Found call type column: {col}\")\n",
    "            break\n",
    "    \n",
    "    if call_type_col:\n",
    "        required_columns.append(call_type_col)\n",
    "    else:\n",
    "        print(\"No call_type column found - will use Fund Source only\")\n",
    "    \n",
    "    missing_columns = [col for col in required_columns if col not in df_paym.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"ERROR: Missing required columns: {missing_columns}\")\n",
    "        return None\n",
    "    \n",
    "    print(\"✓ All required columns present\")\n",
    "    \n",
    "    # Step 4: Create working dataframe (skip date filtering since already done)\n",
    "    df_work = df_paym[required_columns].copy()\n",
    "    \n",
    "    # Check for any remaining invalid dates\n",
    "    invalid_dates = df_work['Pay Document Date (dd/mm/yyyy)'].isna().sum()\n",
    "    if invalid_dates > 0:\n",
    "        print(f\"WARNING: {invalid_dates} rows with invalid dates found, removing them\")\n",
    "        df_work = df_work.dropna(subset=['Pay Document Date (dd/mm/yyyy)'])\n",
    "    \n",
    "    print(f\"Working dataset: {len(df_work)} rows\")\n",
    "    \n",
    "    if len(df_work) == 0:\n",
    "        print(\"ERROR: No data available after validation\")\n",
    "        return None\n",
    "    \n",
    "    # Create quarter and year columns\n",
    "    df_work['Quarter'] = df_work['Pay Document Date (dd/mm/yyyy)'].dt.to_period('Q')\n",
    "    df_work['Year'] = df_work['Pay Document Date (dd/mm/yyyy)'].dt.year\n",
    "    df_work['Quarter_Label'] = df_work['Quarter'].astype(str)\n",
    "    \n",
    "    print(f\"Actual date range: {df_work['Pay Document Date (dd/mm/yyyy)'].min()} to {df_work['Pay Document Date (dd/mm/yyyy)'].max()}\")\n",
    "    print(f\"Quarters found: {sorted(df_work['Quarter_Label'].unique())}\")\n",
    "    \n",
    "    # Step 5: Map payment types and fund sources\n",
    "    payment_type_mapping = {\n",
    "        'IP': 'Interim Payments',\n",
    "        'FP': 'Final Payments', \n",
    "        'PF': 'Pre-financing',\n",
    "        'EXPERTS': 'Experts and Support'\n",
    "    }\n",
    "    \n",
    "    # Keep original fund sources for now (don't map to C1/E0 yet)\n",
    "    df_work['Payment_Type_Desc'] = df_work['v_payment_type'].map(payment_type_mapping)\n",
    "    \n",
    "    # Use call_type if available, otherwise use Fund Source\n",
    "    if call_type_col:\n",
    "        df_work['Call_Type_Display'] = df_work[call_type_col]\n",
    "        print(f\"Call types found: {sorted(df_work['Call_Type_Display'].unique())}\")\n",
    "    else:\n",
    "        df_work['Call_Type_Display'] = df_work['Fund Source']\n",
    "        print(f\"Using Fund Source as call type: {sorted(df_work['Call_Type_Display'].unique())}\")\n",
    "    \n",
    "    # Handle unmapped payment types\n",
    "    unmapped_payments = df_work[df_work['Payment_Type_Desc'].isna()]['v_payment_type'].unique()\n",
    "    if len(unmapped_payments) > 0:\n",
    "        print(f\"WARNING: Unmapped payment types found: {unmapped_payments}\")\n",
    "        # Keep unmapped ones with their original value\n",
    "        df_work['Payment_Type_Desc'] = df_work['Payment_Type_Desc'].fillna(df_work['v_payment_type'])\n",
    "    \n",
    "    # Step 6: Split by Programme (H2020 and HEU)\n",
    "    programmes = df_work['Programme'].unique()\n",
    "    print(f\"Programmes found: {programmes}\")\n",
    "    \n",
    "    results = {\n",
    "        'metadata': {\n",
    "            'cutoff_date': cutoff_date,\n",
    "            'reporting_year': reporting_year,\n",
    "            'scope_start': scope_start,\n",
    "            'scope_end': scope_end,\n",
    "            'months_in_scope': months_in_report,\n",
    "            'actual_date_range': {\n",
    "                'start': df_work['Pay Document Date (dd/mm/yyyy)'].min(),\n",
    "                'end': df_work['Pay Document Date (dd/mm/yyyy)'].max()\n",
    "            },\n",
    "            'call_type_column': call_type_col,\n",
    "            'has_call_types': call_type_col is not None\n",
    "        },\n",
    "        'tables': {}\n",
    "    }\n",
    "    \n",
    "    for programme in programmes:\n",
    "        if programme not in ['H2020', 'HEU']:\n",
    "            print(f\"Skipping programme: {programme}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n=== Processing {programme} ===\")\n",
    "        df_prog = df_work[df_work['Programme'] == programme].copy()\n",
    "        \n",
    "        if len(df_prog) == 0:\n",
    "            print(f\"No data for {programme}\")\n",
    "            continue\n",
    "        \n",
    "        # Create aggregation tables\n",
    "        tables = create_programme_tables(df_prog, programme, reporting_year)\n",
    "        results['tables'][programme] = tables\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_programme_tables(df_prog, programme_name, reporting_year):\n",
    "    \"\"\"\n",
    "    Create all payment type tables for a specific programme\n",
    "    \"\"\"\n",
    "    \n",
    "    tables = {}\n",
    "    \n",
    "    # Get unique payment types in this programme\n",
    "    payment_types = df_prog['Payment_Type_Desc'].dropna().unique()\n",
    "    \n",
    "    for payment_type in payment_types:\n",
    "        print(f\"  Creating table for: {payment_type}\")\n",
    "        \n",
    "        df_type = df_prog[df_prog['Payment_Type_Desc'] == payment_type].copy()\n",
    "        \n",
    "        if len(df_type) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Create quarterly aggregation\n",
    "        quarterly_table = create_quarterly_aggregation(df_type, payment_type, reporting_year)\n",
    "        tables[payment_type] = quarterly_table\n",
    "    \n",
    "    # Create overall summary table\n",
    "    print(f\"  Creating overall summary table\")\n",
    "    overall_table = create_quarterly_aggregation(df_prog, \"All Payments\", reporting_year)\n",
    "    tables['All_Payments'] = overall_table\n",
    "    \n",
    "    return tables\n",
    "\n",
    "def create_quarterly_aggregation(df_type, payment_type_name, reporting_year):\n",
    "    \"\"\"\n",
    "    Create quarterly aggregation table for a specific payment type\n",
    "    - Amounts: Sum all v_amount_to_sum (including by call type/fund source)\n",
    "    - Transactions: Count unique Pay Payment Key\n",
    "    - VOBU/EFTA: Sum only EFTA and VOBU fund sources\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create base aggregation structure\n",
    "    agg_data = []\n",
    "    \n",
    "    # Get all quarters in the data\n",
    "    quarters = sorted(df_type['Quarter'].unique())\n",
    "    \n",
    "    for quarter in quarters:\n",
    "        df_q = df_type[df_type['Quarter'] == quarter].copy()\n",
    "        \n",
    "        # Get call types for this quarter (using Call_Type_Display)\n",
    "        call_types = df_q['Call_Type_Display'].unique()\n",
    "        \n",
    "        quarter_row = {\n",
    "            'Quarter': str(quarter),\n",
    "            'Quarter_Short': f\"{quarter.quarter}Q{quarter.year}\",\n",
    "            'Year': quarter.year,\n",
    "            'Payment_Type': payment_type_name,\n",
    "            'Reporting_Year': reporting_year\n",
    "        }\n",
    "        \n",
    "        # AMOUNTS: Sum all v_amount_to_sum by call type\n",
    "        total_amount_all_types = 0\n",
    "        vobu_efta_amount_all_types = 0\n",
    "        \n",
    "        for call_type in call_types:\n",
    "            df_call_type = df_q[df_q['Call_Type_Display'] == call_type]\n",
    "            \n",
    "            # Total amount for this call type\n",
    "            total_amount = df_call_type['v_amount_to_sum'].sum()\n",
    "            quarter_row[f'Total_Amount_{call_type}'] = total_amount\n",
    "            total_amount_all_types += total_amount\n",
    "            \n",
    "            # VOBU/EFTA amount: Only sum EFTA and VOBU fund sources\n",
    "            df_vobu_efta = df_call_type[df_call_type['Fund Source'].isin(['VOBU', 'EFTA'])]\n",
    "            vobu_efta_amount = df_vobu_efta['v_amount_to_sum'].sum()\n",
    "            quarter_row[f'VOBU_EFTA_Amount_{call_type}'] = vobu_efta_amount\n",
    "            vobu_efta_amount_all_types += vobu_efta_amount\n",
    "            \n",
    "            # TRANSACTIONS: Count unique Pay Payment Key for this call type\n",
    "            unique_transactions_call_type = df_call_type['Pay Payment Key'].nunique()\n",
    "            quarter_row[f'No_of_Transactions_{call_type}'] = unique_transactions_call_type\n",
    "        \n",
    "        # TRANSACTIONS: Count unique Pay Payment Key (deduplicated across all call types)\n",
    "        unique_transactions = df_q['Pay Payment Key'].nunique()\n",
    "        quarter_row['No_of_Transactions'] = unique_transactions\n",
    "        \n",
    "        # OVERALL TOTALS\n",
    "        quarter_row['Total_Amount'] = total_amount_all_types\n",
    "        quarter_row['VOBU_EFTA_Amount'] = vobu_efta_amount_all_types\n",
    "        \n",
    "        agg_data.append(quarter_row)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df_result = pd.DataFrame(agg_data)\n",
    "    \n",
    "    # Add total row\n",
    "    if len(df_result) > 0:\n",
    "        total_row = create_total_row(df_type, df_result, payment_type_name, reporting_year)\n",
    "        df_result = pd.concat([df_result, total_row], ignore_index=True)\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "def create_total_row(df_type, df_result, payment_type_name, reporting_year):\n",
    "    \"\"\"\n",
    "    Create total row for the aggregation table with VOBU/EFTA logic and transaction counts by call type\n",
    "    \"\"\"\n",
    "    \n",
    "    total_row = {\n",
    "        'Quarter': 'Total',\n",
    "        'Quarter_Short': 'Total',\n",
    "        'Year': reporting_year,\n",
    "        'Payment_Type': payment_type_name,\n",
    "        'Reporting_Year': reporting_year\n",
    "    }\n",
    "    \n",
    "    # Sum all amount columns (exclude Total row if it exists)\n",
    "    df_data_only = df_result[df_result['Quarter'] != 'Total']\n",
    "    \n",
    "    # Sum individual call type amounts\n",
    "    amount_cols = [col for col in df_result.columns if 'Amount' in col and col not in ['Total_Amount', 'VOBU_EFTA_Amount']]\n",
    "    for col in amount_cols:\n",
    "        total_row[col] = df_data_only[col].sum()\n",
    "    \n",
    "    # Calculate VOBU/EFTA total from original data (not summing quarterly totals to avoid double counting)\n",
    "    df_vobu_efta = df_type[df_type['Fund Source'].isin(['VOBU', 'EFTA'])]\n",
    "    total_row['VOBU_EFTA_Amount'] = df_vobu_efta['v_amount_to_sum'].sum()\n",
    "    \n",
    "    # Calculate transaction counts by call type from original data\n",
    "    call_types = df_type['Call_Type_Display'].unique()\n",
    "    for call_type in call_types:\n",
    "        df_call_type = df_type[df_type['Call_Type_Display'] == call_type]\n",
    "        total_row[f'No_of_Transactions_{call_type}'] = df_call_type['Pay Payment Key'].nunique()\n",
    "    \n",
    "    # Overall total amount\n",
    "    total_row['Total_Amount'] = df_type['v_amount_to_sum'].sum()\n",
    "    \n",
    "    # Sum unique transactions across all quarters (deduplicated at total level)\n",
    "    total_row['No_of_Transactions'] = df_type['Pay Payment Key'].nunique()\n",
    "    \n",
    "    return pd.DataFrame([total_row])\n",
    "\n",
    "def format_table_for_great_tables(df_table, payment_type, programme, repeat_quarter=True):\n",
    "    \"\"\"\n",
    "    Format table for great_tables library - creates clean pandas DataFrame\n",
    "    Structure exactly like Excel: Quarter | Metric | ADG | COG | POC | STG | SYG | Total\n",
    "    \n",
    "    Args:\n",
    "        repeat_quarter (bool): If True, repeat quarter value in each row. If False, show only once per group.\n",
    "                              True is recommended for great_tables compatibility.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(df_table) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Separate data rows from total row\n",
    "    df_data = df_table[df_table['Quarter'] != 'Total'].copy()\n",
    "    df_total = df_table[df_table['Quarter'] == 'Total'].copy()\n",
    "    \n",
    "    if len(df_data) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get unique quarters and call types from the data\n",
    "    quarters = sorted(df_data['Quarter_Short'].unique())\n",
    "    \n",
    "    # Extract call type columns from the dataframe\n",
    "    call_type_cols = [col for col in df_data.columns if col.startswith('Total_Amount_') and not col.endswith('Amount')]\n",
    "    call_types = sorted([col.replace('Total_Amount_', '') for col in call_type_cols if col != 'Total_Amount'])\n",
    "    \n",
    "    print(f\"  Formatting for great_tables - Call types: {call_types}, Quarters: {quarters}\")\n",
    "    print(f\"  Quarter repeat mode: {repeat_quarter}\")\n",
    "    \n",
    "    # Create the structure for great_tables - Quarter and Metric as separate columns\n",
    "    table_data = []\n",
    "    \n",
    "    # === PROCESS EACH QUARTER ===\n",
    "    for quarter in quarters:\n",
    "        quarter_data = df_data[df_data['Quarter_Short'] == quarter]\n",
    "        \n",
    "        if len(quarter_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        # ROW 1: Total Amount for this quarter\n",
    "        total_amount_row = {\n",
    "            'Quarter': quarter, \n",
    "            'Metric': 'Total Amount'\n",
    "        }\n",
    "        \n",
    "        for call_type in call_types:\n",
    "            amount_col = f'Total_Amount_{call_type}'\n",
    "            total_amount_row[call_type] = quarter_data[amount_col].iloc[0] if amount_col in quarter_data.columns else 0\n",
    "        \n",
    "        total_amount_row['Total'] = quarter_data['Total_Amount'].iloc[0]\n",
    "        table_data.append(total_amount_row)\n",
    "        \n",
    "        # ROW 2: Out of Which VOBU/EFTA for this quarter\n",
    "        vobu_efta_row = {\n",
    "            'Quarter': quarter if repeat_quarter else '', \n",
    "            'Metric': 'Out of Which VOBU/EFTA'\n",
    "        }\n",
    "        \n",
    "        for call_type in call_types:\n",
    "            vobu_efta_col = f'VOBU_EFTA_Amount_{call_type}'\n",
    "            vobu_efta_row[call_type] = quarter_data[vobu_efta_col].iloc[0] if vobu_efta_col in quarter_data.columns else 0\n",
    "        \n",
    "        vobu_efta_row['Total'] = quarter_data['VOBU_EFTA_Amount'].iloc[0]\n",
    "        table_data.append(vobu_efta_row)\n",
    "        \n",
    "        # ROW 3: No of Transactions for this quarter\n",
    "        transactions_row = {\n",
    "            'Quarter': quarter if repeat_quarter else '', \n",
    "            'Metric': 'No of Transactions'\n",
    "        }\n",
    "        \n",
    "        for call_type in call_types:\n",
    "            transactions_col = f'No_of_Transactions_{call_type}'\n",
    "            transactions_row[call_type] = quarter_data[transactions_col].iloc[0] if transactions_col in quarter_data.columns else 0\n",
    "        \n",
    "        transactions_row['Total'] = quarter_data['No_of_Transactions'].iloc[0]\n",
    "        table_data.append(transactions_row)\n",
    "    \n",
    "    # === TOTAL ROWS (from df_total) ===\n",
    "    if len(df_total) > 0:\n",
    "        \n",
    "        # TOTAL ROW 1: Total Amount\n",
    "        total_amount_row = {\n",
    "            'Quarter': 'Total', \n",
    "            'Metric': 'Total Amount'\n",
    "        }\n",
    "        \n",
    "        for call_type in call_types:\n",
    "            amount_col = f'Total_Amount_{call_type}'\n",
    "            total_amount_row[call_type] = df_total[amount_col].iloc[0] if amount_col in df_total.columns else 0\n",
    "        \n",
    "        total_amount_row['Total'] = df_total['Total_Amount'].iloc[0]\n",
    "        table_data.append(total_amount_row)\n",
    "        \n",
    "        # TOTAL ROW 2: Out of Which VOBU/EFTA\n",
    "        total_vobu_efta_row = {\n",
    "            'Quarter': 'Total' if repeat_quarter else '', \n",
    "            'Metric': 'Out of Which VOBU/EFTA'\n",
    "        }\n",
    "        \n",
    "        for call_type in call_types:\n",
    "            vobu_efta_col = f'VOBU_EFTA_Amount_{call_type}'\n",
    "            total_vobu_efta_row[call_type] = df_total[vobu_efta_col].iloc[0] if vobu_efta_col in df_total.columns else 0\n",
    "        \n",
    "        total_vobu_efta_row['Total'] = df_total['VOBU_EFTA_Amount'].iloc[0]\n",
    "        table_data.append(total_vobu_efta_row)\n",
    "        \n",
    "        # TOTAL ROW 3: No of Transactions\n",
    "        total_transactions_row = {\n",
    "            'Quarter': 'Total' if repeat_quarter else '', \n",
    "            'Metric': 'No of Transactions'\n",
    "        }\n",
    "        \n",
    "        for call_type in call_types:\n",
    "            transactions_col = f'No_of_Transactions_{call_type}'\n",
    "            total_transactions_row[call_type] = df_total[transactions_col].iloc[0] if transactions_col in df_total.columns else 0\n",
    "        \n",
    "        total_transactions_row['Total'] = df_total['No_of_Transactions'].iloc[0]\n",
    "        table_data.append(total_transactions_row)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    great_tables_df = pd.DataFrame(table_data)\n",
    "    \n",
    "    # Reorder columns: Quarter, Metric, then call types in alphabetical order, then Total\n",
    "    column_order = ['Quarter', 'Metric'] + call_types + ['Total']\n",
    "    great_tables_df = great_tables_df[column_order]\n",
    "    \n",
    "    return great_tables_df\n",
    "\n",
    "# Main execution function with periodicity integration\n",
    "def generate_all_quarterly_tables(df_paym, cutoff_date=None):\n",
    "    \"\"\"\n",
    "    Main function to generate all quarterly payment tables with proper periodicity handling\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Starting quarterly table generation with periodicity logic...\")\n",
    "    \n",
    "    if cutoff_date is not None:\n",
    "        print(f\"Using provided cutoff date: {cutoff_date}\")\n",
    "    else:\n",
    "        cutoff_date = pd.Timestamp.now()\n",
    "        print(f\"Using current date as cutoff: {cutoff_date}\")\n",
    "    \n",
    "    # Generate tables with scope filtering\n",
    "    results = create_quarterly_payment_tables(df_paym, cutoff_date)\n",
    "    \n",
    "    if results is None:\n",
    "        return None\n",
    "    \n",
    "    # Format for display\n",
    "    formatted_results = format_quarterly_tables_for_display(results)\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\n=== GENERATION COMPLETE ===\")\n",
    "    print(f\"Reporting for: {results['metadata']['reporting_year']}\")\n",
    "    print(f\"Scope: {results['metadata']['scope_start']} to {results['metadata']['scope_end']}\")\n",
    "    \n",
    "    if 'tables' in results:\n",
    "        for programme, tables in results['tables'].items():\n",
    "            print(f\"\\n{programme} Programme:\")\n",
    "            for payment_type, table in tables.items():\n",
    "                data_rows = len(table[table['Quarter'] != 'Total']) if len(table) > 0 else 0\n",
    "                print(f\"  - {payment_type}: {data_rows} quarters\")\n",
    "    \n",
    "    return formatted_results\n",
    "\n",
    "def format_quarterly_tables_for_great_tables(results):\n",
    "    \"\"\"\n",
    "    Format the results for great_tables library - clean pandas DataFrames\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'tables' not in results:\n",
    "        return results\n",
    "        \n",
    "    formatted_results = {\n",
    "        'metadata': results['metadata'],\n",
    "        'great_tables': {}\n",
    "    }\n",
    "    \n",
    "    for programme, tables in results['tables'].items():\n",
    "        formatted_results['great_tables'][programme] = {}\n",
    "        \n",
    "        for payment_type, df_table in tables.items():\n",
    "            # Create great_tables format\n",
    "            gt_table = format_table_for_great_tables(df_table, payment_type, programme)\n",
    "            formatted_results['great_tables'][programme][payment_type] = gt_table\n",
    "    \n",
    "    return formatted_results\n",
    "\n",
    "# Main execution function with great_tables output\n",
    "def generate_all_quarterly_tables(df_paym, cutoff_date=None):\n",
    "    \"\"\"\n",
    "    Main function to generate all quarterly payment tables for great_tables\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Starting quarterly table generation for great_tables...\")\n",
    "    \n",
    "    if cutoff_date is not None:\n",
    "        print(f\"Using provided cutoff date: {cutoff_date}\")\n",
    "    else:\n",
    "        cutoff_date = pd.Timestamp.now()\n",
    "        print(f\"Using current date as cutoff: {cutoff_date}\")\n",
    "    \n",
    "    # Generate tables with scope filtering\n",
    "    results = create_quarterly_payment_tables(df_paym, cutoff_date)\n",
    "    \n",
    "    if results is None:\n",
    "        return None\n",
    "    \n",
    "    # Format for great_tables\n",
    "    formatted_results = format_quarterly_tables_for_great_tables(results)\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\n=== GENERATION COMPLETE ===\")\n",
    "    print(f\"Reporting for: {results['metadata']['reporting_year']}\")\n",
    "    print(f\"Scope: {results['metadata']['scope_start']} to {results['metadata']['scope_end']}\")\n",
    "    print(f\"VOBU/EFTA aggregation: Only EFTA and VOBU fund sources included\")\n",
    "    \n",
    "    if 'tables' in results:\n",
    "        for programme, tables in results['tables'].items():\n",
    "            print(f\"\\n{programme} Programme:\")\n",
    "            for payment_type, table in tables.items():\n",
    "                data_rows = len(table[table['Quarter'] != 'Total']) if len(table) > 0 else 0\n",
    "                print(f\"  - {payment_type}: {data_rows} quarters\")\n",
    "    \n",
    "    return formatted_results\n",
    "\n",
    "# Updated utility functions for great_tables\n",
    "def get_great_table(formatted_results, programme, payment_type):\n",
    "    \"\"\"\n",
    "    Get a specific table formatted for great_tables\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return formatted_results['great_tables'][programme][payment_type]\n",
    "    except KeyError:\n",
    "        print(f\"Table not found: {programme} - {payment_type}\")\n",
    "        available_programmes = list(formatted_results.get('great_tables', {}).keys())\n",
    "        print(f\"Available programmes: {available_programmes}\")\n",
    "        if programme in formatted_results.get('great_tables', {}):\n",
    "            available_payment_types = list(formatted_results['great_tables'][programme].keys())\n",
    "            print(f\"Available payment types for {programme}: {available_payment_types}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def get_summary_table(formatted_results, programme):\n",
    "    \"\"\"\n",
    "    Get the summary table that includes all payment types (including experts)\n",
    "    \"\"\"\n",
    "    return get_great_table(formatted_results, programme, 'All_Payments')\n",
    "\n",
    "def create_comprehensive_summary_table(results, programme):\n",
    "    \"\"\"\n",
    "    Create a comprehensive summary table showing all payment types in one view\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'tables' not in results or programme not in results['tables']:\n",
    "        print(f\"No data found for programme: {programme}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    programme_tables = results['tables'][programme]\n",
    "    \n",
    "    # Initialize summary data\n",
    "    summary_data = []\n",
    "    \n",
    "    # Get all call types from any table\n",
    "    all_call_types = set()\n",
    "    for payment_type, table in programme_tables.items():\n",
    "        if payment_type != 'All_Payments' and len(table) > 0:\n",
    "            total_row = table[table['Quarter'] == 'Total']\n",
    "            if len(total_row) > 0:\n",
    "                call_type_cols = [col for col in total_row.columns if col.startswith('Total_Amount_')]\n",
    "                call_types = [col.replace('Total_Amount_', '') for col in call_type_cols]\n",
    "                all_call_types.update(call_types)\n",
    "    \n",
    "    all_call_types = sorted(list(all_call_types))\n",
    "    \n",
    "    # Create rows for each payment type\n",
    "    for payment_type, table in programme_tables.items():\n",
    "        if payment_type == 'All_Payments':\n",
    "            continue  # Skip the existing all payments, we'll create our own\n",
    "            \n",
    "        if len(table) == 0:\n",
    "            continue\n",
    "            \n",
    "        total_row = table[table['Quarter'] == 'Total']\n",
    "        if len(total_row) == 0:\n",
    "            continue\n",
    "            \n",
    "        # === TOTAL AMOUNT ROW ===\n",
    "        amount_row = {'Payment_Type': payment_type, 'Metric': 'Total Amount'}\n",
    "        \n",
    "        for call_type in all_call_types:\n",
    "            amount_col = f'Total_Amount_{call_type}'\n",
    "            amount_row[call_type] = total_row[amount_col].iloc[0] if amount_col in total_row.columns else 0\n",
    "        \n",
    "        amount_row['Total'] = total_row['Total_Amount'].iloc[0]\n",
    "        summary_data.append(amount_row)\n",
    "        \n",
    "        # === VOBU/EFTA ROW ===\n",
    "        vobu_efta_row = {'Payment_Type': payment_type, 'Metric': 'Out of Which VOBU/EFTA'}\n",
    "        \n",
    "        for call_type in all_call_types:\n",
    "            vobu_efta_col = f'VOBU_EFTA_Amount_{call_type}'\n",
    "            vobu_efta_row[call_type] = total_row[vobu_efta_col].iloc[0] if vobu_efta_col in total_row.columns else 0\n",
    "        \n",
    "        vobu_efta_row['Total'] = total_row['VOBU_EFTA_Amount'].iloc[0]\n",
    "        summary_data.append(vobu_efta_row)\n",
    "        \n",
    "        # === TRANSACTIONS ROW ===\n",
    "        transactions_row = {'Payment_Type': payment_type, 'Metric': 'No of Transactions'}\n",
    "        \n",
    "        for call_type in all_call_types:\n",
    "            transactions_col = f'No_of_Transactions_{call_type}'\n",
    "            transactions_row[call_type] = total_row[transactions_col].iloc[0] if transactions_col in total_row.columns else 0\n",
    "        \n",
    "        transactions_row['Total'] = total_row['No_of_Transactions'].iloc[0]\n",
    "        summary_data.append(transactions_row)\n",
    "    \n",
    "    # === CREATE OVERALL TOTALS ===\n",
    "    if summary_data:\n",
    "        # Get the All_Payments table data\n",
    "        all_payments_table = programme_tables.get('All_Payments', pd.DataFrame())\n",
    "        \n",
    "        if len(all_payments_table) > 0:\n",
    "            total_row = all_payments_table[all_payments_table['Quarter'] == 'Total']\n",
    "            \n",
    "            if len(total_row) > 0:\n",
    "                # TOTAL AMOUNTS ACROSS ALL PAYMENT TYPES\n",
    "                total_amount_row = {'Payment_Type': 'TOTAL ALL TYPES', 'Metric': 'Total Amount'}\n",
    "                for call_type in all_call_types:\n",
    "                    amount_col = f'Total_Amount_{call_type}'\n",
    "                    total_amount_row[call_type] = total_row[amount_col].iloc[0] if amount_col in total_row.columns else 0\n",
    "                total_amount_row['Total'] = total_row['Total_Amount'].iloc[0]\n",
    "                summary_data.append(total_amount_row)\n",
    "                \n",
    "                # TOTAL VOBU/EFTA ACROSS ALL PAYMENT TYPES\n",
    "                total_vobu_efta_row = {'Payment_Type': 'TOTAL ALL TYPES', 'Metric': 'Out of Which VOBU/EFTA'}\n",
    "                for call_type in all_call_types:\n",
    "                    vobu_efta_col = f'VOBU_EFTA_Amount_{call_type}'\n",
    "                    total_vobu_efta_row[call_type] = total_row[vobu_efta_col].iloc[0] if vobu_efta_col in total_row.columns else 0\n",
    "                total_vobu_efta_row['Total'] = total_row['VOBU_EFTA_Amount'].iloc[0]\n",
    "                summary_data.append(total_vobu_efta_row)\n",
    "                \n",
    "                # TOTAL TRANSACTIONS ACROSS ALL PAYMENT TYPES (deduplicated)\n",
    "                total_transactions_row = {'Payment_Type': 'TOTAL ALL TYPES', 'Metric': 'No of Transactions'}\n",
    "                for call_type in all_call_types:\n",
    "                    transactions_col = f'No_of_Transactions_{call_type}'\n",
    "                    total_transactions_row[call_type] = total_row[transactions_col].iloc[0] if transactions_col in total_row.columns else 0\n",
    "                total_transactions_row['Total'] = total_row['No_of_Transactions'].iloc[0]\n",
    "                summary_data.append(total_transactions_row)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    if summary_data:\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        \n",
    "        # Reorder columns\n",
    "        column_order = ['Payment_Type', 'Metric'] + all_call_types + ['Total']\n",
    "        summary_df = summary_df[column_order]\n",
    "        \n",
    "        return summary_df\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def create_payment_type_comparison_table(results, programme):\n",
    "    \"\"\"\n",
    "    Create a table showing just the totals for each payment type for easy comparison\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'tables' not in results or programme not in results['tables']:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    programme_tables = results['tables'][programme]\n",
    "    comparison_data = []\n",
    "    \n",
    "    for payment_type, table in programme_tables.items():\n",
    "        if payment_type == 'All_Payments':\n",
    "            continue\n",
    "            \n",
    "        if len(table) == 0:\n",
    "            continue\n",
    "            \n",
    "        total_row = table[table['Quarter'] == 'Total']\n",
    "        if len(total_row) == 0:\n",
    "            continue\n",
    "        \n",
    "        comparison_row = {\n",
    "            'Payment_Type': payment_type,\n",
    "            'Total_Amount': total_row['Total_Amount'].iloc[0],\n",
    "            'VOBU_EFTA_Amount': total_row['VOBU_EFTA_Amount'].iloc[0],\n",
    "            'No_of_Transactions': total_row['No_of_Transactions'].iloc[0]\n",
    "        }\n",
    "        \n",
    "        comparison_data.append(comparison_row)\n",
    "    \n",
    "    # Add overall total\n",
    "    if comparison_data:\n",
    "        all_payments_table = programme_tables.get('All_Payments', pd.DataFrame())\n",
    "        if len(all_payments_table) > 0:\n",
    "            total_row = all_payments_table[all_payments_table['Quarter'] == 'Total']\n",
    "            if len(total_row) > 0:\n",
    "                overall_row = {\n",
    "                    'Payment_Type': 'TOTAL ALL TYPES',\n",
    "                    'Total_Amount': total_row['Total_Amount'].iloc[0],\n",
    "                    'VOBU_EFTA_Amount': total_row['VOBU_EFTA_Amount'].iloc[0],\n",
    "                    'No_of_Transactions': total_row['No_of_Transactions'].iloc[0]\n",
    "                }\n",
    "                comparison_data.append(overall_row)\n",
    "    \n",
    "    return pd.DataFrame(comparison_data)\n",
    "\n",
    "def list_available_tables(formatted_results):\n",
    "    \"\"\"\n",
    "    List all available tables including summary options\n",
    "    \"\"\"\n",
    "    print(\"=== AVAILABLE TABLES FOR GREAT_TABLES ===\")\n",
    "    \n",
    "    if 'tables' not in formatted_results:\n",
    "        print(\"No tables found\")\n",
    "        return\n",
    "    \n",
    "    for programme, tables in formatted_results['tables'].items():\n",
    "        print(f\"\\n{programme} Programme:\")\n",
    "        for payment_type, df_table in tables.items():\n",
    "            rows, cols = df_table.shape\n",
    "            if payment_type == 'All_Payments':\n",
    "                print(f\"  - {payment_type}: {rows} rows x {cols} columns ⭐ SUMMARY TABLE\")\n",
    "            else:\n",
    "                print(f\"  - {payment_type}: {rows} rows x {cols} columns\")\n",
    "        \n",
    "        print(f\"\\n  📊 Access functions available:\")\n",
    "        print(f\"    # Individual payment types:\")\n",
    "        print(f\"    get_great_table(results, '{programme}', 'Pre-financing', repeat_quarter=True)  # Recommended\")\n",
    "        print(f\"    get_great_table_repeated(results, '{programme}', 'Pre-financing')  # Same as above\")\n",
    "        print(f\"    get_great_table_grouped(results, '{programme}', 'Pre-financing')   # Excel visual style\")\n",
    "        print(f\"    \")\n",
    "        print(f\"    # Summary tables:\")\n",
    "        print(f\"    get_summary_table(results, '{programme}', repeat_quarter=True)  # All payment types\")\n",
    "        print(f\"    create_comprehensive_summary_table(results, '{programme}')       # Alternative\")\n",
    "        print(f\"    create_payment_type_comparison_table(results, '{programme}')     # Quick comparison\")\n",
    "\n",
    "def get_all_programme_tables(formatted_results, programme):\n",
    "    \"\"\"\n",
    "    Get all tables for a specific programme as a dictionary\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return formatted_results['tables'][programme]\n",
    "    except KeyError:\n",
    "        print(f\"Programme not found: {programme}\")\n",
    "        available = list(formatted_results.get('tables', {}).keys())\n",
    "        print(f\"Available programmes: {available}\")\n",
    "        return {}\n",
    "\n",
    "def combine_payment_types_table(formatted_results, programme):\n",
    "    \"\"\"\n",
    "    Combine all payment types for a programme into one large table\n",
    "    \"\"\"\n",
    "    programme_tables = get_all_programme_tables(formatted_results, programme)\n",
    "    \n",
    "    if not programme_tables:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    combined_tables = []\n",
    "    \n",
    "    for payment_type, df_table in programme_tables.items():\n",
    "        if len(df_table) > 0:\n",
    "            # Add a separator row if not the first table\n",
    "            if len(combined_tables) > 0:\n",
    "                separator_row = pd.DataFrame([{\n",
    "                    'Metric': f'--- {payment_type} ---',\n",
    "                    **{col: '' for col in df_table.columns if col != 'Metric'}\n",
    "                }])\n",
    "                combined_tables.append(separator_row)\n",
    "            \n",
    "            combined_tables.append(df_table)\n",
    "    \n",
    "    if combined_tables:\n",
    "        return pd.concat(combined_tables, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Example usage functions\n",
    "def show_table_summary_for_great_tables(formatted_results):\n",
    "    \"\"\"Display summary of all generated tables for great_tables\"\"\"\n",
    "    print(\"=== QUARTERLY TABLES SUMMARY FOR GREAT_TABLES ===\")\n",
    "    print(f\"Reporting Period: {formatted_results['metadata']['reporting_year']}\")\n",
    "    print(f\"Data Range: {formatted_results['metadata']['actual_date_range']['start'].strftime('%Y-%m-%d')} to {formatted_results['metadata']['actual_date_range']['end'].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"VOBU/EFTA Logic: Aggregates only EFTA and VOBU fund sources\")\n",
    "    \n",
    "    if 'great_tables' in formatted_results:\n",
    "        for programme, tables in formatted_results['great_tables'].items():\n",
    "            print(f\"\\n{programme}:\")\n",
    "            for payment_type, table in tables.items():\n",
    "                if len(table) > 0:\n",
    "                    # Get total amounts from the 'Total Amount' row\n",
    "                    total_amount_row = table[table['Metric'] == 'Total Amount']\n",
    "                    vobu_efta_row = table[table['Metric'] == 'Out of Which VOBU/EFTA']\n",
    "                    transactions_row = table[table['Metric'] == 'No of Transactions']\n",
    "                    \n",
    "                    if len(total_amount_row) > 0:\n",
    "                        total_amount = total_amount_row['Total'].iloc[0]\n",
    "                        vobu_efta_amount = vobu_efta_row['Total'].iloc[0] if len(vobu_efta_row) > 0 else 0\n",
    "                        total_transactions = transactions_row['Total'].iloc[0] if len(transactions_row) > 0 else 0\n",
    "                        print(f\"  {payment_type}: €{total_amount:,.0f} total (€{vobu_efta_amount:,.0f} VOBU/EFTA) - {total_transactions} transactions\")\n",
    "\n",
    "# Updated access examples\n",
    "# Backwards compatibility functions\n",
    "def get_excel_format_table(formatted_results, programme, payment_type):\n",
    "    \"\"\"\n",
    "    Backwards compatibility function - redirects to get_great_table\n",
    "    \"\"\"\n",
    "    print(\"Note: get_excel_format_table is deprecated, use get_great_table for great_tables formatting\")\n",
    "    return get_great_table(formatted_results, programme, payment_type)\n",
    "\n",
    "def show_table_summary(formatted_results):\n",
    "    \"\"\"\n",
    "    Backwards compatibility function - redirects to show_table_summary_for_great_tables\n",
    "    \"\"\"\n",
    "    return show_table_summary_for_great_tables(formatted_results)\n",
    "\n",
    "# Updated access examples with summary tables\n",
    "def print_usage_instructions():\n",
    "    \"\"\"\n",
    "    Print instructions for using the generated tables including summary tables\n",
    "    \"\"\"\n",
    "    print(\"\"\"\n",
    "=== HOW TO USE THE QUARTERLY TABLES (Two Format Options) ===\n",
    "\n",
    "1. GENERATE TABLES:\n",
    "   quarterly_tables = generate_all_quarterly_tables(df_paym, cutoff)\n",
    "\n",
    "2. ACCESS INDIVIDUAL PAYMENT TYPE TABLES:\n",
    "   \n",
    "   # OPTION A: Repeated quarters (RECOMMENDED for great_tables)\n",
    "   heu_prefinancing = get_great_table(quarterly_tables, 'HEU', 'Pre-financing', repeat_quarter=True)\n",
    "   heu_interim = get_great_table(quarterly_tables, 'HEU', 'Interim Payments', repeat_quarter=True)\n",
    "   \n",
    "   # OPTION B: Grouped quarters (Excel visual style)\n",
    "   heu_prefinancing_grouped = get_great_table(quarterly_tables, 'HEU', 'Pre-financing', repeat_quarter=False)\n",
    "   \n",
    "   # Shortcut functions:\n",
    "   heu_prefinancing = get_great_table_repeated(quarterly_tables, 'HEU', 'Pre-financing')  # Same as Option A\n",
    "   heu_prefinancing_grouped = get_great_table_grouped(quarterly_tables, 'HEU', 'Pre-financing')  # Same as Option B\n",
    "\n",
    "3. ACCESS SUMMARY TABLES (ALL PAYMENT TYPES INCLUDING EXPERTS):\n",
    "   \n",
    "   # Summary table with repeated quarters (recommended for great_tables)\n",
    "   heu_summary = get_summary_table(quarterly_tables, 'HEU', repeat_quarter=True)\n",
    "   \n",
    "   # Summary table with grouped quarters (Excel visual style)\n",
    "   heu_summary_grouped = get_summary_table(quarterly_tables, 'HEU', repeat_quarter=False)\n",
    "   \n",
    "   # Alternative access\n",
    "   heu_summary_alt = create_comprehensive_summary_table(quarterly_tables, 'HEU', repeat_quarter=True)\n",
    "   \n",
    "   # Quick comparison table (different format - just totals by payment type)\n",
    "   heu_comparison = create_payment_type_comparison_table(quarterly_tables, 'HEU')\n",
    "\n",
    "4. LIST ALL AVAILABLE TABLES:\n",
    "   list_available_tables(quarterly_tables)\n",
    "\n",
    "5. USE WITH GREAT_TABLES:\n",
    "   from great_tables import GT\n",
    "   \n",
    "   # Individual payment type (using repeated format)\n",
    "   gt_table = (\n",
    "       GT(heu_prefinancing)\n",
    "       .tab_header(title=\"HEU Pre-financing\", subtitle=\"Q1 2025\")\n",
    "       .fmt_currency(columns=['ADG', 'COG', 'POC', 'STG', 'SYG', 'Total'], currency='EUR')\n",
    "       .tab_row_group(label=\"2024Q1\", rows=[\"2024Q1\"])  # Can group by Quarter if using repeated format\n",
    "   )\n",
    "\n",
    "FORMAT OPTIONS:\n",
    "\n",
    "OPTION A - Repeated Quarters (RECOMMENDED for great_tables):\n",
    "Quarter | Metric                  | ADG | COG | POC | STG | SYG | Total\n",
    "2024Q1  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
    "2024Q1  | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
    "2024Q1  | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
    "2024Q2  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
    "2024Q2  | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
    "2024Q2  | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
    "\n",
    "OPTION B - Grouped Quarters (Excel visual style):\n",
    "Quarter | Metric                  | ADG | COG | POC | STG | SYG | Total\n",
    "2024Q1  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
    "        | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
    "        | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
    "2024Q2  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
    "        | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
    "        | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
    "\n",
    "RECOMMENDATION:\n",
    "✅ Use repeat_quarter=True (Option A) for great_tables - better for:\n",
    "  - Data processing and filtering\n",
    "  - Row grouping operations\n",
    "  - Exporting to other formats\n",
    "  - Table manipulation\n",
    "\n",
    "Use repeat_quarter=False (Option B) for:\n",
    "  - Pure visual presentation matching Excel\n",
    "  - When you want minimal visual clutter\n",
    "\"\"\")\n",
    "\n",
    "def show_summary_examples():\n",
    "    \"\"\"\n",
    "    Show examples of the different summary table options with correct format\n",
    "    \"\"\"\n",
    "    print(\"\"\"\n",
    "=== SUMMARY TABLE EXAMPLES (Both Format Options) ===\n",
    "\n",
    "# 1a. Summary table with repeated quarters (RECOMMENDED for great_tables)\n",
    "heu_summary = get_summary_table(quarterly_tables, 'HEU', repeat_quarter=True)\n",
    "# Quarter | Metric                  | ADG | COG | POC | STG | SYG | Total\n",
    "# 2024Q1  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
    "# 2024Q1  | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
    "# 2024Q1  | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
    "# Total   | Total Amount            | ... | ... | ... | ... | ... | ...\n",
    "# Total   | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
    "# Total   | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
    "\n",
    "# 1b. Summary table with grouped quarters (Excel visual style)\n",
    "heu_summary_grouped = get_summary_table(quarterly_tables, 'HEU', repeat_quarter=False)\n",
    "# Quarter | Metric                  | ADG | COG | POC | STG | SYG | Total\n",
    "# 2024Q1  | Total Amount            | ... | ... | ... | ... | ... | ...\n",
    "#         | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
    "#         | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
    "# Total   | Total Amount            | ... | ... | ... | ... | ... | ...\n",
    "#         | Out of Which VOBU/EFTA  | ... | ... | ... | ... | ... | ...\n",
    "#         | No of Transactions      | ... | ... | ... | ... | ... | ...\n",
    "\n",
    "# 2. Quick comparison (different format - by payment type)\n",
    "heu_comparison = create_payment_type_comparison_table(quarterly_tables, 'HEU')\n",
    "# Payment_Type | Total_Amount | VOBU_EFTA_Amount | No_of_Transactions\n",
    "# Pre-financing | 352,568,326 | 336,797,403 | 309\n",
    "# Interim Payments | 185,710,686 | 175,320,845 | 115\n",
    "# TOTAL ALL TYPES | 1,628,225,910 | 1,398,938,052 | 1,573\n",
    "\n",
    "BOTH formats contain the same data, just different visual presentation!\n",
    "\"\"\")\n",
    "\n",
    "# If run directly, show instructions\n",
    "if __name__ == \"__main__\":\n",
    "    print_usage_instructions()\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    show_summary_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "968f6cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting quarterly table generation for great_tables...\n",
      "Using provided cutoff date: 2025-06-01 00:00:00\n",
      "=== QUARTERLY PAYMENT TABLES GENERATION ===\n",
      "Cutoff date: 2025-06-01 00:00:00\n",
      "Reporting year: 2025\n",
      "Expected scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Note: Assuming df_paym is already filtered for this scope\n",
      "Found call type column: call_type\n",
      "✓ All required columns present\n",
      "Working dataset: 4890 rows\n",
      "Actual date range: 2025-01-16 00:00:00 to 2025-06-02 00:00:00\n",
      "Quarters found: ['2025Q1', '2025Q2']\n",
      "Call types found: ['ADG', 'COG', 'EXPERTS', 'POC', 'STG', 'SYG']\n",
      "Programmes found: ['HEU' 'H2020']\n",
      "\n",
      "=== Processing HEU ===\n",
      "  Creating table for: Pre-financing\n",
      "  Creating table for: Interim Payments\n",
      "  Creating table for: Experts and Support\n",
      "  Creating table for: Final Payments\n",
      "  Creating overall summary table\n",
      "\n",
      "=== Processing H2020 ===\n",
      "  Creating table for: Interim Payments\n",
      "  Creating table for: Final Payments\n",
      "  Creating overall summary table\n",
      "  Formatting for great_tables - Call types: ['ADG', 'COG', 'POC', 'STG', 'SYG'], Quarters: ['1Q2025', '2Q2025']\n",
      "  Quarter repeat mode: True\n",
      "  Formatting for great_tables - Call types: ['ADG', 'COG', 'STG', 'SYG'], Quarters: ['1Q2025', '2Q2025']\n",
      "  Quarter repeat mode: True\n",
      "  Formatting for great_tables - Call types: ['EXPERTS'], Quarters: ['1Q2025', '2Q2025']\n",
      "  Quarter repeat mode: True\n",
      "  Formatting for great_tables - Call types: ['POC'], Quarters: ['1Q2025', '2Q2025']\n",
      "  Quarter repeat mode: True\n",
      "  Formatting for great_tables - Call types: ['ADG', 'COG', 'EXPERTS', 'POC', 'STG', 'SYG'], Quarters: ['1Q2025', '2Q2025']\n",
      "  Quarter repeat mode: True\n",
      "  Formatting for great_tables - Call types: ['ADG', 'COG', 'STG', 'SYG'], Quarters: ['1Q2025', '2Q2025']\n",
      "  Quarter repeat mode: True\n",
      "  Formatting for great_tables - Call types: ['ADG', 'COG', 'STG', 'SYG'], Quarters: ['1Q2025', '2Q2025']\n",
      "  Quarter repeat mode: True\n",
      "  Formatting for great_tables - Call types: ['ADG', 'COG', 'STG', 'SYG'], Quarters: ['1Q2025', '2Q2025']\n",
      "  Quarter repeat mode: True\n",
      "\n",
      "=== GENERATION COMPLETE ===\n",
      "Reporting for: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "VOBU/EFTA aggregation: Only EFTA and VOBU fund sources included\n",
      "\n",
      "HEU Programme:\n",
      "  - Pre-financing: 2 quarters\n",
      "  - Interim Payments: 2 quarters\n",
      "  - Experts and Support: 2 quarters\n",
      "  - Final Payments: 2 quarters\n",
      "  - All_Payments: 2 quarters\n",
      "\n",
      "H2020 Programme:\n",
      "  - Interim Payments: 2 quarters\n",
      "  - Final Payments: 2 quarters\n",
      "  - All_Payments: 2 quarters\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "quarterly_tables = generate_all_quarterly_tables(df_paym, cutoff )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15f2860c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Metric</th>\n",
       "      <th>ADG</th>\n",
       "      <th>COG</th>\n",
       "      <th>POC</th>\n",
       "      <th>STG</th>\n",
       "      <th>SYG</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1Q2025</td>\n",
       "      <td>Total Amount</td>\n",
       "      <td>60065912.4</td>\n",
       "      <td>8.454135e+07</td>\n",
       "      <td>5062500.0</td>\n",
       "      <td>1.247404e+08</td>\n",
       "      <td>79357691.7</td>\n",
       "      <td>3.537678e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1Q2025</td>\n",
       "      <td>Out of Which VOBU/EFTA</td>\n",
       "      <td>60065912.4</td>\n",
       "      <td>8.072030e+07</td>\n",
       "      <td>4965000.0</td>\n",
       "      <td>1.128881e+08</td>\n",
       "      <td>79357691.7</td>\n",
       "      <td>3.379970e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1Q2025</td>\n",
       "      <td>No of Transactions</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.600000e+01</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.390000e+02</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.100000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2Q2025</td>\n",
       "      <td>Total Amount</td>\n",
       "      <td>5099243.4</td>\n",
       "      <td>1.391124e+08</td>\n",
       "      <td>5962500.0</td>\n",
       "      <td>2.401659e+07</td>\n",
       "      <td>46452946.4</td>\n",
       "      <td>2.206437e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2Q2025</td>\n",
       "      <td>Out of Which VOBU/EFTA</td>\n",
       "      <td>5099243.4</td>\n",
       "      <td>1.382231e+08</td>\n",
       "      <td>3640000.0</td>\n",
       "      <td>1.629071e+07</td>\n",
       "      <td>45457190.4</td>\n",
       "      <td>2.087103e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2Q2025</td>\n",
       "      <td>No of Transactions</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.150000e+02</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.600000e+01</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.130000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total</td>\n",
       "      <td>Total Amount</td>\n",
       "      <td>65165155.8</td>\n",
       "      <td>2.236538e+08</td>\n",
       "      <td>11025000.0</td>\n",
       "      <td>1.487570e+08</td>\n",
       "      <td>125810638.1</td>\n",
       "      <td>5.744116e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Total</td>\n",
       "      <td>Out of Which VOBU/EFTA</td>\n",
       "      <td>65165155.8</td>\n",
       "      <td>2.189434e+08</td>\n",
       "      <td>8605000.0</td>\n",
       "      <td>1.291788e+08</td>\n",
       "      <td>124814882.1</td>\n",
       "      <td>5.467072e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Total</td>\n",
       "      <td>No of Transactions</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.810000e+02</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.650000e+02</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.230000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Quarter                  Metric         ADG           COG         POC  \\\n",
       "0  1Q2025            Total Amount  60065912.4  8.454135e+07   5062500.0   \n",
       "1  1Q2025  Out of Which VOBU/EFTA  60065912.4  8.072030e+07   4965000.0   \n",
       "2  1Q2025      No of Transactions        37.0  6.600000e+01        45.0   \n",
       "3  2Q2025            Total Amount   5099243.4  1.391124e+08   5962500.0   \n",
       "4  2Q2025  Out of Which VOBU/EFTA   5099243.4  1.382231e+08   3640000.0   \n",
       "5  2Q2025      No of Transactions         3.0  1.150000e+02        55.0   \n",
       "6   Total            Total Amount  65165155.8  2.236538e+08  11025000.0   \n",
       "7   Total  Out of Which VOBU/EFTA  65165155.8  2.189434e+08   8605000.0   \n",
       "8   Total      No of Transactions        40.0  1.810000e+02       100.0   \n",
       "\n",
       "            STG          SYG         Total  \n",
       "0  1.247404e+08   79357691.7  3.537678e+08  \n",
       "1  1.128881e+08   79357691.7  3.379970e+08  \n",
       "2  1.390000e+02         23.0  3.100000e+02  \n",
       "3  2.401659e+07   46452946.4  2.206437e+08  \n",
       "4  1.629071e+07   45457190.4  2.087103e+08  \n",
       "5  2.600000e+01         14.0  2.130000e+02  \n",
       "6  1.487570e+08  125810638.1  5.744116e+08  \n",
       "7  1.291788e+08  124814882.1  5.467072e+08  \n",
       "8  1.650000e+02         37.0  5.230000e+02  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heu_prefinancing = get_great_table(quarterly_tables, 'HEU', 'Pre-financing')\n",
    "heu_prefinancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f7e2c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Metric</th>\n",
       "      <th>ADG</th>\n",
       "      <th>COG</th>\n",
       "      <th>STG</th>\n",
       "      <th>SYG</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1Q2025</td>\n",
       "      <td>Total Amount</td>\n",
       "      <td>5671359.26</td>\n",
       "      <td>8931795.08</td>\n",
       "      <td>30656937.93</td>\n",
       "      <td>22497012.74</td>\n",
       "      <td>6.775711e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1Q2025</td>\n",
       "      <td>Out of Which VOBU/EFTA</td>\n",
       "      <td>5671359.26</td>\n",
       "      <td>8432021.08</td>\n",
       "      <td>25796245.16</td>\n",
       "      <td>21207250.51</td>\n",
       "      <td>6.110688e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1Q2025</td>\n",
       "      <td>No of Transactions</td>\n",
       "      <td>10.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>95.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1.380000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2Q2025</td>\n",
       "      <td>Total Amount</td>\n",
       "      <td>15793008.09</td>\n",
       "      <td>22838494.46</td>\n",
       "      <td>38504633.62</td>\n",
       "      <td>8040321.52</td>\n",
       "      <td>8.517646e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2Q2025</td>\n",
       "      <td>Out of Which VOBU/EFTA</td>\n",
       "      <td>15793008.09</td>\n",
       "      <td>22838494.46</td>\n",
       "      <td>31024571.32</td>\n",
       "      <td>8040321.52</td>\n",
       "      <td>7.769640e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2Q2025</td>\n",
       "      <td>No of Transactions</td>\n",
       "      <td>26.00</td>\n",
       "      <td>47.00</td>\n",
       "      <td>127.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.050000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total</td>\n",
       "      <td>Total Amount</td>\n",
       "      <td>21464367.35</td>\n",
       "      <td>31770289.54</td>\n",
       "      <td>69161571.55</td>\n",
       "      <td>30537334.26</td>\n",
       "      <td>1.529336e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Total</td>\n",
       "      <td>Out of Which VOBU/EFTA</td>\n",
       "      <td>21464367.35</td>\n",
       "      <td>31270515.54</td>\n",
       "      <td>56820816.48</td>\n",
       "      <td>29247572.03</td>\n",
       "      <td>1.388033e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Total</td>\n",
       "      <td>No of Transactions</td>\n",
       "      <td>36.00</td>\n",
       "      <td>65.00</td>\n",
       "      <td>222.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>3.430000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Quarter                  Metric          ADG          COG          STG  \\\n",
       "0  1Q2025            Total Amount   5671359.26   8931795.08  30656937.93   \n",
       "1  1Q2025  Out of Which VOBU/EFTA   5671359.26   8432021.08  25796245.16   \n",
       "2  1Q2025      No of Transactions        10.00        18.00        95.00   \n",
       "3  2Q2025            Total Amount  15793008.09  22838494.46  38504633.62   \n",
       "4  2Q2025  Out of Which VOBU/EFTA  15793008.09  22838494.46  31024571.32   \n",
       "5  2Q2025      No of Transactions        26.00        47.00       127.00   \n",
       "6   Total            Total Amount  21464367.35  31770289.54  69161571.55   \n",
       "7   Total  Out of Which VOBU/EFTA  21464367.35  31270515.54  56820816.48   \n",
       "8   Total      No of Transactions        36.00        65.00       222.00   \n",
       "\n",
       "           SYG         Total  \n",
       "0  22497012.74  6.775711e+07  \n",
       "1  21207250.51  6.110688e+07  \n",
       "2        15.00  1.380000e+02  \n",
       "3   8040321.52  8.517646e+07  \n",
       "4   8040321.52  7.769640e+07  \n",
       "5         5.00  2.050000e+02  \n",
       "6  30537334.26  1.529336e+08  \n",
       "7  29247572.03  1.388033e+08  \n",
       "8        20.00  3.430000e+02  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heu_ip = get_great_table(quarterly_tables, 'HEU', 'Interim Payments')\n",
    "heu_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92b3eada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Metric</th>\n",
       "      <th>POC</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1Q2025</td>\n",
       "      <td>Total Amount</td>\n",
       "      <td>1632000.00</td>\n",
       "      <td>1632000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1Q2025</td>\n",
       "      <td>Out of Which VOBU/EFTA</td>\n",
       "      <td>1541863.75</td>\n",
       "      <td>1541863.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1Q2025</td>\n",
       "      <td>No of Transactions</td>\n",
       "      <td>58.00</td>\n",
       "      <td>58.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2Q2025</td>\n",
       "      <td>Total Amount</td>\n",
       "      <td>1140000.00</td>\n",
       "      <td>1140000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2Q2025</td>\n",
       "      <td>Out of Which VOBU/EFTA</td>\n",
       "      <td>1120000.00</td>\n",
       "      <td>1120000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2Q2025</td>\n",
       "      <td>No of Transactions</td>\n",
       "      <td>39.00</td>\n",
       "      <td>39.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total</td>\n",
       "      <td>Total Amount</td>\n",
       "      <td>2772000.00</td>\n",
       "      <td>2772000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Total</td>\n",
       "      <td>Out of Which VOBU/EFTA</td>\n",
       "      <td>2661863.75</td>\n",
       "      <td>2661863.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Total</td>\n",
       "      <td>No of Transactions</td>\n",
       "      <td>97.00</td>\n",
       "      <td>97.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Quarter                  Metric         POC       Total\n",
       "0  1Q2025            Total Amount  1632000.00  1632000.00\n",
       "1  1Q2025  Out of Which VOBU/EFTA  1541863.75  1541863.75\n",
       "2  1Q2025      No of Transactions       58.00       58.00\n",
       "3  2Q2025            Total Amount  1140000.00  1140000.00\n",
       "4  2Q2025  Out of Which VOBU/EFTA  1120000.00  1120000.00\n",
       "5  2Q2025      No of Transactions       39.00       39.00\n",
       "6   Total            Total Amount  2772000.00  2772000.00\n",
       "7   Total  Out of Which VOBU/EFTA  2661863.75  2661863.75\n",
       "8   Total      No of Transactions       97.00       97.00"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heu_fp = get_great_table(quarterly_tables, 'HEU', 'Final Payments')\n",
    "heu_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3f2098a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Metric</th>\n",
       "      <th>EXPERTS</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1Q2025</td>\n",
       "      <td>Total Amount</td>\n",
       "      <td>3986096.99</td>\n",
       "      <td>3986096.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1Q2025</td>\n",
       "      <td>Out of Which VOBU/EFTA</td>\n",
       "      <td>3941406.67</td>\n",
       "      <td>3941406.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1Q2025</td>\n",
       "      <td>No of Transactions</td>\n",
       "      <td>1493.00</td>\n",
       "      <td>1493.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2Q2025</td>\n",
       "      <td>Total Amount</td>\n",
       "      <td>3974216.64</td>\n",
       "      <td>3974216.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2Q2025</td>\n",
       "      <td>Out of Which VOBU/EFTA</td>\n",
       "      <td>3974216.64</td>\n",
       "      <td>3974216.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2Q2025</td>\n",
       "      <td>No of Transactions</td>\n",
       "      <td>1313.00</td>\n",
       "      <td>1313.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total</td>\n",
       "      <td>Total Amount</td>\n",
       "      <td>7960313.63</td>\n",
       "      <td>7960313.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Total</td>\n",
       "      <td>Out of Which VOBU/EFTA</td>\n",
       "      <td>7915623.31</td>\n",
       "      <td>7915623.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Total</td>\n",
       "      <td>No of Transactions</td>\n",
       "      <td>2806.00</td>\n",
       "      <td>2806.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Quarter                  Metric     EXPERTS       Total\n",
       "0  1Q2025            Total Amount  3986096.99  3986096.99\n",
       "1  1Q2025  Out of Which VOBU/EFTA  3941406.67  3941406.67\n",
       "2  1Q2025      No of Transactions     1493.00     1493.00\n",
       "3  2Q2025            Total Amount  3974216.64  3974216.64\n",
       "4  2Q2025  Out of Which VOBU/EFTA  3974216.64  3974216.64\n",
       "5  2Q2025      No of Transactions     1313.00     1313.00\n",
       "6   Total            Total Amount  7960313.63  7960313.63\n",
       "7   Total  Out of Which VOBU/EFTA  7915623.31  7915623.31\n",
       "8   Total      No of Transactions     2806.00     2806.00"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heu_expt = get_great_table(quarterly_tables, 'HEU', 'Experts and Support')\n",
    "heu_expt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d68b0185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Metric</th>\n",
       "      <th>ADG</th>\n",
       "      <th>COG</th>\n",
       "      <th>EXPERTS</th>\n",
       "      <th>POC</th>\n",
       "      <th>STG</th>\n",
       "      <th>SYG</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1Q2025</td>\n",
       "      <td>Total Amount</td>\n",
       "      <td>65737271.66</td>\n",
       "      <td>9.347314e+07</td>\n",
       "      <td>3986096.99</td>\n",
       "      <td>6694500.00</td>\n",
       "      <td>1.553973e+08</td>\n",
       "      <td>1.018547e+08</td>\n",
       "      <td>4.271430e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1Q2025</td>\n",
       "      <td>Out of Which VOBU/EFTA</td>\n",
       "      <td>65737271.66</td>\n",
       "      <td>8.915232e+07</td>\n",
       "      <td>3941406.67</td>\n",
       "      <td>6506863.75</td>\n",
       "      <td>1.386843e+08</td>\n",
       "      <td>1.005649e+08</td>\n",
       "      <td>4.045871e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1Q2025</td>\n",
       "      <td>No of Transactions</td>\n",
       "      <td>47.00</td>\n",
       "      <td>8.400000e+01</td>\n",
       "      <td>1493.00</td>\n",
       "      <td>103.00</td>\n",
       "      <td>2.340000e+02</td>\n",
       "      <td>3.800000e+01</td>\n",
       "      <td>1.999000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2Q2025</td>\n",
       "      <td>Total Amount</td>\n",
       "      <td>20892251.49</td>\n",
       "      <td>1.619509e+08</td>\n",
       "      <td>3974216.64</td>\n",
       "      <td>7102500.00</td>\n",
       "      <td>6.252123e+07</td>\n",
       "      <td>5.449327e+07</td>\n",
       "      <td>3.109344e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2Q2025</td>\n",
       "      <td>Out of Which VOBU/EFTA</td>\n",
       "      <td>20892251.49</td>\n",
       "      <td>1.610616e+08</td>\n",
       "      <td>3974216.64</td>\n",
       "      <td>4760000.00</td>\n",
       "      <td>4.731529e+07</td>\n",
       "      <td>5.349751e+07</td>\n",
       "      <td>2.915009e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2Q2025</td>\n",
       "      <td>No of Transactions</td>\n",
       "      <td>29.00</td>\n",
       "      <td>1.620000e+02</td>\n",
       "      <td>1313.00</td>\n",
       "      <td>94.00</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>1.770000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total</td>\n",
       "      <td>Total Amount</td>\n",
       "      <td>86629523.15</td>\n",
       "      <td>2.554241e+08</td>\n",
       "      <td>7960313.63</td>\n",
       "      <td>13797000.00</td>\n",
       "      <td>2.179186e+08</td>\n",
       "      <td>1.563480e+08</td>\n",
       "      <td>7.380775e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Total</td>\n",
       "      <td>Out of Which VOBU/EFTA</td>\n",
       "      <td>86629523.15</td>\n",
       "      <td>2.502140e+08</td>\n",
       "      <td>7915623.31</td>\n",
       "      <td>11266863.75</td>\n",
       "      <td>1.859996e+08</td>\n",
       "      <td>1.540625e+08</td>\n",
       "      <td>6.960880e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Total</td>\n",
       "      <td>No of Transactions</td>\n",
       "      <td>76.00</td>\n",
       "      <td>2.460000e+02</td>\n",
       "      <td>2806.00</td>\n",
       "      <td>197.00</td>\n",
       "      <td>3.870000e+02</td>\n",
       "      <td>5.700000e+01</td>\n",
       "      <td>3.769000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Quarter                  Metric          ADG           COG     EXPERTS  \\\n",
       "0  1Q2025            Total Amount  65737271.66  9.347314e+07  3986096.99   \n",
       "1  1Q2025  Out of Which VOBU/EFTA  65737271.66  8.915232e+07  3941406.67   \n",
       "2  1Q2025      No of Transactions        47.00  8.400000e+01     1493.00   \n",
       "3  2Q2025            Total Amount  20892251.49  1.619509e+08  3974216.64   \n",
       "4  2Q2025  Out of Which VOBU/EFTA  20892251.49  1.610616e+08  3974216.64   \n",
       "5  2Q2025      No of Transactions        29.00  1.620000e+02     1313.00   \n",
       "6   Total            Total Amount  86629523.15  2.554241e+08  7960313.63   \n",
       "7   Total  Out of Which VOBU/EFTA  86629523.15  2.502140e+08  7915623.31   \n",
       "8   Total      No of Transactions        76.00  2.460000e+02     2806.00   \n",
       "\n",
       "           POC           STG           SYG         Total  \n",
       "0   6694500.00  1.553973e+08  1.018547e+08  4.271430e+08  \n",
       "1   6506863.75  1.386843e+08  1.005649e+08  4.045871e+08  \n",
       "2       103.00  2.340000e+02  3.800000e+01  1.999000e+03  \n",
       "3   7102500.00  6.252123e+07  5.449327e+07  3.109344e+08  \n",
       "4   4760000.00  4.731529e+07  5.349751e+07  2.915009e+08  \n",
       "5        94.00  1.530000e+02  1.900000e+01  1.770000e+03  \n",
       "6  13797000.00  2.179186e+08  1.563480e+08  7.380775e+08  \n",
       "7  11266863.75  1.859996e+08  1.540625e+08  6.960880e+08  \n",
       "8       197.00  3.870000e+02  5.700000e+01  3.769000e+03  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heu_all = get_great_table(quarterly_tables, 'HEU', 'All_Payments')\n",
    "heu_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "65d3d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_all = fetch_vars_for_report(report, db_path)\n",
    "heu_vars_data = vars_all.get('table_2a_HE')\n",
    "h2020_vars_data = vars_all.get('table_2a_H2020')\n",
    "\n",
    "heu_total_appropriations = next(\n",
    "    (item['Available_Payment_Appropriations'] for item in heu_vars_data \n",
    "     if item['Budget Address Type'] == 'Total'), \n",
    "    None\n",
    ")\n",
    "\n",
    "heu_total_appropriations_expt = next(\n",
    "    (item['Available_Payment_Appropriations'] for item in heu_vars_data \n",
    "     if item['Budget Address Type'] == 'Experts'), \n",
    "    None\n",
    ")\n",
    "\n",
    "h2020_total_appropriations = next(\n",
    "    (item['Available_Payment_Appropriations'] for item in h2020_vars_data \n",
    "     if item['Budget Address Type'] == 'Total'), \n",
    "    None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3714a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"database/reporting.db\"\n",
    "DB_PATH = Path(\"database/reporting.db\")\n",
    "report = 'Quarterly_Report'\n",
    "report_params = load_report_params(report_name=report, db_path=DB_PATH )\n",
    "TTP_gross = report_params.get(\"TTP_GROSS_HISTORY\")\n",
    "TTP_gross_H2020 = TTP_gross.get('H2020')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4177733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# =============================================================================\n",
    "# CLEAN TTP CALCULATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_current_ttp_metrics(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Calculate current TTP metrics from df_paym data\n",
    "    \"\"\"\n",
    "    # Filter data up to cutoff and deduplicate by Pay Payment Key\n",
    "    quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "    last_valid_date = quarter_dates[1]\n",
    "\n",
    "    df_filtered = df_paym[\n",
    "        df_paym['Pay Document Date (dd/mm/yyyy)'] <= last_valid_date\n",
    "    ].copy()\n",
    "    df_unique = df_filtered.drop_duplicates(subset=['Pay Payment Key']).copy()\n",
    "    \n",
    "    # Convert to numeric\n",
    "    df_unique['v_TTP_NET'] = pd.to_numeric(df_unique['v_TTP_NET'], errors='coerce')\n",
    "    df_unique['v_TTP_GROSS'] = pd.to_numeric(df_unique['v_TTP_GROSS'], errors='coerce')\n",
    "    df_unique['v_payment_in_time'] = pd.to_numeric(df_unique['v_payment_in_time'], errors='coerce')\n",
    "\n",
    "    # Filter out negative TTP_NET values\n",
    "    df_unique = df_unique[df_unique['v_TTP_NET'] >= 0]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Calculate by Programme and Payment Type\n",
    "    for programme in ['H2020', 'HEU']:\n",
    "        prog_data = df_unique[df_unique['Programme'] == programme]\n",
    "        if len(prog_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        results[programme] = {}\n",
    "        \n",
    "        # Overall programme metrics\n",
    "        prog_valid = prog_data[prog_data['v_payment_in_time'].notna()]\n",
    "        results[programme]['overall'] = {\n",
    "            'avg_ttp_net': prog_data['v_TTP_NET'].mean(),\n",
    "            'avg_ttp_gross': prog_data['v_TTP_GROSS'].mean(),\n",
    "            'on_time_pct': prog_data['v_payment_in_time'].sum() / len(prog_valid) if len(prog_valid) > 0 else 0\n",
    "        }\n",
    "        \n",
    "        # By payment type - using correct short form values from v_payment_type\n",
    "        payment_types = ['IP', 'FP', 'EXPERTS', 'PF']  # Short form values\n",
    "        \n",
    "        for payment_type in payment_types:\n",
    "            pt_data = prog_data[prog_data['v_payment_type'] == payment_type]\n",
    "            if len(pt_data) > 0:\n",
    "                pt_valid = pt_data[pt_data['v_payment_in_time'].notna()]\n",
    "                results[programme][payment_type] = {\n",
    "                    'avg_ttp_net': pt_data['v_TTP_NET'].mean(),\n",
    "                    'avg_ttp_gross': pt_data['v_TTP_GROSS'].mean(),\n",
    "                    'on_time_pct': pt_data['v_payment_in_time'].sum() / len(pt_valid) if len(pt_valid) > 0 else 0\n",
    "                }\n",
    "    \n",
    "    # Overall total\n",
    "    total_valid = df_unique[df_unique['v_payment_in_time'].notna()]\n",
    "    results['TOTAL'] = {\n",
    "        'avg_ttp_net': df_unique['v_TTP_NET'].mean(),\n",
    "        'avg_ttp_gross': df_unique['v_TTP_GROSS'].mean(),\n",
    "        'on_time_pct': df_unique['v_payment_in_time'].sum() / len(total_valid) if len(total_valid) > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def load_historical_ttp_data(report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Load historical TTP data from database\n",
    "    \"\"\"\n",
    "    DB_PATH = Path(db_path)\n",
    "    report_params = load_report_params(report_name=report_name, db_path=DB_PATH)\n",
    "    \n",
    "    return {\n",
    "        \"TTP_NET_HISTORY\": report_params.get(\"TTP_NET_HISTORY\"),\n",
    "        \"TTP_GROSS_HISTORY\": report_params.get(\"TTP_GROSS_HISTORY\"),\n",
    "        \"PAYMENTS_ON_TIME_HISTORY\": report_params.get(\"PAYMENTS_ON_TIME_HISTORY\")\n",
    "    }\n",
    "\n",
    "def create_ttp_comparison_table(df_paym, cutoff, historical_data):\n",
    "    \"\"\"\n",
    "    Create TTP comparison table matching the image structure\n",
    "    \"\"\"\n",
    "    # Calculate current metrics\n",
    "    current_metrics = calculate_current_ttp_metrics(df_paym, cutoff)\n",
    "    \n",
    "    # Determine labels based on cutoff\n",
    "    cutoff_date = pd.to_datetime(cutoff)\n",
    "    current_year = cutoff_date.year\n",
    "    current_label = f\"{current_year}-YTD\"\n",
    "    historical_label = f\"Dec {current_year - 1}\"\n",
    "    \n",
    "    # Build comparison data\n",
    "    comparison_data = []\n",
    "    \n",
    "    # H2020 section\n",
    "    h2020_current = current_metrics.get('H2020', {})\n",
    "    \n",
    "    # H2020 - Interim Payments (IP)\n",
    "    current_ip = h2020_current.get('IP', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Interim Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_ip['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"H2020\"].get(\"IP\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_ip['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"H2020\"].get(\"IP\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_ip['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('IP', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # H2020 - Final Payments (FP)\n",
    "    current_fp = h2020_current.get('FP', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Final Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_fp['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"H2020\"].get(\"FP\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_fp['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"H2020\"].get(\"FP\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_fp['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('FP', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # H2020 - Experts Payments (EXPERTS)\n",
    "    current_exp = h2020_current.get('EXPERTS', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Experts Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_exp['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"H2020\"].get(\"Experts\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_exp['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"H2020\"].get(\"Experts\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_exp['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('Experts', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # H2020 - Overall\n",
    "    current_h2020 = h2020_current.get('overall', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'H2020',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_h2020['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"H2020\"].get(\"H2020\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_h2020['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"H2020\"].get(\"H2020\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_h2020['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('H2020', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU section\n",
    "    heu_current = current_metrics.get('HEU', {})\n",
    "    \n",
    "    # HEU - Prefinancing Payments (PF)\n",
    "    current_pf = heu_current.get('PF', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Prefinancing Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_pf['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"PF\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_pf['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"PF\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_pf['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('PF', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU - Interim Payments (IP)\n",
    "    current_ip_heu = heu_current.get('IP', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Interim Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_ip_heu['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"IP\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_ip_heu['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"IP\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_ip_heu['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('IP', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU - Final Payments (FP)\n",
    "    current_fp_heu = heu_current.get('FP', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Final Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_fp_heu['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"FP\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_fp_heu['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"FP\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_fp_heu['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('FP', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU - Experts Payment (EXPERTS)\n",
    "    current_exp_heu = heu_current.get('EXPERTS', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Experts Payment',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_exp_heu['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"Experts\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_exp_heu['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"Experts\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_exp_heu['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('Experts', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU - Overall\n",
    "    current_heu = heu_current.get('overall', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'HEU',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_heu['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"HEU\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_heu['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"HEU\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_heu['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('HEU', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # TOTAL row\n",
    "    current_total = current_metrics.get('TOTAL', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'TOTAL',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_total['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"ALL\"].get(\"TOTAL\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_total['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"ALL\"].get(\"TOTAL\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_total['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['ALL'].get('TOTAL', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame(comparison_data)\n",
    "\n",
    "def create_ttp_effectiveness_table(df_paym, cutoff, historical_data, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Create TTP effectiveness and efficiency indicators table\n",
    "    \"\"\"\n",
    "    # Calculate current metrics\n",
    "    current_metrics = calculate_current_ttp_metrics(df_paym, cutoff)\n",
    "    \n",
    "    # Determine labels based on cutoff using get_scope_start_end\n",
    "    quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "    last_valid_date = quarter_dates[1]\n",
    "    current_month = pd.to_datetime(last_valid_date).strftime('%b-%y')\n",
    "    \n",
    "    cutoff_date = pd.to_datetime(cutoff)\n",
    "    current_year = cutoff_date.year\n",
    "    historical_label = f\"Dec-{str(current_year-1)[-2:]}\"\n",
    "    \n",
    "    # Load database parameters for admin and expert meetings\n",
    "    from pathlib import Path\n",
    "    DB_PATH = Path(db_path)\n",
    "    report_params = load_report_params(report_name=report_name, db_path=DB_PATH)\n",
    "    \n",
    "    admin_eff = report_params.get(\"Administrative_expenditure_Effectiveness\", {})\n",
    "    admin_ttp = report_params.get(\"Administrative_expenditure_ttp\", {})\n",
    "    expt_meet_eff = report_params.get(\"Expert_meetings_Effectiveness\", {})\n",
    "    expt_meet_ttp = report_params.get(\"Expert_meetings_ttp\", {})\n",
    "    \n",
    "    # Build effectiveness data\n",
    "    effectiveness_data = []\n",
    "    \n",
    "    # Get current metrics for calculations\n",
    "    h2020_current = current_metrics.get('H2020', {})\n",
    "    heu_current = current_metrics.get('HEU', {})\n",
    "    \n",
    "    # Research grants - Interim Payments - H2020\n",
    "    h2020_ip = h2020_current.get('IP', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Interim Payments - H2020',\n",
    "        current_month: f\"{h2020_ip*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('IP', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 90 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants - Final Payments - H2020\n",
    "    h2020_fp = h2020_current.get('FP', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Final Payments - H2020',\n",
    "        current_month: f\"{h2020_fp*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('FP', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 90 days'\n",
    "    })\n",
    "    \n",
    "    # Experts with Appointment Letters H2020\n",
    "    h2020_exp = h2020_current.get('EXPERTS', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Experts with Appointment Letters H2020',\n",
    "        current_month: f\"{h2020_exp*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('Experts', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 30 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants - Pre-financings HEU\n",
    "    heu_pf = heu_current.get('PF', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Pre-financings HEU',\n",
    "        current_month: f\"{heu_pf*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('PF', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 30 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants - Interim Payments HEU\n",
    "    heu_ip = heu_current.get('IP', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Interim Payments HEU',\n",
    "        current_month: f\"{heu_ip*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('IP', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 90 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants - Final Payments HEU\n",
    "    heu_fp = heu_current.get('FP', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Final Payments HEU',\n",
    "        current_month: f\"{heu_fp*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('FP', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 90 days'\n",
    "    })\n",
    "    \n",
    "    # Administrative expenditure (from database)\n",
    "    admin_current = admin_eff.get(\"Current\", 0)\n",
    "    admin_old = admin_eff.get(\"Old\", 0)\n",
    "    admin_target = admin_eff.get(\"Target\", \"99% in 30 days\")\n",
    "    \n",
    "    # Format admin values - handle both percentage (0.985) and already formatted (98.5%) values\n",
    "    if isinstance(admin_current, (int, float)) and admin_current <= 1:\n",
    "        admin_current_str = f\"{admin_current*100:.2f}%\"\n",
    "    else:\n",
    "        admin_current_str = str(admin_current) if admin_current != \"na\" else \"n/a\"\n",
    "        \n",
    "    if isinstance(admin_old, (int, float)) and admin_old <= 1:\n",
    "        admin_old_str = f\"{admin_old*100:.2f}%\"\n",
    "    else:\n",
    "        admin_old_str = str(admin_old) if admin_old != \"na\" else \"n/a\"\n",
    "    \n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Administrative expenditure',\n",
    "        current_month: admin_current_str,\n",
    "        historical_label: admin_old_str,\n",
    "        'Target': admin_target\n",
    "    })\n",
    "    \n",
    "    # Experts with Appointment Letters HEU\n",
    "    heu_exp = heu_current.get('EXPERTS', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Experts with Appointment Letters HEU',\n",
    "        current_month: f\"{heu_exp*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('Experts', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 30 days'\n",
    "    })\n",
    "    \n",
    "    # Expert meetings PMO (from database)\n",
    "    expt_current = expt_meet_eff.get(\"Current\", \"na\")\n",
    "    expt_old = expt_meet_eff.get(\"Old\", \"na\")\n",
    "    expt_target = expt_meet_eff.get(\"Target\", \"n/a\")\n",
    "    \n",
    "    # Format expert values - handle both percentage and string values\n",
    "    if isinstance(expt_current, (int, float)) and expt_current <= 1:\n",
    "        expt_current_str = f\"{expt_current*100:.2f}%\"\n",
    "    else:\n",
    "        expt_current_str = str(expt_current) if expt_current != \"na\" else \"n/a\"\n",
    "        \n",
    "    if isinstance(expt_old, (int, float)) and expt_old <= 1:\n",
    "        expt_old_str = f\"{expt_old*100:.2f}%\"\n",
    "    else:\n",
    "        expt_old_str = str(expt_old) if expt_old != \"na\" else \"n/a\"\n",
    "    \n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Expert meetings PMO',\n",
    "        current_month: expt_current_str,\n",
    "        historical_label: expt_old_str,\n",
    "        'Target': expt_target\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame(effectiveness_data)\n",
    "\n",
    "\n",
    "\n",
    "def create_ttp_days_table(df_paym, cutoff, historical_data, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Create Time to Pay: Average number of days (H2020 - HEU) table\n",
    "    \"\"\"\n",
    "    # Calculate current metrics\n",
    "    current_metrics = calculate_current_ttp_metrics(df_paym, cutoff)\n",
    "    \n",
    "    # Load database parameters for admin and expert meetings\n",
    "    from pathlib import Path\n",
    "    DB_PATH = Path(db_path)\n",
    "    report_params = load_report_params(report_name=report_name, db_path=DB_PATH)\n",
    "    \n",
    "    admin_eff = report_params.get(\"Administrative_expenditure_Effectiveness\", {})\n",
    "    admin_ttp = report_params.get(\"Administrative_expenditure_ttp\", {})\n",
    "    expt_meet_eff = report_params.get(\"Expert_meetings_Effectiveness\", {})\n",
    "    expt_meet_ttp = report_params.get(\"Expert_meetings_ttp\", {})\n",
    "    \n",
    "    # Build days data\n",
    "    days_data = []\n",
    "    \n",
    "    # Get current metrics for calculations\n",
    "    h2020_current = current_metrics.get('H2020', {})\n",
    "    heu_current = current_metrics.get('HEU', {})\n",
    "    \n",
    "    # Research grants (days) - Interim Payments- H2020\n",
    "    h2020_ip = h2020_current.get('IP', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Interim Payments- H2020',\n",
    "        'NET': round(h2020_ip.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(h2020_ip.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '90 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants (days) - Final Payments- H2020\n",
    "    h2020_fp = h2020_current.get('FP', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Final Payments- H2020',\n",
    "        'NET': round(h2020_fp.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(h2020_fp.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '90 days'\n",
    "    })\n",
    "    \n",
    "    # Experts with Appointment Letters (days) H2020\n",
    "    h2020_exp = h2020_current.get('EXPERTS', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Experts with Appointment Letters (days) H2020',\n",
    "        'NET': round(h2020_exp.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(h2020_exp.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants (days) - Pre-financings - HEU\n",
    "    heu_pf = heu_current.get('PF', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Pre-financings - HEU',\n",
    "        'NET': round(heu_pf.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(heu_pf.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants (days) - Interim Payments- HEU\n",
    "    heu_ip = heu_current.get('IP', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Interim Payments- HEU',\n",
    "        'NET': round(heu_ip.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(heu_ip.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '90 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants (days) - Final Payments- HEU\n",
    "    heu_fp = heu_current.get('FP', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Final Payments- HEU',\n",
    "        'NET': round(heu_fp.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(heu_fp.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '90 days'\n",
    "    })\n",
    "    \n",
    "    # Expert with Appointment Letter (days) HEU\n",
    "    heu_exp = heu_current.get('EXPERTS', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Expert with Appointment Letter (days) HEU',\n",
    "        'NET': round(heu_exp.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(heu_exp.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    # Expert meetings (PMO) (days) - from database\n",
    "    expt_net_current = expt_meet_ttp.get(\"Current\", \"na\")\n",
    "    expt_gross_current = expt_meet_ttp.get(\"Current\", \"na\")  # Assuming same for both NET and GROSS\n",
    "    \n",
    "    # Format expert meeting values\n",
    "    if isinstance(expt_net_current, (int, float)):\n",
    "        expt_net_str = str(round(expt_net_current, 1))\n",
    "        expt_gross_str = str(round(expt_gross_current, 1))\n",
    "    else:\n",
    "        expt_net_str = \"n/a\"\n",
    "        expt_gross_str = \"n/a\"\n",
    "    \n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Expert meetings (PMO) (days)',\n",
    "        'NET': expt_net_str,\n",
    "        'GROSS': expt_gross_str,\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    # Administrative expenditure (days) - from database\n",
    "    admin_net_current = admin_ttp.get(\"Current\", 0)\n",
    "    admin_gross_current = admin_ttp.get(\"Current\", 0)  # Assuming same for both NET and GROSS\n",
    "    \n",
    "    # Format admin values\n",
    "    if isinstance(admin_net_current, (int, float)):\n",
    "        admin_net_str = str(round(admin_net_current, 1))\n",
    "        admin_gross_str = str(round(admin_gross_current, 1))\n",
    "    else:\n",
    "        admin_net_str = \"n/a\"\n",
    "        admin_gross_str = \"n/a\"\n",
    "    \n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Administrative expenditure (days)',\n",
    "        'NET': admin_net_str,\n",
    "        'GROSS': admin_gross_str,\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame(days_data)\n",
    "\n",
    "def generate_all_ttp_tables(df_paym, cutoff, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Generate all three TTP tables - comparison table, effectiveness table, and days table\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    comparison_table, effectiveness_table, days_table = generate_all_ttp_tables(df_paym, cutoff)\n",
    "    \"\"\"\n",
    "    # Load historical data\n",
    "    historical_data = load_historical_ttp_data(report_name=report_name, db_path=db_path)\n",
    "    \n",
    "    # Create all three tables\n",
    "    comparison_table = create_ttp_comparison_table(df_paym, cutoff, historical_data)\n",
    "    effectiveness_table = create_ttp_effectiveness_table(df_paym, cutoff, historical_data, report_name, db_path)\n",
    "    days_table = create_ttp_days_table(df_paym, cutoff, historical_data, report_name, db_path)\n",
    "    \n",
    "    return comparison_table, effectiveness_table, days_table\n",
    "\n",
    "# =============================================================================\n",
    "# UPDATED MAIN FUNCTION - USE THIS IN JUPYTER\n",
    "# =============================================================================\n",
    "\n",
    "def generate_ttp_tables(df_paym, cutoff, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Main function to generate all TTP tables\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    comparison_table, effectiveness_table, days_table = generate_ttp_tables(df_paym, cutoff)\n",
    "    \n",
    "    # Display all three tables\n",
    "    print(\"TTP Comparison Table:\")\n",
    "    display(comparison_table)\n",
    "    \n",
    "    print(\"\\nEffectiveness and Efficiency Indicators:\")\n",
    "    display(effectiveness_table)\n",
    "    \n",
    "    print(\"\\nTime to Pay: Average number of days:\")\n",
    "    display(days_table)\n",
    "    \"\"\"\n",
    "    return generate_all_ttp_tables(df_paym, cutoff, report_name, db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de92fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# USAGE IN JUPYTER NOTEBOOK\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# Use this in your Jupyter notebook:\n",
    "comparison_table, effectiveness_table, ttp_days_table = generate_ttp_tables(df_paym, cutoff)\n",
    "comparison_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1776247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "effectiveness_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64016b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttp_days_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41432c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b6833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# =============================================================================\n",
    "# TABLE GENERATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_current_ttp_metrics(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Calculate current TTP metrics from df_paym data, filtering out negative v_TTP_NET\n",
    "    \"\"\"\n",
    "    # Filter data up to cutoff and deduplicate by Pay Payment Key\n",
    "    quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "    last_valid_date = quarter_dates[1]\n",
    "\n",
    "    df_filtered = df_paym[\n",
    "        df_paym['Pay Document Date (dd/mm/yyyy)'] <= last_valid_date\n",
    "    ].copy()\n",
    "    df_unique = df_filtered.drop_duplicates(subset=['Pay Payment Key']).copy()\n",
    "    \n",
    "    # Convert to numeric and filter negative v_TTP_NET\n",
    "    df_unique['v_TTP_NET'] = pd.to_numeric(df_unique['v_TTP_NET'], errors='coerce')\n",
    "    df_unique['v_TTP_GROSS'] = pd.to_numeric(df_unique['v_TTP_GROSS'], errors='coerce')\n",
    "    df_unique['v_payment_in_time'] = pd.to_numeric(df_unique['v_payment_in_time'], errors='coerce')\n",
    "    df_unique = df_unique[df_unique['v_TTP_NET'] >= 0]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Calculate by Programme and Payment Type\n",
    "    for programme in ['H2020', 'HEU']:\n",
    "        prog_data = df_unique[df_unique['Programme'] == programme]\n",
    "        if len(prog_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        results[programme] = {}\n",
    "        \n",
    "        # Overall programme metrics\n",
    "        prog_valid = prog_data[prog_data['v_payment_in_time'].notna()]\n",
    "        results[programme]['overall'] = {\n",
    "            'avg_ttp_net': prog_data['v_TTP_NET'].mean(),\n",
    "            'avg_ttp_gross': prog_data['v_TTP_GROSS'].mean(),\n",
    "            'on_time_pct': prog_data['v_payment_in_time'].sum() / len(prog_valid) if len(prog_valid) > 0 else 0\n",
    "        }\n",
    "        \n",
    "        # By payment type - using correct short form values from v_payment_type\n",
    "        payment_types = ['IP', 'FP', 'EXPERTS', 'PF']  # Short form values\n",
    "        for payment_type in payment_types:\n",
    "            pt_data = prog_data[prog_data['v_payment_type'] == payment_type]\n",
    "            if len(pt_data) > 0:\n",
    "                pt_valid = pt_data[pt_data['v_payment_in_time'].notna()]\n",
    "                results[programme][payment_type] = {\n",
    "                    'avg_ttp_net': pt_data['v_TTP_NET'].mean(),\n",
    "                    'avg_ttp_gross': pt_data['v_TTP_GROSS'].mean(),\n",
    "                    'on_time_pct': pt_data['v_payment_in_time'].sum() / len(pt_valid) if len(pt_valid) > 0 else 0\n",
    "                }\n",
    "    \n",
    "    # Overall total\n",
    "    total_valid = df_unique[df_unique['v_payment_in_time'].notna()]\n",
    "    results['TOTAL'] = {\n",
    "        'avg_ttp_net': df_unique['v_TTP_NET'].mean(),\n",
    "        'avg_ttp_gross': df_unique['v_TTP_GROSS'].mean(),\n",
    "        'on_time_pct': df_unique['v_payment_in_time'].sum() / len(total_valid) if len(total_valid) > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_quarterly_ttp_table(df_paym, cutoff, programme, payment_type):\n",
    "    \"\"\"\n",
    "    Create a quarterly TTP table for a specific programme and payment type\n",
    "    Returns table, programme, payment_type, and a flag indicating if the table is empty\n",
    "    \"\"\"\n",
    "    # Filter data\n",
    "    df_filtered = df_paym[\n",
    "        (df_paym['Pay Document Date (dd/mm/yyyy)'] <= pd.to_datetime(cutoff)) &\n",
    "        (df_paym['Programme'] == programme) &\n",
    "        (df_paym['v_payment_type'] == payment_type)\n",
    "    ].copy()\n",
    "    \n",
    "    # If no data after filtering, return an empty table with a flag\n",
    "    if df_filtered.empty:\n",
    "        empty_table = pd.DataFrame(columns=['Quarter', 'ADG', 'COG', 'POC', 'STG', 'SYG', 'Total'])\n",
    "        return empty_table, programme, payment_type, True\n",
    "    \n",
    "    # Convert to numeric and filter negative TTP_NET\n",
    "    df_filtered['v_TTP_NET'] = pd.to_numeric(df_filtered['v_TTP_NET'], errors='coerce')\n",
    "    df_filtered = df_filtered[df_filtered['v_TTP_NET'] >= 0]\n",
    "    \n",
    "    # If all TTP_NET values are filtered out, return an empty table\n",
    "    if df_filtered.empty:\n",
    "        empty_table = pd.DataFrame(columns=['Quarter', 'ADG', 'COG', 'POC', 'STG', 'SYG', 'Total'])\n",
    "        return empty_table, programme, payment_type, True\n",
    "    \n",
    "    # Extract quarter from date\n",
    "    df_filtered['Quarter'] = pd.to_datetime(df_filtered['Pay Document Date (dd/mm/yyyy)']).dt.to_period('Q').astype(str)\n",
    "    \n",
    "    # Use call_type as CallType (based on logs)\n",
    "    if 'call_type' not in df_filtered.columns:\n",
    "        df_filtered['call_type'] = 'Default'  # Placeholder if call_type is missing\n",
    "    df_filtered['CallType'] = df_filtered['call_type']\n",
    "    \n",
    "    # Aggregate by Quarter and CallType (using v_TTP_NET mean as metric)\n",
    "    quarterly_data = df_filtered.groupby(['Quarter', 'CallType']).agg({\n",
    "        'v_TTP_NET': 'mean'\n",
    "    }).round(1).unstack(fill_value=0)\n",
    "    \n",
    "    # Rename columns to match call types from logs (ADG, COG, etc.)\n",
    "    quarterly_data.columns = [f'{col[1]}' for col in quarterly_data.columns]\n",
    "    \n",
    "    # Add total row (mean across quarters for each call type)\n",
    "    total_row = quarterly_data.mean().rename('Total')\n",
    "    quarterly_table = pd.concat([quarterly_data, total_row.to_frame().T])\n",
    "    \n",
    "    # Simplify index to only include Quarter\n",
    "    quarterly_table.index = quarterly_table.index.droplevel([1, 2]) if isinstance(quarterly_table.index, pd.MultiIndex) else quarterly_table.index\n",
    "    \n",
    "    return quarterly_table, programme, payment_type, False\n",
    "\n",
    "def generate_quarterly_tables(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Generate quarterly TTP tables for each programme and payment type\n",
    "    Includes a flag to indicate empty tables\n",
    "    \"\"\"\n",
    "    tables = {}\n",
    "    payment_types = ['IP', 'FP', 'EXPERTS', 'PF']  # Short form values\n",
    "    programs = ['H2020', 'HEU']\n",
    "\n",
    "    for prog in programs:\n",
    "        for pt in payment_types:\n",
    "            table, program, payment_type, is_empty = create_quarterly_ttp_table(df_paym, cutoff, prog, pt)\n",
    "            tables[f'{prog}_{pt}_table'] = {\n",
    "                'table': table,\n",
    "                'programme': program,\n",
    "                'payment_type': payment_type,\n",
    "                'is_empty': is_empty\n",
    "            }\n",
    "\n",
    "    return tables\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN USAGE FOR TABLES\n",
    "# =============================================================================\n",
    "\n",
    "def main_tables(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Main function to generate and display quarterly TTP tables\n",
    "    \"\"\"\n",
    "    # Generate tables\n",
    "    quarterly_tables = generate_quarterly_tables(df_paym, cutoff)\n",
    "    \n",
    "    # Display tables (in Jupyter Notebook)\n",
    "    for key, data in quarterly_tables.items():\n",
    "        table = data['table']\n",
    "        program = data['programme']\n",
    "        payment_type = data['payment_type']\n",
    "        is_empty = data['is_empty']\n",
    "        print(f\"\\n{key} (Programme: {program}, Payment Type: {payment_type}, Empty: {is_empty}):\")\n",
    "        display(table)\n",
    "    \n",
    "    return quarterly_tables\n",
    "\n",
    "# Example usage (uncomment to run)\n",
    "# quarterly_tables = main_tables(df_paym, cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b359d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example usage (uncomment to run)\n",
    "quarterly_tables = main_tables(df_paym, cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import time\n",
    "import warnings\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "\n",
    "# Suppress the Altair FutureWarning about convert_dtype\n",
    "warnings.filterwarnings(\"ignore\", message=\".*convert_dtype.*\", category=FutureWarning)\n",
    "\n",
    "def rolling_ttp(df,programme,typeofpayment):\n",
    "    \n",
    "        start, end  = get_scope_start_end(cutoff)\n",
    "        last_month = int(end.month)\n",
    "        i = 1\n",
    "        moving_avg_ttp = []\n",
    "        months = []\n",
    "\n",
    "        quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "        last_valid_date = quarter_dates[1]\n",
    "\n",
    "        df_filtered = df[\n",
    "                df['Pay Document Date (dd/mm/yyyy)'] <= last_valid_date\n",
    "        ].copy()\n",
    "        df_unique = df_filtered.drop_duplicates(subset=['Pay Payment Key']).copy()\n",
    "        \n",
    "        # Convert to numeric and filter negative v_TTP_NET\n",
    "        df_unique['v_TTP_NET'] = pd.to_numeric(df_unique['v_TTP_NET'], errors='coerce')\n",
    "        df_unique['v_TTP_GROSS'] = pd.to_numeric(df_unique['v_TTP_GROSS'], errors='coerce')\n",
    "        df_unique['v_payment_in_time'] = pd.to_numeric(df_unique['v_payment_in_time'], errors='coerce')\n",
    "        df_unique = df_unique[df_unique['v_TTP_NET'] >= 0]\n",
    "\n",
    "        while i <= last_month : \n",
    "                df_test =  df_unique.loc[( df_unique['Programme'] == programme) & ( df_unique['v_payment_type'] == typeofpayment) & ( df_unique['Month']<= i )]    \n",
    "                mean = round(df_test['TTP_NET'].mean(),1)\n",
    "                moving_avg_ttp.insert(i,mean)\n",
    "                months.insert(i,i)\n",
    "                i+=1\n",
    "\n",
    "        d = {'Month': months, 'TTP': moving_avg_ttp}\n",
    "        df_mov_ttp = pd.DataFrame(data=d)\n",
    "        return df_mov_ttp \n",
    "\n",
    "def avg_ttp(df,programme,typeofpayment):\n",
    "    \n",
    "        start, end  = get_scope_start_end(cutoff)\n",
    "        last_month = int(end.month)\n",
    "        i = 1\n",
    "        moving_avg_ttp = []\n",
    "        months = []\n",
    "\n",
    "        quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "        last_valid_date = quarter_dates[1]\n",
    "\n",
    "        df_filtered = df[\n",
    "                df['Pay Document Date (dd/mm/yyyy)'] <= last_valid_date\n",
    "        ].copy()\n",
    "        df_unique = df_filtered.drop_duplicates(subset=['Pay Payment Key']).copy()\n",
    "        \n",
    "        # Convert to numeric and filter negative v_TTP_NET\n",
    "        df_unique['v_TTP_NET'] = pd.to_numeric(df_unique['v_TTP_NET'], errors='coerce')\n",
    "        df_unique['v_TTP_GROSS'] = pd.to_numeric(df_unique['v_TTP_GROSS'], errors='coerce')\n",
    "        df_unique['v_payment_in_time'] = pd.to_numeric(df_unique['v_payment_in_time'], errors='coerce')\n",
    "        df_unique = df_unique[df_unique['v_TTP_NET'] >= 0]\n",
    "\n",
    "        pivot_ttp_month =  df_unique.pivot_table( index= df_unique[[\"Month\"]], values= df_unique[['TTP_NET']],fill_value=0,aggfunc='mean')\n",
    "        pivot_ttp_month['TTP_NET'] = pivot_ttp_month['TTP_NET'].round(1)\n",
    "        #pivot_ttp_month.columns =  pivot_ttp_month.columns.droplevel()\n",
    "        pivot_ttp_month.reset_index(inplace = True)\n",
    "\n",
    "        return pivot_ttp_month\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CHART GENERATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def chart_machine_ttp(df, paymentType, prog, avg, rollingAvg):\n",
    "    \"\"\"Clean version with all positioning and styling issues fixed\"\"\"\n",
    "    \n",
    "    # Time limits\n",
    "    time_limits = {\n",
    "        'PF': 30, 'EXPERTS': 30, 'IP': 90, 'FP': 90\n",
    "    }\n",
    "    time_limit = time_limits.get(paymentType, 90)\n",
    "    \n",
    "    # Clean data\n",
    "    df_clean = df.copy()\n",
    "    df_clean['Month'] = pd.to_numeric(df_clean['Month'], errors='coerce')\n",
    "    df_clean['TTP_NET'] = pd.to_numeric(df_clean['TTP_NET'], errors='coerce')\n",
    "    df_clean = df_clean.dropna(subset=['Month', 'TTP_NET'])\n",
    "    \n",
    "    rollingAvg_clean = rollingAvg.copy()\n",
    "    rollingAvg_clean['Month'] = pd.to_numeric(rollingAvg_clean['Month'], errors='coerce')\n",
    "    rollingAvg_clean['TTP'] = pd.to_numeric(rollingAvg_clean['TTP'], errors='coerce')\n",
    "    rollingAvg_clean = rollingAvg_clean.dropna()\n",
    "    \n",
    "    if df_clean.empty:\n",
    "        return alt.Chart().mark_text(text=\"No data available\")\n",
    "    \n",
    "    # Calculate Y-axis range - extend if values are close to limits\n",
    "    max_value = max(\n",
    "        df_clean['TTP_NET'].max() if not df_clean.empty else 0,\n",
    "        rollingAvg_clean['TTP'].max() if not rollingAvg_clean.empty else 0,\n",
    "        time_limit\n",
    "    )\n",
    "    \n",
    "    # Extend Y-axis if monthly average is close to time limit (within 10 days)\n",
    "    if abs(avg - time_limit) <= 10:\n",
    "        y_max = max_value * 1.2  # Extend by 20%\n",
    "    else:\n",
    "        y_max = max_value * 1.1  # Normal 10% extension\n",
    "    \n",
    "    # Get last month with data for triangle positioning\n",
    "    last_month_with_data = df_clean['Month'].max() if not df_clean.empty else 1\n",
    "    start, end = get_scope_start_end(cutoff)\n",
    "    year = int(end.year)\n",
    "    \n",
    "    # Get rolling average value for triangle positioning - position exactly on the line\n",
    "    last_rolling_value = rollingAvg_clean[\n",
    "        rollingAvg_clean['Month'] == last_month_with_data\n",
    "    ]['TTP'].values\n",
    "    triangle_y_pos = last_rolling_value[0] if len(last_rolling_value) > 0 else avg\n",
    "    \n",
    "    # Create triangle annotation data positioned on the rolling average line\n",
    "    triangle_data = pd.DataFrame({\n",
    "        'Month': [last_month_with_data],\n",
    "        'TTP': [triangle_y_pos],  # Exact position on rolling average line\n",
    "        'Triangle': ['⯆'],  # Down-pointing arrow\n",
    "        'Comment': [f'{prog} Average {year} = {avg}']\n",
    "    })\n",
    "    \n",
    "    # Main bars with darker color for better label visibility\n",
    "    bars = alt.Chart(df_clean).mark_bar(\n",
    "        opacity=0.8,\n",
    "        color='#4682B4'  # Darker steel blue for better contrast\n",
    "    ).encode(\n",
    "        x=alt.X('Month:O', title='Month'),\n",
    "        y=alt.Y('TTP_NET:Q', title='Days', scale=alt.Scale(domain=[0, y_max]))\n",
    "    )\n",
    "    \n",
    "    # Bar labels with darker color for visibility\n",
    "    bar_labels = bars.mark_text(\n",
    "        dy=-8,\n",
    "        fontSize=11,\n",
    "        fontWeight='bold',\n",
    "        color=\"#0A6BBA\"  # Dark blue for better visibility\n",
    "    ).encode(\n",
    "        text=alt.Text('TTP_NET:Q', format='.1f')\n",
    "    )\n",
    "    \n",
    "    # Rolling average line - keeping red as requested\n",
    "    avg_line = alt.Chart(rollingAvg_clean).mark_line(\n",
    "        color='#DC143C',  # Crimson red\n",
    "        strokeWidth=3,\n",
    "        strokeDash=[5, 5]\n",
    "    ).encode(\n",
    "        x=alt.X('Month:O'),\n",
    "        y=alt.Y('TTP:Q', scale=alt.Scale(domain=[0, y_max]))\n",
    "    )\n",
    "    \n",
    "    # Time limit line - keeping orange\n",
    "    limit_line = alt.Chart(pd.DataFrame({\n",
    "        'Month': list(range(1, 13)),\n",
    "        'limit': [time_limit] * 12\n",
    "    })).mark_line(\n",
    "        color='#FF8C00',  # Dark orange\n",
    "        strokeWidth=2\n",
    "    ).encode(\n",
    "        x=alt.X('Month:O'),\n",
    "        y=alt.Y('limit:Q', scale=alt.Scale(domain=[0, y_max]))\n",
    "    )\n",
    "    \n",
    "    # Triangle positioned next to the rolling average line\n",
    "    triangle = alt.Chart(triangle_data).mark_text(\n",
    "        dx=15,   # Small offset to the right of the data point\n",
    "        dy=-5,   # Slightly above the rolling average line\n",
    "        fontSize=25,  # Bigger arrow\n",
    "        color='orange',\n",
    "        fontWeight='bold'\n",
    "    ).encode(\n",
    "        x=alt.X('Month:O'),\n",
    "        y=alt.Y('TTP:Q', scale=alt.Scale(domain=[0, y_max])),\n",
    "        text='Triangle:N'\n",
    "    )\n",
    "    \n",
    "    # Annotation text positioned above the triangle\n",
    "    annotation = alt.Chart(triangle_data).mark_text(\n",
    "        dx=15,   # Aligned with triangle\n",
    "        dy=-25,  # Above the triangle\n",
    "        fontSize=12,\n",
    "        fontWeight='bold',\n",
    "        color='#1B5390',\n",
    "        align='left'\n",
    "    ).encode(\n",
    "        x=alt.X('Month:O'),\n",
    "        y=alt.Y('TTP:Q', scale=alt.Scale(domain=[0, y_max])),\n",
    "        text='Comment:N'\n",
    "    )\n",
    "    \n",
    "    # Create unified legend data\n",
    "    legend_data = pd.DataFrame({\n",
    "        'Legend': ['Monthly Values', 'Rolling Average', 'Contractual Limit'],\n",
    "        'Month': [1, 1, 1],  # Dummy values for positioning\n",
    "        'Value': [0, 0, 0],   # Dummy values\n",
    "        'Color': ['#4682B4', '#DC143C', '#FF8C00']\n",
    "    })\n",
    "    \n",
    "    # Create legend as separate marks\n",
    "    legend_bars = alt.Chart(legend_data).mark_rect(\n",
    "        width=15,\n",
    "        height=15\n",
    "    ).encode(\n",
    "        x=alt.X('Legend:N', title=None, axis=alt.Axis(labelAngle=0)),\n",
    "        color=alt.Color('Color:N', scale=None, legend=None)\n",
    "    ).properties(\n",
    "        width=400,\n",
    "        height=30\n",
    "    ).resolve_scale(color='independent')\n",
    "    \n",
    "    # Main chart\n",
    "    main_chart = (bars + bar_labels + avg_line + limit_line + triangle + annotation).properties(\n",
    "        width=600,\n",
    "        height=300,\n",
    "        title=alt.TitleParams(\n",
    "            text=f'{prog} {paymentType} - Time to Pay Analysis',\n",
    "            fontSize=16,\n",
    "            fontWeight='bold',\n",
    "            anchor='start',\n",
    "            color='#1B5390'\n",
    "        )\n",
    "    ).resolve_scale(\n",
    "        color='independent'\n",
    "    )\n",
    "    \n",
    "    # Combine main chart with legend\n",
    "    final_chart = alt.vconcat(\n",
    "        main_chart,\n",
    "        legend_bars\n",
    "    ).resolve_scale(\n",
    "        color='independent'\n",
    "    )\n",
    "    \n",
    "    return final_chart\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL GENERATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def generate_charts(df_paym, cutoff, quarterly_tables):\n",
    "    \"\"\"\n",
    "    Generate TTP charts for each programme and payment type, skipping empty tables\n",
    "    \"\"\"\n",
    "    charts = {}\n",
    "    payment_types = ['IP', 'FP', 'EXPERTS', 'PF']  # Short form values\n",
    "    programs = ['H2020', 'HEU']\n",
    "\n",
    "    for prog in programs:\n",
    "        for pt in payment_types:\n",
    "            table_key = f'{prog}_{pt}_table'\n",
    "            # Skip chart generation if the corresponding table is empty\n",
    "            if quarterly_tables[table_key]['is_empty']:\n",
    "                print(f\"Skipping chart for {table_key} (empty table)\")\n",
    "                continue\n",
    "\n",
    "            # Prepare data for chart\n",
    "            df_chart = df_paym[\n",
    "                (df_paym['Programme'] == prog) &\n",
    "                (df_paym['v_payment_type'] == pt)\n",
    "            ].copy()\n",
    "            df_chart['Month'] = pd.to_datetime(df_chart['Pay Document Date (dd/mm/yyyy)']).dt.month\n",
    "            df_chart['TTP_NET'] = pd.to_numeric(df_chart['v_TTP_NET'], errors='coerce')\n",
    "            df_chart = df_chart[df_chart['TTP_NET'] >= 0]\n",
    "\n",
    "            # If df_chart is empty, this should be caught by the table check above, but confirm\n",
    "            if df_chart.empty:\n",
    "                print(f\"Data for chart {table_key} is empty, but table flag not set correctly\")\n",
    "                continue\n",
    "\n",
    "            # Calculate average for this combination\n",
    "            current_metrics = calculate_current_ttp_metrics(df_chart, cutoff)\n",
    "            avg_ttp_net = round(float(current_metrics[prog][pt]['avg_ttp_net']),1)if pt in current_metrics[prog] else 0\n",
    "            rolling_avg = rolling_ttp(df_chart, prog, pt)\n",
    "\n",
    "            df_ttp = avg_ttp(df_chart, prog, pt)\n",
    "\n",
    "            # Generate chart\n",
    "            chart = chart_machine_ttp(df_ttp, pt, prog, avg_ttp_net, rolling_avg)\n",
    "            logger.debug(f\"Generated tta_chart_img for {prog, '{prog}_{pt}_chart'}\")\n",
    "            \n",
    "            var_name = f'{prog}_{pt}_ttp_chart'\n",
    "            try:\n",
    "                logger.debug(f\"Saving {var_name} to database\")\n",
    "                insert_variable(\n",
    "                    report=report, module=\"PaymentsModule\", var=var_name,\n",
    "                    value=df_ttp,\n",
    "                    db_path=db_path, anchor=var_name, altair_chart=chart\n",
    "                )\n",
    "                logger.debug(f\"Saved {var_name} to database\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to save {var_name}: {str(e)}\")\n",
    "\n",
    "            charts[f'{prog}_{pt}_chart'] = chart\n",
    "            \n",
    "\n",
    "    return charts\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN USAGE FOR CHARTS\n",
    "# =============================================================================\n",
    "\n",
    "def main_charts(df_paym, cutoff, quarterly_tables):\n",
    "    \"\"\"\n",
    "    Main function to generate and display TTP charts, skipping empty tables\n",
    "    \"\"\"\n",
    "    # Generate charts\n",
    "    ttp_charts = generate_charts(df_paym, cutoff, quarterly_tables)\n",
    "    \n",
    "    # Display charts (in Jupyter Notebook)\n",
    "    for key, chart in ttp_charts.items():\n",
    "        print(f\"\\n{key}:\")\n",
    "        display(chart)\n",
    "    \n",
    "    return ttp_charts\n",
    "\n",
    "# Example usage (uncomment to run after generating tables)\n",
    "# ttp_charts = main_charts(df_paym, cutoff, quarterly_tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893d6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttp_charts = main_charts(df_paym, cutoff, quarterly_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc09283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_effectiveness_breakdown(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Create effectiveness breakdown tables by directorate and payment type\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter data up to cutoff and deduplicate by Pay Payment Key\n",
    "    quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "    last_valid_date = quarter_dates[1]\n",
    "\n",
    "    df_filtered = df_paym[\n",
    "        df_paym['Pay Document Date (dd/mm/yyyy)'] <= last_valid_date\n",
    "    ].copy()\n",
    "    df_unique = df_filtered.drop_duplicates(subset=['Pay Payment Key']).copy()\n",
    "    \n",
    "    # Convert to numeric\n",
    "    df_unique['v_TTP_NET'] = pd.to_numeric(df_unique['v_TTP_NET'], errors='coerce')\n",
    "    df_unique['v_TTP_GROSS'] = pd.to_numeric(df_unique['v_TTP_GROSS'], errors='coerce')\n",
    "    df_unique['v_payment_in_time'] = pd.to_numeric(df_unique['v_payment_in_time'], errors='coerce')\n",
    "    \n",
    "    # Filter out negative TTP_NET values\n",
    "    df_unique = df_unique[df_unique['v_TTP_NET'] >= 0]\n",
    "    \n",
    "    # Determine year label from cutoff\n",
    "    cutoff_date = pd.to_datetime(cutoff)\n",
    "    current_year = cutoff_date.year\n",
    "    year_label = f\"{current_year} - YTD\"\n",
    "    \n",
    "    return df_unique, year_label\n",
    "\n",
    "def create_quarterly_ttp_breakdown(df_paym, cutoff, metric_type='NET'):\n",
    "    \"\"\"\n",
    "    Create quarterly TTP breakdown tables by directorate and payment type\n",
    "    \n",
    "    Parameters:\n",
    "    - df_paym: Payment data DataFrame\n",
    "    - cutoff: Cutoff date for analysis\n",
    "    - metric_type: 'NET' or 'GROSS' for which TTP metric to use\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter data up to cutoff and deduplicate by Pay Payment Key\n",
    "    quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "    last_valid_date = quarter_dates[1]\n",
    "\n",
    "    df_filtered = df_paym[\n",
    "        df_paym['Pay Document Date (dd/mm/yyyy)'] <= last_valid_date\n",
    "    ].copy()\n",
    "    df_unique = df_filtered.drop_duplicates(subset=['Pay Payment Key']).copy()\n",
    "    \n",
    "    # Convert to numeric\n",
    "    df_unique['v_TTP_NET'] = pd.to_numeric(df_unique['v_TTP_NET'], errors='coerce')\n",
    "    df_unique['v_TTP_GROSS'] = pd.to_numeric(df_unique['v_TTP_GROSS'], errors='coerce')\n",
    "    df_unique['v_payment_in_time'] = pd.to_numeric(df_unique['v_payment_in_time'], errors='coerce')\n",
    "    \n",
    "    # Filter out negative TTP_NET values\n",
    "    df_unique = df_unique[df_unique['v_TTP_NET'] >= 0]\n",
    "    \n",
    "    # Extract quarter from date\n",
    "    df_unique['Quarter'] = pd.to_datetime(df_unique['Pay Document Date (dd/mm/yyyy)']).dt.to_period('Q')\n",
    "    \n",
    "    # Create quarter labels (e.g., 2024Q1, 2024Q2, etc.)\n",
    "    df_unique['Quarter_Label'] = df_unique['Quarter'].astype(str)\n",
    "    \n",
    "    # Get unique quarters and sort them\n",
    "    quarters = sorted(df_unique['Quarter_Label'].unique())\n",
    "    \n",
    "    return quarters, df_unique\n",
    "\n",
    "def create_h2020_quarterly_table(df_paym, cutoff, metric_type='NET'):\n",
    "    \"\"\"\n",
    "    Create H2020 quarterly breakdown table with MultiIndex columns\n",
    "    \"\"\"\n",
    "    quarters, df_unique = create_quarterly_ttp_breakdown(df_paym, cutoff, metric_type)\n",
    "    \n",
    "    # Filter for H2020\n",
    "    h2020_data = df_unique[df_unique['Programme'] == 'H2020'].copy()\n",
    "    \n",
    "    # Get actual directorates from the data\n",
    "    available_directorates = sorted([d for d in h2020_data['call_type'].unique() if pd.notna(d)])\n",
    "    \n",
    "    # Define payment types based on the image structure\n",
    "    payment_types_h2020 = ['FP', 'IP']  # Final Payments and Interim Payments\n",
    "    \n",
    "    # Create MultiIndex columns structure\n",
    "    columns = []\n",
    "    \n",
    "    # Add directorate columns\n",
    "    for dir_name in available_directorates:\n",
    "        for pt in payment_types_h2020:\n",
    "            columns.append((dir_name, pt))\n",
    "    \n",
    "    # Add Experts column (single column, no sub-payment types)\n",
    "    columns.append(('Experts', 'Experts'))\n",
    "    \n",
    "    # Add Total column  \n",
    "    columns.append(('Total', 'Total'))\n",
    "    \n",
    "    multi_columns = pd.MultiIndex.from_tuples(columns, names=['Directorate', 'Payment_Type'])\n",
    "    \n",
    "    # Create DataFrame with quarters as index\n",
    "    quarters_with_summary = quarters + ['Dep C.']\n",
    "    quarterly_data = pd.DataFrame(index=quarters_with_summary, columns=multi_columns, dtype=float)\n",
    "    \n",
    "    ttp_column = f'v_TTP_{metric_type}'\n",
    "    \n",
    "    # Fill quarterly data\n",
    "    for quarter in quarters:\n",
    "        quarter_data = h2020_data[h2020_data['Quarter_Label'] == quarter]\n",
    "        \n",
    "        # Fill directorate data\n",
    "        for dir_name in available_directorates:\n",
    "            dir_data = quarter_data[quarter_data['call_type'] == dir_name]\n",
    "            \n",
    "            for pt in payment_types_h2020:\n",
    "                pt_data = dir_data[dir_data['v_payment_type'] == pt]\n",
    "                avg_ttp = pt_data[ttp_column].mean() if len(pt_data) > 0 else 0\n",
    "                quarterly_data.loc[quarter, (dir_name, pt)] = round(avg_ttp, 1) if not pd.isna(avg_ttp) else 0.0\n",
    "        \n",
    "        # Experts\n",
    "        experts_data = quarter_data[quarter_data['v_payment_type'] == 'EXPERTS']\n",
    "        experts_avg = experts_data[ttp_column].mean() if len(experts_data) > 0 else 0\n",
    "        quarterly_data.loc[quarter, ('Experts', 'Experts')] = round(experts_avg, 1) if not pd.isna(experts_avg) else 0.0\n",
    "        \n",
    "        # Total\n",
    "        total_avg = quarter_data[ttp_column].mean() if len(quarter_data) > 0 else 0\n",
    "        quarterly_data.loc[quarter, ('Total', 'Total')] = round(total_avg, 1) if not pd.isna(total_avg) else 0.0\n",
    "    \n",
    "    # Fill Dep C. summary row\n",
    "    for dir_name in available_directorates:\n",
    "        dir_data = h2020_data[h2020_data['call_type'] == dir_name]\n",
    "        \n",
    "        for pt in payment_types_h2020:\n",
    "            pt_data = dir_data[dir_data['v_payment_type'] == pt]\n",
    "            avg_ttp = pt_data[ttp_column].mean() if len(pt_data) > 0 else 0\n",
    "            quarterly_data.loc['Dep C.', (dir_name, pt)] = round(avg_ttp, 1) if not pd.isna(avg_ttp) else 0.0\n",
    "    \n",
    "    # Overall experts and total for Dep C.\n",
    "    experts_overall = h2020_data[h2020_data['v_payment_type'] == 'EXPERTS'][ttp_column].mean()\n",
    "    quarterly_data.loc['Dep C.', ('Experts', 'Experts')] = round(experts_overall, 1) if not pd.isna(experts_overall) else 0.0\n",
    "    \n",
    "    total_overall = h2020_data[ttp_column].mean()\n",
    "    quarterly_data.loc['Dep C.', ('Total', 'Total')] = round(total_overall, 1) if not pd.isna(total_overall) else 0.0\n",
    "    \n",
    "    # Convert to numeric and handle any remaining NaN values\n",
    "    quarterly_data = quarterly_data.fillna(0.0).infer_objects(copy=False).astype(float)\n",
    "    \n",
    "    return quarterly_data\n",
    "\n",
    "def create_heu_quarterly_table(df_paym, cutoff, metric_type='NET'):\n",
    "    \"\"\"\n",
    "    Create HEU quarterly breakdown table with MultiIndex columns\n",
    "    \"\"\"\n",
    "    quarters, df_unique = create_quarterly_ttp_breakdown(df_paym, cutoff, metric_type)\n",
    "    \n",
    "    # Filter for HEU\n",
    "    heu_data = df_unique[df_unique['Programme'] == 'HEU'].copy()\n",
    "    \n",
    "    # Get actual directorates from the data\n",
    "    available_directorates = sorted([d for d in heu_data['call_type'].unique() if pd.notna(d)])\n",
    "    \n",
    "    # Create MultiIndex columns structure based on image\n",
    "    columns = []\n",
    "    \n",
    "    # Based on image: ADG(PF,IP), COG(PF,FP), POC(PF,IP), STG(PF,IP), SYG(PF)\n",
    "    directorate_payment_mapping = {\n",
    "        'ADG': ['PF', 'IP'],\n",
    "        'COG': ['PF', 'FP'], \n",
    "        'POC': ['PF', 'IP'],\n",
    "        'STG': ['PF', 'IP'],\n",
    "        'SYG': ['PF']\n",
    "    }\n",
    "    \n",
    "    # Add columns for available directorates\n",
    "    for dir_name in available_directorates:\n",
    "        if dir_name in directorate_payment_mapping:\n",
    "            for pt in directorate_payment_mapping[dir_name]:\n",
    "                columns.append((dir_name, pt))\n",
    "    \n",
    "    # Add Experts column\n",
    "    columns.append(('Experts', 'Experts'))\n",
    "    \n",
    "    # Add Total column  \n",
    "    columns.append(('Total', 'Total'))\n",
    "    \n",
    "    multi_columns = pd.MultiIndex.from_tuples(columns, names=['Directorate', 'Payment_Type'])\n",
    "    \n",
    "    # Create DataFrame with quarters as index\n",
    "    quarters_with_summary = quarters + ['Dep C.']\n",
    "    quarterly_data = pd.DataFrame(index=quarters_with_summary, columns=multi_columns, dtype=float)\n",
    "\n",
    "    \n",
    "    ttp_column = f'v_TTP_{metric_type}'\n",
    "    \n",
    "    # Fill quarterly data\n",
    "    for quarter in quarters:\n",
    "        quarter_data = heu_data[heu_data['Quarter_Label'] == quarter]\n",
    "        \n",
    "        # Fill directorate data\n",
    "        for dir_name in available_directorates:\n",
    "            if dir_name in directorate_payment_mapping:\n",
    "                dir_data = quarter_data[quarter_data['call_type'] == dir_name]\n",
    "                \n",
    "                for pt in directorate_payment_mapping[dir_name]:\n",
    "                    pt_data = dir_data[dir_data['v_payment_type'] == pt]\n",
    "                    avg_ttp = pt_data[ttp_column].mean() if len(pt_data) > 0 else 0\n",
    "                    quarterly_data.loc[quarter, (dir_name, pt)] = round(avg_ttp, 1) if not pd.isna(avg_ttp) else 0.0\n",
    "        \n",
    "        # Experts\n",
    "        experts_data = quarter_data[quarter_data['v_payment_type'] == 'EXPERTS']\n",
    "        experts_avg = experts_data[ttp_column].mean() if len(experts_data) > 0 else 0\n",
    "        quarterly_data.loc[quarter, ('Experts', 'Experts')] = round(experts_avg, 1) if not pd.isna(experts_avg) else 0.0\n",
    "        \n",
    "        # Total\n",
    "        total_avg = quarter_data[ttp_column].mean() if len(quarter_data) > 0 else 0\n",
    "        quarterly_data.loc[quarter, ('Total', 'Total')] = round(total_avg, 1) if not pd.isna(total_avg) else 0.0\n",
    "    \n",
    "    # Fill Dep C. summary row\n",
    "    for dir_name in available_directorates:\n",
    "        if dir_name in directorate_payment_mapping:\n",
    "            dir_data = heu_data[heu_data['call_type'] == dir_name]\n",
    "            \n",
    "            for pt in directorate_payment_mapping[dir_name]:\n",
    "                pt_data = dir_data[dir_data['v_payment_type'] == pt]\n",
    "                avg_ttp = pt_data[ttp_column].mean() if len(pt_data) > 0 else 0\n",
    "                quarterly_data.loc['Dep C.', (dir_name, pt)] = round(avg_ttp, 1) if not pd.isna(avg_ttp) else 0.0\n",
    "    \n",
    "    # Overall experts and total for Dep C.\n",
    "    experts_overall = heu_data[heu_data['v_payment_type'] == 'EXPERTS'][ttp_column].mean()\n",
    "    quarterly_data.loc['Dep C.', ('Experts', 'Experts')] = round(experts_overall, 1) if not pd.isna(experts_overall) else 0.0\n",
    "    \n",
    "    total_overall = heu_data[ttp_column].mean()\n",
    "    quarterly_data.loc['Dep C.', ('Total', 'Total')] = round(total_overall, 1) if not pd.isna(total_overall) else 0.0\n",
    "    \n",
    "    # Convert to numeric and handle any remaining NaN values\n",
    "    quarterly_data = quarterly_data.fillna(0.0).infer_objects(copy=False).astype(float)\n",
    "    \n",
    "    return quarterly_data\n",
    "\n",
    "def generate_quarterly_breakdown_tables(df_paym, cutoff, metric_type='NET'):\n",
    "    \"\"\"\n",
    "    Generate both H2020 and HEU quarterly breakdown tables with MultiIndex columns\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    h2020_table, heu_table = generate_quarterly_breakdown_tables(df_paym, cutoff, 'NET')\n",
    "    \n",
    "    # Display tables\n",
    "    print(\"H2020 Quarterly Breakdown:\")\n",
    "    display(h2020_table)\n",
    "    \n",
    "    print(\"\\nHEU Quarterly Breakdown:\")\n",
    "    display(heu_table)\n",
    "    \n",
    "    # Access MultiIndex structure:\n",
    "    print(\"HEU columns:\", heu_table.columns.tolist())\n",
    "    print(\"Data for ADG-PF:\", heu_table[('ADG', 'PF')])\n",
    "    \"\"\"\n",
    "    h2020_table = create_h2020_quarterly_table(df_paym, cutoff, metric_type)\n",
    "    heu_table = create_heu_quarterly_table(df_paym, cutoff, metric_type)\n",
    "    \n",
    "    return h2020_table, heu_table\n",
    "\n",
    "def create_h2020_effectiveness_table(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Create H2020 effectiveness breakdown table by directorate\n",
    "    \"\"\"\n",
    "    df_unique, year_label = create_effectiveness_breakdown(df_paym, cutoff)\n",
    "    \n",
    "    # Filter for H2020\n",
    "    h2020_data = df_unique[df_unique['Programme'] == 'H2020'].copy()\n",
    "    \n",
    "    # Get actual directorates from the data\n",
    "    available_directorates = sorted([d for d in h2020_data['call_type'].unique() if pd.notna(d)])\n",
    "    \n",
    "    # Build table data\n",
    "    table_data = []\n",
    "    \n",
    "    # Calculate effectiveness for each directorate\n",
    "    for dir_name in available_directorates:\n",
    "        dir_data = h2020_data[h2020_data['call_type'] == dir_name]\n",
    "        row = {'call_type': dir_name}\n",
    "        \n",
    "        # Final Payments (30 days target)\n",
    "        fp_data = dir_data[dir_data['v_payment_type'] == 'FP']\n",
    "        if len(fp_data) > 0:\n",
    "            fp_valid = fp_data[fp_data['v_payment_in_time'].notna()]\n",
    "            fp_effectiveness = (fp_data['v_payment_in_time'].sum() / len(fp_valid) * 100) if len(fp_valid) > 0 else 0\n",
    "            row[f'Final Payments - The contractual time limit is 30 days {year_label}'] = f\"{fp_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'Final Payments - The contractual time limit is 30 days {year_label}'] = \"-\"\n",
    "        \n",
    "        # Interim Payments (60 days target)\n",
    "        ip_data = dir_data[dir_data['v_payment_type'] == 'IP']\n",
    "        if len(ip_data) > 0:\n",
    "            ip_valid = ip_data[ip_data['v_payment_in_time'].notna()]\n",
    "            ip_effectiveness = (ip_data['v_payment_in_time'].sum() / len(ip_valid) * 100) if len(ip_valid) > 0 else 0\n",
    "            row[f'Interim Payments - The contractual time limit is 60 days {year_label}'] = f\"{ip_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'Interim Payments - The contractual time limit is 60 days {year_label}'] = \"-\"\n",
    "        \n",
    "        # Experts Payment (30 days target)\n",
    "        exp_data = dir_data[dir_data['v_payment_type'] == 'EXPERTS']\n",
    "        if len(exp_data) > 0:\n",
    "            exp_valid = exp_data[exp_data['v_payment_in_time'].notna()]\n",
    "            exp_effectiveness = (exp_data['v_payment_in_time'].sum() / len(exp_valid) * 100) if len(exp_valid) > 0 else 0\n",
    "            row[f'Experts Payment - The contractual time limit is 30 days {year_label}'] = f\"{exp_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'Experts Payment - The contractual time limit is 30 days {year_label}'] = \"-\"\n",
    "        \n",
    "        # All Payments (60 days target)\n",
    "        if len(dir_data) > 0:\n",
    "            all_valid = dir_data[dir_data['v_payment_in_time'].notna()]\n",
    "            all_effectiveness = (dir_data['v_payment_in_time'].sum() / len(all_valid) * 100) if len(all_valid) > 0 else 0\n",
    "            row[f'All Payments - The contractual time limit is 60 days {year_label}'] = f\"{all_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'All Payments - The contractual time limit is 60 days {year_label}'] = \"-\"\n",
    "        \n",
    "        table_data.append(row)\n",
    "    \n",
    "    # Add \"All Payments\" summary row\n",
    "    all_row = {'call_type': 'All Payments'}\n",
    "    \n",
    "    # Calculate overall effectiveness for all directorates\n",
    "    # Final Payments\n",
    "    all_fp_data = h2020_data[h2020_data['v_payment_type'] == 'FP']\n",
    "    if len(all_fp_data) > 0:\n",
    "        all_fp_valid = all_fp_data[all_fp_data['v_payment_in_time'].notna()]\n",
    "        all_fp_effectiveness = (all_fp_data['v_payment_in_time'].sum() / len(all_fp_valid) * 100) if len(all_fp_valid) > 0 else 0\n",
    "        all_row[f'Final Payments - The contractual time limit is 30 days {year_label}'] = f\"{all_fp_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'Final Payments - The contractual time limit is 30 days {year_label}'] = \"-\"\n",
    "    \n",
    "    # Interim Payments\n",
    "    all_ip_data = h2020_data[h2020_data['v_payment_type'] == 'IP']\n",
    "    if len(all_ip_data) > 0:\n",
    "        all_ip_valid = all_ip_data[all_ip_data['v_payment_in_time'].notna()]\n",
    "        all_ip_effectiveness = (all_ip_data['v_payment_in_time'].sum() / len(all_ip_valid) * 100) if len(all_ip_valid) > 0 else 0\n",
    "        all_row[f'Interim Payments - The contractual time limit is 60 days {year_label}'] = f\"{all_ip_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'Interim Payments - The contractual time limit is 60 days {year_label}'] = \"-\"\n",
    "    \n",
    "    # Experts Payment\n",
    "    all_exp_data = h2020_data[h2020_data['v_payment_type'] == 'EXPERTS']\n",
    "    if len(all_exp_data) > 0:\n",
    "        all_exp_valid = all_exp_data[all_exp_data['v_payment_in_time'].notna()]\n",
    "        all_exp_effectiveness = (all_exp_data['v_payment_in_time'].sum() / len(all_exp_valid) * 100) if len(all_exp_valid) > 0 else 0\n",
    "        all_row[f'Experts Payment - The contractual time limit is 30 days {year_label}'] = f\"{all_exp_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'Experts Payment - The contractual time limit is 30 days {year_label}'] = \"-\"\n",
    "    \n",
    "    # All Payments\n",
    "    if len(h2020_data) > 0:\n",
    "        all_h2020_valid = h2020_data[h2020_data['v_payment_in_time'].notna()]\n",
    "        all_h2020_effectiveness = (h2020_data['v_payment_in_time'].sum() / len(all_h2020_valid) * 100) if len(all_h2020_valid) > 0 else 0\n",
    "        all_row[f'All Payments - The contractual time limit is 60 days {year_label}'] = f\"{all_h2020_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'All Payments - The contractual time limit is 60 days {year_label}'] = \"-\"\n",
    "    \n",
    "    table_data.append(all_row)\n",
    "    \n",
    "    return pd.DataFrame(table_data)\n",
    "\n",
    "def create_heu_effectiveness_table(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Create HEU effectiveness breakdown table by directorate\n",
    "    \"\"\"\n",
    "    df_unique, year_label = create_effectiveness_breakdown(df_paym, cutoff)\n",
    "    \n",
    "    # Filter for HEU\n",
    "    heu_data = df_unique[df_unique['Programme'] == 'HEU'].copy()\n",
    "    \n",
    "    # Get actual directorates from the data\n",
    "    available_directorates = sorted([d for d in heu_data['call_type'].unique() if pd.notna(d)])\n",
    "    \n",
    "    # Build table data\n",
    "    table_data = []\n",
    "    \n",
    "    # Calculate effectiveness for each directorate\n",
    "    for dir_name in available_directorates:\n",
    "        dir_data = heu_data[heu_data['call_type'] == dir_name]\n",
    "        row = {'call_type': dir_name}\n",
    "        \n",
    "        # Experts Payment (30 days target)\n",
    "        exp_data = dir_data[dir_data['v_payment_type'] == 'EXPERTS']\n",
    "        if len(exp_data) > 0:\n",
    "            exp_valid = exp_data[exp_data['v_payment_in_time'].notna()]\n",
    "            exp_effectiveness = (exp_data['v_payment_in_time'].sum() / len(exp_valid) * 100) if len(exp_valid) > 0 else 0\n",
    "            row[f'Experts Payment - The contractual time limit is 30 days {year_label}'] = f\"{exp_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'Experts Payment - The contractual time limit is 30 days {year_label}'] = \"-\"\n",
    "        \n",
    "        # Final Payments (90 days target)\n",
    "        fp_data = dir_data[dir_data['v_payment_type'] == 'FP']\n",
    "        if len(fp_data) > 0:\n",
    "            fp_valid = fp_data[fp_data['v_payment_in_time'].notna()]\n",
    "            fp_effectiveness = (fp_data['v_payment_in_time'].sum() / len(fp_valid) * 100) if len(fp_valid) > 0 else 0\n",
    "            row[f'Final Payments - The contractual time limit is 90 days {year_label}'] = f\"{fp_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'Final Payments - The contractual time limit is 90 days {year_label}'] = \"-\"\n",
    "        \n",
    "        # Interim Payments (90 days target)\n",
    "        ip_data = dir_data[dir_data['v_payment_type'] == 'IP']\n",
    "        if len(ip_data) > 0:\n",
    "            ip_valid = ip_data[ip_data['v_payment_in_time'].notna()]\n",
    "            ip_effectiveness = (ip_data['v_payment_in_time'].sum() / len(ip_valid) * 100) if len(ip_valid) > 0 else 0\n",
    "            row[f'Interim Payments - The contractual time limit is 90 days {year_label}'] = f\"{ip_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'Interim Payments - The contractual time limit is 90 days {year_label}'] = \"-\"\n",
    "        \n",
    "        # Prefinancing Payments (days target - need to determine from data)\n",
    "        pf_data = dir_data[dir_data['v_payment_type'] == 'PF']\n",
    "        if len(pf_data) > 0:\n",
    "            pf_valid = pf_data[pf_data['v_payment_in_time'].notna()]\n",
    "            pf_effectiveness = (pf_data['v_payment_in_time'].sum() / len(pf_valid) * 100) if len(pf_valid) > 0 else 0\n",
    "            row[f'Prefinancing Payments - The contractual time limit is days {year_label}'] = f\"{pf_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'Prefinancing Payments - The contractual time limit is days {year_label}'] = \"-\"\n",
    "        \n",
    "        # All Payments (90 days target)\n",
    "        if len(dir_data) > 0:\n",
    "            all_valid = dir_data[dir_data['v_payment_in_time'].notna()]\n",
    "            all_effectiveness = (dir_data['v_payment_in_time'].sum() / len(all_valid) * 100) if len(all_valid) > 0 else 0\n",
    "            row[f'All Payments - The contractual time limit is 90 days {year_label}'] = f\"{all_effectiveness:.2f}%\"\n",
    "        else:\n",
    "            row[f'All Payments - The contractual time limit is 90 days {year_label}'] = \"-\"\n",
    "        \n",
    "        table_data.append(row)\n",
    "    \n",
    "    # Add \"All Payments\" summary row\n",
    "    all_row = {'call_type': 'All Payments'}\n",
    "    \n",
    "    # Calculate overall effectiveness for all directorates\n",
    "    # Experts Payment\n",
    "    all_exp_data = heu_data[heu_data['v_payment_type'] == 'EXPERTS']\n",
    "    if len(all_exp_data) > 0:\n",
    "        all_exp_valid = all_exp_data[all_exp_data['v_payment_in_time'].notna()]\n",
    "        all_exp_effectiveness = (all_exp_data['v_payment_in_time'].sum() / len(all_exp_valid) * 100) if len(all_exp_valid) > 0 else 0\n",
    "        all_row[f'Experts Payment - The contractual time limit is 30 days {year_label}'] = f\"{all_exp_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'Experts Payment - The contractual time limit is 30 days {year_label}'] = \"-\"\n",
    "    \n",
    "    # Final Payments\n",
    "    all_fp_data = heu_data[heu_data['v_payment_type'] == 'FP']\n",
    "    if len(all_fp_data) > 0:\n",
    "        all_fp_valid = all_fp_data[all_fp_data['v_payment_in_time'].notna()]\n",
    "        all_fp_effectiveness = (all_fp_data['v_payment_in_time'].sum() / len(all_fp_valid) * 100) if len(all_fp_valid) > 0 else 0\n",
    "        all_row[f'Final Payments - The contractual time limit is 90 days {year_label}'] = f\"{all_fp_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'Final Payments - The contractual time limit is 90 days {year_label}'] = \"-\"\n",
    "    \n",
    "    # Interim Payments\n",
    "    all_ip_data = heu_data[heu_data['v_payment_type'] == 'IP']\n",
    "    if len(all_ip_data) > 0:\n",
    "        all_ip_valid = all_ip_data[all_ip_data['v_payment_in_time'].notna()]\n",
    "        all_ip_effectiveness = (all_ip_data['v_payment_in_time'].sum() / len(all_ip_valid) * 100) if len(all_ip_valid) > 0 else 0\n",
    "        all_row[f'Interim Payments - The contractual time limit is 90 days {year_label}'] = f\"{all_ip_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'Interim Payments - The contractual time limit is 90 days {year_label}'] = \"-\"\n",
    "    \n",
    "    # Prefinancing Payments\n",
    "    all_pf_data = heu_data[heu_data['v_payment_type'] == 'PF']\n",
    "    if len(all_pf_data) > 0:\n",
    "        all_pf_valid = all_pf_data[all_pf_data['v_payment_in_time'].notna()]\n",
    "        all_pf_effectiveness = (all_pf_data['v_payment_in_time'].sum() / len(all_pf_valid) * 100) if len(all_pf_valid) > 0 else 0\n",
    "        all_row[f'Prefinancing Payments - The contractual time limit is days {year_label}'] = f\"{all_pf_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'Prefinancing Payments - The contractual time limit is days {year_label}'] = \"-\"\n",
    "    \n",
    "    # All Payments\n",
    "    if len(heu_data) > 0:\n",
    "        all_heu_valid = heu_data[heu_data['v_payment_in_time'].notna()]\n",
    "        all_heu_effectiveness = (heu_data['v_payment_in_time'].sum() / len(all_heu_valid) * 100) if len(all_heu_valid) > 0 else 0\n",
    "        all_row[f'All Payments - The contractual time limit is 90 days {year_label}'] = f\"{all_heu_effectiveness:.2f}%\"\n",
    "    else:\n",
    "        all_row[f'All Payments - The contractual time limit is 90 days {year_label}'] = \"-\"\n",
    "    \n",
    "    table_data.append(all_row)\n",
    "    \n",
    "    return pd.DataFrame(table_data)\n",
    "\n",
    "\n",
    "def generate_effectiveness_breakdown_tables(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Generate both H2020 and HEU effectiveness breakdown tables (ORIGINAL STRUCTURE)\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    h2020_eff_table, heu_eff_table = generate_effectiveness_breakdown_tables(df_paym, cutoff)\n",
    "    \n",
    "    # Display tables\n",
    "    print(\"H2020 Effectiveness Breakdown:\")\n",
    "    display(h2020_eff_table)\n",
    "    \n",
    "    print(\"\\nHEU Effectiveness Breakdown:\")\n",
    "    display(heu_eff_table)\n",
    "    \"\"\"\n",
    "    h2020_eff_table = create_h2020_effectiveness_table(df_paym, cutoff)\n",
    "    heu_eff_table = create_heu_effectiveness_table(df_paym, cutoff)\n",
    "    \n",
    "    return h2020_eff_table, heu_eff_table\n",
    "\n",
    "# =============================================================================\n",
    "# CLEAN TTP CALCULATION FUNCTIONS (from original file)\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_current_ttp_metrics(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Calculate current TTP metrics from df_paym data\n",
    "    \"\"\"\n",
    "    # Filter data up to cutoff and deduplicate by Pay Payment Key\n",
    "    quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "    last_valid_date = quarter_dates[1]\n",
    "\n",
    "    df_filtered = df_paym[\n",
    "        df_paym['Pay Document Date (dd/mm/yyyy)'] <= last_valid_date\n",
    "    ].copy()\n",
    "    df_unique = df_filtered.drop_duplicates(subset=['Pay Payment Key']).copy()\n",
    "    \n",
    "    # Convert to numeric\n",
    "    df_unique['v_TTP_NET'] = pd.to_numeric(df_unique['v_TTP_NET'], errors='coerce')\n",
    "    df_unique['v_TTP_GROSS'] = pd.to_numeric(df_unique['v_TTP_GROSS'], errors='coerce')\n",
    "    df_unique['v_payment_in_time'] = pd.to_numeric(df_unique['v_payment_in_time'], errors='coerce')\n",
    "\n",
    "    # Filter out negative TTP_NET values\n",
    "    df_unique = df_unique[df_unique['v_TTP_NET'] >= 0]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Calculate by Programme and Payment Type\n",
    "    for programme in ['H2020', 'HEU']:\n",
    "        prog_data = df_unique[df_unique['Programme'] == programme]\n",
    "        if len(prog_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        results[programme] = {}\n",
    "        \n",
    "        # Overall programme metrics\n",
    "        prog_valid = prog_data[prog_data['v_payment_in_time'].notna()]\n",
    "        results[programme]['overall'] = {\n",
    "            'avg_ttp_net': prog_data['v_TTP_NET'].mean(),\n",
    "            'avg_ttp_gross': prog_data['v_TTP_GROSS'].mean(),\n",
    "            'on_time_pct': prog_data['v_payment_in_time'].sum() / len(prog_valid) if len(prog_valid) > 0 else 0\n",
    "        }\n",
    "        \n",
    "        # By payment type - using correct short form values from v_payment_type\n",
    "        payment_types = ['IP', 'FP', 'EXPERTS', 'PF']  # Short form values\n",
    "        \n",
    "        for payment_type in payment_types:\n",
    "            pt_data = prog_data[prog_data['v_payment_type'] == payment_type]\n",
    "            if len(pt_data) > 0:\n",
    "                pt_valid = pt_data[pt_data['v_payment_in_time'].notna()]\n",
    "                results[programme][payment_type] = {\n",
    "                    'avg_ttp_net': pt_data['v_TTP_NET'].mean(),\n",
    "                    'avg_ttp_gross': pt_data['v_TTP_GROSS'].mean(),\n",
    "                    'on_time_pct': pt_data['v_payment_in_time'].sum() / len(pt_valid) if len(pt_valid) > 0 else 0\n",
    "                }\n",
    "    \n",
    "    # Overall total\n",
    "    total_valid = df_unique[df_unique['v_payment_in_time'].notna()]\n",
    "    results['TOTAL'] = {\n",
    "        'avg_ttp_net': df_unique['v_TTP_NET'].mean(),\n",
    "        'avg_ttp_gross': df_unique['v_TTP_GROSS'].mean(),\n",
    "        'on_time_pct': df_unique['v_payment_in_time'].sum() / len(total_valid) if len(total_valid) > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def load_historical_ttp_data(report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Load historical TTP data from database\n",
    "    \"\"\"\n",
    "    DB_PATH = Path(db_path)\n",
    "    report_params = load_report_params(report_name=report_name, db_path=DB_PATH)\n",
    "    \n",
    "    return {\n",
    "        \"TTP_NET_HISTORY\": report_params.get(\"TTP_NET_HISTORY\"),\n",
    "        \"TTP_GROSS_HISTORY\": report_params.get(\"TTP_GROSS_HISTORY\"),\n",
    "        \"PAYMENTS_ON_TIME_HISTORY\": report_params.get(\"PAYMENTS_ON_TIME_HISTORY\")\n",
    "    }\n",
    "\n",
    "def create_ttp_comparison_table(df_paym, cutoff, historical_data):\n",
    "    \"\"\"\n",
    "    Create TTP comparison table matching the image structure\n",
    "    \"\"\"\n",
    "    # Calculate current metrics\n",
    "    current_metrics = calculate_current_ttp_metrics(df_paym, cutoff)\n",
    "    \n",
    "    # Determine labels based on cutoff\n",
    "    cutoff_date = pd.to_datetime(cutoff)\n",
    "    current_year = cutoff_date.year\n",
    "    current_label = f\"{current_year}-YTD\"\n",
    "    historical_label = f\"Dec {current_year - 1}\"\n",
    "    \n",
    "    # Build comparison data\n",
    "    comparison_data = []\n",
    "    \n",
    "    # H2020 section\n",
    "    h2020_current = current_metrics.get('H2020', {})\n",
    "    \n",
    "    # H2020 - Interim Payments (IP)\n",
    "    current_ip = h2020_current.get('IP', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Interim Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_ip['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"H2020\"].get(\"IP\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_ip['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"H2020\"].get(\"IP\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_ip['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('IP', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # H2020 - Final Payments (FP)\n",
    "    current_fp = h2020_current.get('FP', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Final Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_fp['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"H2020\"].get(\"FP\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_fp['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"H2020\"].get(\"FP\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_fp['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('FP', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # H2020 - Experts Payments (EXPERTS)\n",
    "    current_exp = h2020_current.get('EXPERTS', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Experts Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_exp['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"H2020\"].get(\"Experts\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_exp['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"H2020\"].get(\"Experts\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_exp['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('Experts', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # H2020 - Overall\n",
    "    current_h2020 = h2020_current.get('overall', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'H2020',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_h2020['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"H2020\"].get(\"H2020\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_h2020['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"H2020\"].get(\"H2020\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_h2020['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('H2020', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU section\n",
    "    heu_current = current_metrics.get('HEU', {})\n",
    "    \n",
    "    # HEU - Prefinancing Payments (PF)\n",
    "    current_pf = heu_current.get('PF', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Prefinancing Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_pf['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"PF\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_pf['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"PF\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_pf['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('PF', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU - Interim Payments (IP)\n",
    "    current_ip_heu = heu_current.get('IP', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Interim Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_ip_heu['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"IP\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_ip_heu['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"IP\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_ip_heu['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('IP', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU - Final Payments (FP)\n",
    "    current_fp_heu = heu_current.get('FP', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Final Payments',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_fp_heu['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"FP\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_fp_heu['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"FP\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_fp_heu['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('FP', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU - Experts Payment (EXPERTS)\n",
    "    current_exp_heu = heu_current.get('EXPERTS', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'Experts Payment',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_exp_heu['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"Experts\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_exp_heu['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"Experts\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_exp_heu['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('Experts', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # HEU - Overall\n",
    "    current_heu = heu_current.get('overall', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'HEU',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_heu['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"HEU\"].get(\"HEU\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_heu['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"HEU\"].get(\"HEU\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_heu['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('HEU', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    # TOTAL row\n",
    "    current_total = current_metrics.get('TOTAL', {'avg_ttp_net': 0, 'avg_ttp_gross': 0, 'on_time_pct': 0})\n",
    "    comparison_data.append({\n",
    "        'Type of Payments': 'TOTAL',\n",
    "        f'Average Net Time to Pay (in days) {current_label}': round(current_total['avg_ttp_net'], 1),\n",
    "        f'Average Net Time to Pay (in days) {historical_label}': historical_data[\"TTP_NET_HISTORY\"][\"ALL\"].get(\"TOTAL\", \"n.a\"),\n",
    "        f'Average Gross Time to Pay (in days) {current_label}': round(current_total['avg_ttp_gross'], 1),\n",
    "        f'Average Gross Time to Pay (in days) {historical_label}': historical_data[\"TTP_GROSS_HISTORY\"][\"ALL\"].get(\"TOTAL\", \"n.a\"),\n",
    "        f'Target Paid on Time - Contractually {current_label}': f\"{current_total['on_time_pct']*100:.2f}%\",\n",
    "        f'Target Paid on Time - Contractually {historical_label}': f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['ALL'].get('TOTAL', 0)*100:.2f}%\"\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame(comparison_data)\n",
    "\n",
    "def create_ttp_effectiveness_table(df_paym, cutoff, historical_data, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Create TTP effectiveness and efficiency indicators table\n",
    "    \"\"\"\n",
    "    # Calculate current metrics\n",
    "    current_metrics = calculate_current_ttp_metrics(df_paym, cutoff)\n",
    "    \n",
    "    # Determine labels based on cutoff using get_scope_start_end\n",
    "    quarter_dates = get_scope_start_end(cutoff=cutoff)\n",
    "    last_valid_date = quarter_dates[1]\n",
    "    current_month = pd.to_datetime(last_valid_date).strftime('%b-%y')\n",
    "    \n",
    "    cutoff_date = pd.to_datetime(cutoff)\n",
    "    current_year = cutoff_date.year\n",
    "    historical_label = f\"Dec-{str(current_year-1)[-2:]}\"\n",
    "    \n",
    "    # Load database parameters for admin and expert meetings\n",
    "    from pathlib import Path\n",
    "    DB_PATH = Path(db_path)\n",
    "    report_params = load_report_params(report_name=report_name, db_path=DB_PATH)\n",
    "    \n",
    "    admin_eff = report_params.get(\"Administrative_expenditure_Effectiveness\", {})\n",
    "    admin_ttp = report_params.get(\"Administrative_expenditure_ttp\", {})\n",
    "    expt_meet_eff = report_params.get(\"Expert_meetings_Effectiveness\", {})\n",
    "    expt_meet_ttp = report_params.get(\"Expert_meetings_ttp\", {})\n",
    "    \n",
    "    # Build effectiveness data\n",
    "    effectiveness_data = []\n",
    "    \n",
    "    # Get current metrics for calculations\n",
    "    h2020_current = current_metrics.get('H2020', {})\n",
    "    heu_current = current_metrics.get('HEU', {})\n",
    "    \n",
    "    # Research grants - Interim Payments - H2020\n",
    "    h2020_ip = h2020_current.get('IP', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Interim Payments - H2020',\n",
    "        current_month: f\"{h2020_ip*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('IP', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 90 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants - Final Payments - H2020\n",
    "    h2020_fp = h2020_current.get('FP', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Final Payments - H2020',\n",
    "        current_month: f\"{h2020_fp*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('FP', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 90 days'\n",
    "    })\n",
    "    \n",
    "    # Experts with Appointment Letters H2020\n",
    "    h2020_exp = h2020_current.get('EXPERTS', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Experts with Appointment Letters H2020',\n",
    "        current_month: f\"{h2020_exp*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['H2020'].get('Experts', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 30 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants - Pre-financings HEU\n",
    "    heu_pf = heu_current.get('PF', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Pre-financings HEU',\n",
    "        current_month: f\"{heu_pf*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('PF', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 30 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants - Interim Payments HEU\n",
    "    heu_ip = heu_current.get('IP', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Interim Payments HEU',\n",
    "        current_month: f\"{heu_ip*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('IP', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 90 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants - Final Payments HEU\n",
    "    heu_fp = heu_current.get('FP', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Research grants - Final Payments HEU',\n",
    "        current_month: f\"{heu_fp*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('FP', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 90 days'\n",
    "    })\n",
    "    \n",
    "    # Administrative expenditure (from database)\n",
    "    admin_current = admin_eff.get(\"Current\", 0)\n",
    "    admin_old = admin_eff.get(\"Old\", 0)\n",
    "    admin_target = admin_eff.get(\"Target\", \"99% in 30 days\")\n",
    "    \n",
    "    # Format admin values - handle both percentage (0.985) and already formatted (98.5%) values\n",
    "    if isinstance(admin_current, (int, float)) and admin_current <= 1:\n",
    "        admin_current_str = f\"{admin_current*100:.2f}%\"\n",
    "    else:\n",
    "        admin_current_str = str(admin_current) if admin_current != \"na\" else \"n/a\"\n",
    "        \n",
    "    if isinstance(admin_old, (int, float)) and admin_old <= 1:\n",
    "        admin_old_str = f\"{admin_old*100:.2f}%\"\n",
    "    else:\n",
    "        admin_old_str = str(admin_old) if admin_old != \"na\" else \"n/a\"\n",
    "    \n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Administrative expenditure',\n",
    "        current_month: admin_current_str,\n",
    "        historical_label: admin_old_str,\n",
    "        'Target': admin_target\n",
    "    })\n",
    "    \n",
    "    # Experts with Appointment Letters HEU\n",
    "    heu_exp = heu_current.get('EXPERTS', {}).get('on_time_pct', 0)\n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Experts with Appointment Letters HEU',\n",
    "        current_month: f\"{heu_exp*100:.2f}%\",\n",
    "        historical_label: f\"{historical_data['PAYMENTS_ON_TIME_HISTORY']['HEU'].get('Experts', 0)*100:.2f}%\",\n",
    "        'Target': '95% in 30 days'\n",
    "    })\n",
    "    \n",
    "    # Expert meetings PMO (from database)\n",
    "    expt_current = expt_meet_eff.get(\"Current\", \"na\")\n",
    "    expt_old = expt_meet_eff.get(\"Old\", \"na\")\n",
    "    expt_target = expt_meet_eff.get(\"Target\", \"n/a\")\n",
    "    \n",
    "    # Format expert values - handle both percentage and string values\n",
    "    if isinstance(expt_current, (int, float)) and expt_current <= 1:\n",
    "        expt_current_str = f\"{expt_current*100:.2f}%\"\n",
    "    else:\n",
    "        expt_current_str = str(expt_current) if expt_current != \"na\" else \"n/a\"\n",
    "        \n",
    "    if isinstance(expt_old, (int, float)) and expt_old <= 1:\n",
    "        expt_old_str = f\"{expt_old*100:.2f}%\"\n",
    "    else:\n",
    "        expt_old_str = str(expt_old) if expt_old != \"na\" else \"n/a\"\n",
    "    \n",
    "    effectiveness_data.append({\n",
    "        'Time-to–Pay: % of payments made on time (H2020 - HEU)': 'Expert meetings PMO',\n",
    "        current_month: expt_current_str,\n",
    "        historical_label: expt_old_str,\n",
    "        'Target': expt_target\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame(effectiveness_data)\n",
    "\n",
    "def create_ttp_days_table(df_paym, cutoff, historical_data, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Create Time to Pay: Average number of days (H2020 - HEU) table\n",
    "    \"\"\"\n",
    "    # Calculate current metrics\n",
    "    current_metrics = calculate_current_ttp_metrics(df_paym, cutoff)\n",
    "    \n",
    "    # Load database parameters for admin and expert meetings\n",
    "    from pathlib import Path\n",
    "    DB_PATH = Path(db_path)\n",
    "    report_params = load_report_params(report_name=report_name, db_path=DB_PATH)\n",
    "    \n",
    "    admin_eff = report_params.get(\"Administrative_expenditure_Effectiveness\", {})\n",
    "    admin_ttp = report_params.get(\"Administrative_expenditure_ttp\", {})\n",
    "    expt_meet_eff = report_params.get(\"Expert_meetings_Effectiveness\", {})\n",
    "    expt_meet_ttp = report_params.get(\"Expert_meetings_ttp\", {})\n",
    "    \n",
    "    # Build days data\n",
    "    days_data = []\n",
    "    \n",
    "    # Get current metrics for calculations\n",
    "    h2020_current = current_metrics.get('H2020', {})\n",
    "    heu_current = current_metrics.get('HEU', {})\n",
    "    \n",
    "    # Research grants (days) - Interim Payments- H2020\n",
    "    h2020_ip = h2020_current.get('IP', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Interim Payments- H2020',\n",
    "        'NET': round(h2020_ip.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(h2020_ip.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '90 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants (days) - Final Payments- H2020\n",
    "    h2020_fp = h2020_current.get('FP', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Final Payments- H2020',\n",
    "        'NET': round(h2020_fp.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(h2020_fp.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '90 days'\n",
    "    })\n",
    "    \n",
    "    # Experts with Appointment Letters (days) H2020\n",
    "    h2020_exp = h2020_current.get('EXPERTS', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Experts with Appointment Letters (days) H2020',\n",
    "        'NET': round(h2020_exp.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(h2020_exp.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants (days) - Pre-financings - HEU\n",
    "    heu_pf = heu_current.get('PF', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Pre-financings - HEU',\n",
    "        'NET': round(heu_pf.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(heu_pf.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants (days) - Interim Payments- HEU\n",
    "    heu_ip = heu_current.get('IP', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Interim Payments- HEU',\n",
    "        'NET': round(heu_ip.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(heu_ip.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '90 days'\n",
    "    })\n",
    "    \n",
    "    # Research grants (days) - Final Payments- HEU\n",
    "    heu_fp = heu_current.get('FP', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Research grants (days) - Final Payments- HEU',\n",
    "        'NET': round(heu_fp.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(heu_fp.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '90 days'\n",
    "    })\n",
    "    \n",
    "    # Expert with Appointment Letter (days) HEU\n",
    "    heu_exp = heu_current.get('EXPERTS', {})\n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Expert with Appointment Letter (days) HEU',\n",
    "        'NET': round(heu_exp.get('avg_ttp_net', 0), 1),\n",
    "        'GROSS': round(heu_exp.get('avg_ttp_gross', 0), 1),\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    # Expert meetings (PMO) (days) - from database\n",
    "    expt_net_current = expt_meet_ttp.get(\"Current\", \"na\")\n",
    "    expt_gross_current = expt_meet_ttp.get(\"Current\", \"na\")  # Assuming same for both NET and GROSS\n",
    "    \n",
    "    # Format expert meeting values\n",
    "    if isinstance(expt_net_current, (int, float)):\n",
    "        expt_net_str = str(round(expt_net_current, 1))\n",
    "        expt_gross_str = str(round(expt_gross_current, 1))\n",
    "    else:\n",
    "        expt_net_str = \"n/a\"\n",
    "        expt_gross_str = \"n/a\"\n",
    "    \n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Expert meetings (PMO) (days)',\n",
    "        'NET': expt_net_str,\n",
    "        'GROSS': expt_gross_str,\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    # Administrative expenditure (days) - from database\n",
    "    admin_net_current = admin_ttp.get(\"Current\", 0)\n",
    "    admin_gross_current = admin_ttp.get(\"Current\", 0)  # Assuming same for both NET and GROSS\n",
    "    \n",
    "    # Format admin values\n",
    "    if isinstance(admin_net_current, (int, float)):\n",
    "        admin_net_str = str(round(admin_net_current, 1))\n",
    "        admin_gross_str = str(round(admin_gross_current, 1))\n",
    "    else:\n",
    "        admin_net_str = \"n/a\"\n",
    "        admin_gross_str = \"n/a\"\n",
    "    \n",
    "    days_data.append({\n",
    "        'Time to Pay: Average number of days (H2020 - HEU)': 'Administrative expenditure (days)',\n",
    "        'NET': admin_net_str,\n",
    "        'GROSS': admin_gross_str,\n",
    "        'Target': '30 days'\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame(days_data)\n",
    "\n",
    "def generate_all_ttp_tables(df_paym, cutoff, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Generate all three TTP tables - comparison table, effectiveness table, and days table\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    comparison_table, effectiveness_table, days_table = generate_all_ttp_tables(df_paym, cutoff)\n",
    "    \"\"\"\n",
    "    # Load historical data\n",
    "    historical_data = load_historical_ttp_data(report_name=report_name, db_path=db_path)\n",
    "    \n",
    "    # Create all three tables\n",
    "    comparison_table = create_ttp_comparison_table(df_paym, cutoff, historical_data)\n",
    "    effectiveness_table = create_ttp_effectiveness_table(df_paym, cutoff, historical_data, report_name, db_path)\n",
    "    days_table = create_ttp_days_table(df_paym, cutoff, historical_data, report_name, db_path)\n",
    "    \n",
    "    return comparison_table, effectiveness_table, days_table\n",
    "\n",
    "def generate_complete_ttp_suite(df_paym, cutoff, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Generate the complete TTP report suite with all table variations\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    tables = generate_complete_ttp_suite(df_paym, cutoff)\n",
    "    \n",
    "    # Access any table:\n",
    "    comparison_table = tables['comparison']\n",
    "    effectiveness_table = tables['effectiveness'] \n",
    "    days_table = tables['days']\n",
    "    h2020_net_quarterly = tables['h2020_net_quarterly']  # MultiIndex DataFrame\n",
    "    heu_net_quarterly = tables['heu_net_quarterly']      # MultiIndex DataFrame  \n",
    "    h2020_gross_quarterly = tables['h2020_gross_quarterly']\n",
    "    heu_gross_quarterly = tables['heu_gross_quarterly']\n",
    "    h2020_effectiveness = tables['h2020_effectiveness']  # Clean table like Picture 1\n",
    "    heu_effectiveness = tables['heu_effectiveness']      # Clean table like Picture 1\n",
    "    \n",
    "    # Example: Access specific data from MultiIndex quarterly table\n",
    "    print(\"ADG PF data:\", tables['heu_net_quarterly'][('ADG', 'PF')])\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate summary tables\n",
    "    comparison_table, effectiveness_table, days_table = generate_all_ttp_tables(df_paym, cutoff, report_name, db_path)\n",
    "    \n",
    "    # Generate quarterly breakdown tables (days) with MultiIndex - FOR GREAT_TABLES\n",
    "    h2020_net_quarterly, heu_net_quarterly = generate_quarterly_breakdown_tables(df_paym, cutoff, 'NET')\n",
    "    h2020_gross_quarterly, heu_gross_quarterly = generate_quarterly_breakdown_tables(df_paym, cutoff, 'GROSS')\n",
    "    \n",
    "    # Generate effectiveness breakdown tables (percentages) - CLEAN STRUCTURE like Picture 1\n",
    "    h2020_effectiveness, heu_effectiveness = generate_effectiveness_breakdown_tables(df_paym, cutoff)\n",
    "    \n",
    "    return {\n",
    "        'comparison': comparison_table,\n",
    "        'effectiveness': effectiveness_table,\n",
    "        'days': days_table,\n",
    "        'h2020_net_quarterly': h2020_net_quarterly,\n",
    "        'heu_net_quarterly': heu_net_quarterly,\n",
    "        'h2020_gross_quarterly': h2020_gross_quarterly,\n",
    "        'heu_gross_quarterly': heu_gross_quarterly,\n",
    "        'h2020_effectiveness': h2020_effectiveness,\n",
    "        'heu_effectiveness': heu_effectiveness\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# UPDATED MAIN FUNCTIONS - USE THESE IN JUPYTER\n",
    "# =============================================================================\n",
    "\n",
    "def generate_ttp_tables(df_paym, cutoff, report_name='Quarterly_Report', db_path=\"database/reporting.db\"):\n",
    "    \"\"\"\n",
    "    Main function to generate all TTP tables\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    comparison_table, effectiveness_table, days_table = generate_ttp_tables(df_paym, cutoff)\n",
    "    \n",
    "    # Display all three summary tables\n",
    "    print(\"TTP Comparison Table:\")\n",
    "    display(comparison_table)\n",
    "    \n",
    "    print(\"\\nEffectiveness and Efficiency Indicators:\")\n",
    "    display(effectiveness_table)\n",
    "    \n",
    "    print(\"\\nTime to Pay: Average number of days:\")\n",
    "    display(days_table)\n",
    "    \"\"\"\n",
    "    return generate_all_ttp_tables(df_paym, cutoff, report_name, db_path)\n",
    "\n",
    "def generate_quarterly_tables_for_great_tables(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Generate quarterly breakdown tables specifically formatted for great_tables (MultiIndex)\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    h2020_net, heu_net, h2020_gross, heu_gross = generate_quarterly_tables_for_great_tables(df_paym, cutoff)\n",
    "    \n",
    "    # These DataFrames have MultiIndex columns perfect for great_tables:\n",
    "    # - Level 0: Directorate (ADG, COG, POC, STG, SYG, Experts, Total)  \n",
    "    # - Level 1: Payment Type (PF, IP, FP, EXPERTS)\n",
    "    # - Index: Quarters (2024Q1, 2024Q2, etc.) + \"Dep C.\" summary row\n",
    "    \n",
    "    # Example usage:\n",
    "    print(\"HEU NET quarterly table structure:\")\n",
    "    print(\"Columns:\", heu_net.columns.tolist())\n",
    "    print(\"Index:\", heu_net.index.tolist())\n",
    "    print(\"ADG-PF column:\", heu_net[('ADG', 'PF')])\n",
    "    \"\"\"\n",
    "    h2020_net, heu_net = generate_quarterly_breakdown_tables(df_paym, cutoff, 'NET')\n",
    "    h2020_gross, heu_gross = generate_quarterly_breakdown_tables(df_paym, cutoff, 'GROSS')\n",
    "    \n",
    "    return h2020_net, heu_net, h2020_gross, heu_gross\n",
    "\n",
    "def generate_effectiveness_tables_for_display(df_paym, cutoff):\n",
    "    \"\"\"\n",
    "    Generate effectiveness breakdown tables for regular display (Clean structure like Picture 1)\n",
    "    \n",
    "    Usage in Jupyter:\n",
    "    h2020_eff, heu_eff = generate_effectiveness_tables_for_display(df_paym, cutoff)\n",
    "    \n",
    "    # These DataFrames have clean structure like Picture 1:\n",
    "    # - Rows: Directorates (ADG, COG, POC, STG, SYG, All Payments)\n",
    "    # - Columns: Payment types with descriptive headers\n",
    "    # - Values: Formatted percentages like \"100.00%\"\n",
    "    \n",
    "    # Example usage:\n",
    "    print(\"H2020 Effectiveness Table:\")\n",
    "    display(h2020_eff)\n",
    "    \"\"\"\n",
    "    return generate_effectiveness_breakdown_tables(df_paym, cutoff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9516b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2020_net, heu_net, h2020_gross, heu_gross = generate_quarterly_tables_for_great_tables(df_paym, cutoff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf7ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "heu_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb7b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = generate_complete_ttp_suite(df_paym, cutoff)\n",
    "h2020_effect = tables['h2020_effectiveness']\n",
    "h2020_effect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f737ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "heu_effect = tables['heu_effectiveness']\n",
    "heu_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7f6d0b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payment Charts and Tables Generator\n",
      "==================================================\n",
      "This script requires df_paym and df_forecast to be loaded\n",
      "\n",
      "IMPORTANT: Budget appropriations are only available for:\n",
      "  H2020: 'all' call types combined\n",
      "  HEU: 'all' call types combined and 'EXPERTS'\n",
      "  Individual call types (STG, ADG, COG, POC, SYG) have NO budget data\n",
      "\n",
      "Example usage:\n",
      "# Generate all charts (budget applied where available)\n",
      "results = generate_all_charts(df_paym, df_forecast, AVAILABLE_BUDGET_CONFIG)\n",
      "display_results_summary(results)\n",
      "save_charts_to_files(results)\n",
      "\n",
      "Or generate individual charts:\n",
      "# Individual call type (no budget elements)\n",
      "result = generate_payment_chart_and_table(df_paym, df_forecast, 'HEU', 'STG', None)\n",
      "# Programme total (with budget elements)\n",
      "result = generate_payment_chart_and_table(df_paym, df_forecast, 'HEU', 'all', 1_532_500_000)\n",
      "result['chart'].show()  # Display chart\n",
      "print(result['table'])  # Display table\n",
      "\n",
      "Check budget availability:\n",
      "print(check_budget_availability('HEU', 'STG'))     # False - no budget\n",
      "print(check_budget_availability('HEU', 'all'))     # True - budget available\n",
      "print(check_budget_availability('HEU', 'EXPERTS')) # True - budget available\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from datetime import datetime, date\n",
    "from typing import Tuple\n",
    "import locale\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set locale for number formatting (adjust as needed)\n",
    "try:\n",
    "    locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
    "except:\n",
    "    try:\n",
    "        locale.setlocale(locale.LC_ALL, 'C')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Configuration - Update these as needed\n",
    "colorScheme = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "title_color = '#333333'\n",
    "\n",
    "def get_current_reporting_date():\n",
    "    \"\"\"Get current reporting date - uses current timestamp\"\"\"\n",
    "    return pd.Timestamp.now()\n",
    "\n",
    "def get_call_type_column(df):\n",
    "    \"\"\"Identify the call type column in the dataframe\"\"\"\n",
    "    possible_columns = ['SCRS_CALL_TYPE', 'call_type', 'Call Type', 'v_call_type', 'Local Position', 'v_1_Program']\n",
    "    for col in possible_columns:\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def prepare_payment_data(df_paym, programme, call_type=None, cutoff_date=None):\n",
    "    \"\"\"\n",
    "    Prepare payment data for chart generation using existing date utilities\n",
    "    \n",
    "    Parameters:\n",
    "    - df_paym: Payment dataframe\n",
    "    - programme: 'H2020' or 'HEU' \n",
    "    - call_type: Specific call type (e.g., 'STG', 'ADG', etc.) or 'all' for all\n",
    "    - cutoff_date: Cutoff date for reporting (default: current timestamp)\n",
    "    \"\"\"\n",
    "    \n",
    "    if cutoff_date is None:\n",
    "        cutoff_date = get_current_reporting_date()\n",
    "    \n",
    "    # Ensure cutoff_date is a pandas Timestamp\n",
    "    if isinstance(cutoff_date, str):\n",
    "        cutoff_date = pd.to_datetime(cutoff_date)\n",
    "    elif hasattr(cutoff_date, 'date'):  # datetime object\n",
    "        cutoff_date = pd.Timestamp(cutoff_date)\n",
    "    elif not isinstance(cutoff_date, pd.Timestamp):\n",
    "        cutoff_date = pd.Timestamp(cutoff_date)\n",
    "    \n",
    "    print(f\"Preparing data for {programme} - {call_type} - Cutoff: {cutoff_date}\")\n",
    "    \n",
    "    # Use existing utilities to get scope\n",
    "    reporting_year = determine_epoch_year(cutoff_date)\n",
    "    scope_start, scope_end = get_scope_start_end(cutoff_date)\n",
    "    months_list = months_in_scope(cutoff_date)\n",
    "    \n",
    "    print(f\"Reporting year: {reporting_year}\")\n",
    "    print(f\"Scope: {scope_start} to {scope_end}\")\n",
    "    print(f\"Months in scope: {len(months_list)} months\")\n",
    "    \n",
    "    # Copy and filter data\n",
    "    df = df_paym.copy()\n",
    "    \n",
    "    # Filter by programme\n",
    "    df = df[df['Programme'] == programme].copy()\n",
    "    \n",
    "    # Parse dates if they're strings\n",
    "    if df['Pay Document Date (dd/mm/yyyy)'].dtype == 'object':\n",
    "        df['Pay Document Date (dd/mm/yyyy)'] = pd.to_datetime(df['Pay Document Date (dd/mm/yyyy)'], \n",
    "                                                              format='%d/%m/%Y', errors='coerce')\n",
    "    \n",
    "    # Filter by date scope (use scope_start and scope_end)\n",
    "    df = df[\n",
    "        (df['Pay Document Date (dd/mm/yyyy)'] >= scope_start) & \n",
    "        (df['Pay Document Date (dd/mm/yyyy)'] <= scope_end)\n",
    "    ].copy()\n",
    "    \n",
    "    # Filter by fund source (equivalent to old C1, E0 filter)\n",
    "    df = df[df['Fund Source'].notna()].copy()\n",
    "    \n",
    "    # Handle call type filtering\n",
    "    call_type_col = get_call_type_column(df)\n",
    "    \n",
    "    if call_type and call_type != 'all' and call_type_col:\n",
    "        df = df[df[call_type_col] == call_type].copy()\n",
    "        print(f\"Filtered by {call_type_col} = {call_type}: {len(df)} rows\")\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        print(\"No data after filtering\")\n",
    "        return create_dummy_payment_data(programme, call_type, cutoff_date, reporting_year)\n",
    "    \n",
    "    # Create month column\n",
    "    df['Month'] = df['Pay Document Date (dd/mm/yyyy)'].dt.month\n",
    "    df['Year'] = df['Pay Document Date (dd/mm/yyyy)'].dt.year\n",
    "    \n",
    "    # Filter for reporting year (already filtered by scope, but double-check)\n",
    "    df = df[df['Year'] == reporting_year].copy()\n",
    "    \n",
    "    # Aggregate by month (sum amounts)\n",
    "    monthly_payments = df.groupby(['Month'])['v_amount_to_sum'].sum().reset_index()\n",
    "    monthly_payments.rename(columns={'v_amount_to_sum': 'Paid'}, inplace=True)\n",
    "    \n",
    "    # Add programme and year info\n",
    "    monthly_payments['v_1_Program'] = programme\n",
    "    monthly_payments['Year'] = reporting_year\n",
    "    \n",
    "    print(f\"Monthly payments aggregated: {len(monthly_payments)} months\")\n",
    "    return monthly_payments\n",
    "\n",
    "def prepare_forecast_data(df_forecast, programme, call_type=None):\n",
    "    \"\"\"\n",
    "    Prepare forecast data to match payment data structure\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df_forecast.copy()\n",
    "    \n",
    "    # Map the actual column names from your forecast data\n",
    "    programme_col_map = {\n",
    "        'SCRS_FMWK': 'SCRS_FMWK',  # Your actual programme column\n",
    "        'Programme': 'Programme',\n",
    "        'v_1_Program': 'v_1_Program'\n",
    "    }\n",
    "    \n",
    "    call_type_col_map = {\n",
    "        'SCRS_CALL_TYPE': 'SCRS_CALL_TYPE',  # Your actual call type column\n",
    "        'call_type': 'call_type',\n",
    "        'Local Position': 'Local Position'\n",
    "    }\n",
    "    \n",
    "    forecast_amount_col_map = {\n",
    "        'Sum(SCRS_C1_MNT)': 'Sum(SCRS_C1_MNT)',  # Your actual forecast amount column\n",
    "        'Forecast': 'Forecast',\n",
    "        'v_amount_to_sum': 'v_amount_to_sum'\n",
    "    }\n",
    "    \n",
    "    month_col_map = {\n",
    "        'Month_Num': 'Month_Num',  # Your actual month number column\n",
    "        'Month': 'Month'\n",
    "    }\n",
    "    \n",
    "    # Find programme column\n",
    "    programme_col = None\n",
    "    for col in programme_col_map.keys():\n",
    "        if col in df.columns:\n",
    "            programme_col = col\n",
    "            break\n",
    "    \n",
    "    # Find call type column  \n",
    "    call_type_col = None\n",
    "    for col in call_type_col_map.keys():\n",
    "        if col in df.columns:\n",
    "            call_type_col = col\n",
    "            break\n",
    "    \n",
    "    # Find forecast amount column\n",
    "    forecast_col = None\n",
    "    for col in forecast_amount_col_map.keys():\n",
    "        if col in df.columns:\n",
    "            forecast_col = col\n",
    "            break\n",
    "            \n",
    "    # Find month column\n",
    "    month_col = None\n",
    "    for col in month_col_map.keys():\n",
    "        if col in df.columns:\n",
    "            month_col = col\n",
    "            break\n",
    "    \n",
    "    print(f\"Forecast data columns detected:\")\n",
    "    print(f\"  Programme: {programme_col}\")\n",
    "    print(f\"  Call Type: {call_type_col}\")  \n",
    "    print(f\"  Amount: {forecast_col}\")\n",
    "    print(f\"  Month: {month_col}\")\n",
    "    \n",
    "    # Filter by programme\n",
    "    if programme_col:\n",
    "        df = df[df[programme_col] == programme].copy()\n",
    "        print(f\"Filtered forecast by {programme_col} = {programme}: {len(df)} rows\")\n",
    "    else:\n",
    "        print(\"No programme column found in forecast data - using all data\")\n",
    "    \n",
    "    # Handle call type filtering\n",
    "    if call_type and call_type != 'all' and call_type_col:\n",
    "        df = df[df[call_type_col] == call_type].copy()\n",
    "        print(f\"Filtered forecast by {call_type_col} = {call_type}: {len(df)} rows\")\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        print(\"No forecast data after filtering - creating zero forecast\")\n",
    "        return pd.DataFrame({\n",
    "            'Month': range(1, 13),\n",
    "            'Forecast': [0] * 12,\n",
    "            'v_1_Program': programme\n",
    "        })\n",
    "    \n",
    "    if not forecast_col:\n",
    "        print(f\"No forecast amount column found. Available columns: {list(df.columns)}\")\n",
    "        print(\"Creating zero forecast\")\n",
    "        return pd.DataFrame({\n",
    "            'Month': range(1, 13),\n",
    "            'Forecast': [0] * 12,\n",
    "            'v_1_Program': programme\n",
    "        })\n",
    "    \n",
    "    # Aggregate by month if month column exists\n",
    "    if month_col:\n",
    "        forecast_monthly = df.groupby([month_col])[forecast_col].sum().reset_index()\n",
    "        forecast_monthly.rename(columns={\n",
    "            month_col: 'Month',\n",
    "            forecast_col: 'Forecast'\n",
    "        }, inplace=True)\n",
    "    else:\n",
    "        # Distribute forecast equally across 12 months\n",
    "        total_forecast = df[forecast_col].sum()\n",
    "        forecast_monthly = pd.DataFrame({\n",
    "            'Month': range(1, 13),\n",
    "            'Forecast': [total_forecast / 12] * 12\n",
    "        })\n",
    "    \n",
    "    forecast_monthly['v_1_Program'] = programme\n",
    "    \n",
    "    print(f\"Forecast monthly data prepared: {len(forecast_monthly)} months, total: {forecast_monthly['Forecast'].sum():,.0f}\")\n",
    "    return forecast_monthly\n",
    "\n",
    "def create_dummy_payment_data(programme, call_type, cutoff_date, reporting_year):\n",
    "    \"\"\"Create dummy data when no payments exist\"\"\"\n",
    "    \n",
    "    # Use the existing months_in_scope function to get the right months\n",
    "    months_list = months_in_scope(cutoff_date)\n",
    "    month_numbers = list(range(1, len(months_list) + 1))\n",
    "    \n",
    "    dummy_data = []\n",
    "    \n",
    "    for month in month_numbers:\n",
    "        dummy_data.append({\n",
    "            'Month': month,\n",
    "            'Paid': 0,\n",
    "            'v_1_Program': programme\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(dummy_data)\n",
    "\n",
    "def merge_payment_and_forecast_data(df_paid, df_forecast, programme, budget_amount=None):\n",
    "    \"\"\"\n",
    "    Merge payment and forecast data, calculate cumulative values and deviations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Merge on Month\n",
    "    df_merged = pd.merge(df_paid, df_forecast[['Month', 'Forecast']], \n",
    "                        on='Month', how='outer').fillna(0)\n",
    "    \n",
    "    # Ensure we have all months 1-12\n",
    "    all_months = pd.DataFrame({'Month': range(1, 13)})\n",
    "    df_merged = pd.merge(all_months, df_merged, on='Month', how='left').fillna(0)\n",
    "    df_merged['v_1_Program'] = programme\n",
    "    \n",
    "    # Sort by month\n",
    "    df_merged.sort_values('Month', inplace=True)\n",
    "    df_merged.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Calculate cumulative values\n",
    "    df_merged['Paid_Cumulative'] = df_merged['Paid'].cumsum()\n",
    "    df_merged['Forecast_Cumulative'] = df_merged['Forecast'].cumsum()\n",
    "    \n",
    "    # Add budget appropriations only if available\n",
    "    df_merged['Has_Budget'] = budget_amount is not None and budget_amount > 0\n",
    "    if df_merged['Has_Budget'].iloc[0]:\n",
    "        df_merged['Appropriations'] = budget_amount\n",
    "    else:\n",
    "        df_merged['Appropriations'] = None\n",
    "    \n",
    "    # Calculate total forecast for percentage calculations\n",
    "    total_forecast = df_merged['Forecast'].sum()\n",
    "    \n",
    "    if total_forecast > 0:\n",
    "        df_merged['Consumption_Pct'] = df_merged['Paid_Cumulative'] / total_forecast\n",
    "        df_merged['Forecast_Pct'] = df_merged['Forecast_Cumulative'] / total_forecast\n",
    "        df_merged['Deviation_Pct'] = df_merged['Consumption_Pct'] - df_merged['Forecast_Pct']\n",
    "    else:\n",
    "        df_merged['Consumption_Pct'] = 0\n",
    "        df_merged['Forecast_Pct'] = 0\n",
    "        df_merged['Deviation_Pct'] = 0\n",
    "    \n",
    "    # Calculate deviation in absolute terms\n",
    "    df_merged['Deviation_Amount'] = df_merged['Paid_Cumulative'] - df_merged['Forecast_Cumulative']\n",
    "    \n",
    "    # Calculate deviation vs budget percentage only if budget is available\n",
    "    if df_merged['Has_Budget'].iloc[0]:\n",
    "        df_merged['Deviation_vs_Budget_Pct'] = df_merged['Deviation_Amount'] / budget_amount\n",
    "    else:\n",
    "        df_merged['Deviation_vs_Budget_Pct'] = None\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "def create_payment_chart(df_merged, programme, call_type, year, cutoff_month):\n",
    "    \"\"\"\n",
    "    Create the payment consumption chart using Altair\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter data up to cutoff month for actual payments\n",
    "    df_display = df_merged.copy()\n",
    "    df_current = df_display[df_display['Month'] <= cutoff_month].copy()\n",
    "    \n",
    "    # Check if budget data is available\n",
    "    has_budget = df_merged['Has_Budget'].iloc[0] if len(df_merged) > 0 else False\n",
    "    \n",
    "    # Chart title\n",
    "    if call_type == 'all':\n",
    "        title = f\"{programme} - Consumption All Calls {year}\"\n",
    "    else:\n",
    "        title = f\"{programme} - Consumption {call_type} {year}\"\n",
    "    \n",
    "    # Get current month deviation for annotation\n",
    "    if len(df_current) > 0:\n",
    "        current_deviation = df_current.iloc[-1]['Deviation_Pct']\n",
    "        current_month = df_current.iloc[-1]['Month']\n",
    "    else:\n",
    "        current_deviation = 0\n",
    "        current_month = cutoff_month\n",
    "    \n",
    "    # Determine deviation color and annotation\n",
    "    if current_deviation < -0.01:  # Less than -1%\n",
    "        deviation_color = 'red'\n",
    "        deviation_comment = 'Underconsumption'\n",
    "        arrow = '↓'\n",
    "    elif current_deviation > 0.01:  # Greater than 1%\n",
    "        deviation_color = 'green'\n",
    "        deviation_comment = 'Overconsumption'\n",
    "        arrow = '↑'\n",
    "    else:\n",
    "        deviation_color = '#2b7a30'\n",
    "        deviation_comment = 'On Track'\n",
    "        arrow = '→'\n",
    "    \n",
    "    # Set up Altair theme\n",
    "    def my_theme():\n",
    "        return {\n",
    "            'config': {\n",
    "                'view': {'continuousHeight': 350, 'continuousWidth': 550},\n",
    "                'range': {'category': {'scheme': colorScheme}},\n",
    "                'title': {\n",
    "                    \"fontSize\": 18, \n",
    "                    \"font\": 'Lato', \n",
    "                    \"anchor\": \"center\",\n",
    "                    'color': title_color,\n",
    "                    'fontWeight': 'bold'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    alt.themes.register('my_theme', my_theme)\n",
    "    alt.themes.enable('my_theme')\n",
    "    \n",
    "    # Base chart for consumption bars\n",
    "    bar_chart = alt.Chart(df_current, title=title).mark_bar(\n",
    "        size=45,\n",
    "        opacity=0.7,\n",
    "        color='#1f77b4'\n",
    "    ).encode(\n",
    "        x=alt.X('Month:O', title='Month'),\n",
    "        y=alt.Y('Paid_Cumulative:Q', title='Amount (€)', scale=alt.Scale(zero=True)),\n",
    "    ).properties(\n",
    "        width=550,\n",
    "        height=350\n",
    "    )\n",
    "    \n",
    "    # Forecast line\n",
    "    forecast_line = alt.Chart(df_display).mark_line(\n",
    "        opacity=0.8,\n",
    "        strokeWidth=3,\n",
    "        color='#ff7f0e'\n",
    "    ).encode(\n",
    "        x='Month:O',\n",
    "        y='Forecast_Cumulative:Q'\n",
    "    )\n",
    "    \n",
    "    # Appropriations line - only if budget data is available\n",
    "    charts_to_combine = [bar_chart, forecast_line]\n",
    "    \n",
    "    if has_budget:\n",
    "        appropriations_line = alt.Chart(df_display).mark_line(\n",
    "            opacity=0.8,\n",
    "            strokeWidth=3,\n",
    "            color='#2ca02c'\n",
    "        ).encode(\n",
    "            x='Month:O',\n",
    "            y='Appropriations:Q'\n",
    "        )\n",
    "        charts_to_combine.append(appropriations_line)\n",
    "    \n",
    "    # Percentage text on bars\n",
    "    percentage_text = bar_chart.mark_text(\n",
    "        baseline='bottom',\n",
    "        dx=0,\n",
    "        dy=-5,\n",
    "        align='center',\n",
    "        fontSize=12,\n",
    "        fontWeight='bold',\n",
    "        color='#8a2003'\n",
    "    ).encode(\n",
    "        text=alt.Text('Consumption_Pct:Q', format='.1%')\n",
    "    )\n",
    "    \n",
    "    # Deviation annotation\n",
    "    deviation_base = alt.Chart(pd.DataFrame([{\n",
    "        'Month': current_month,\n",
    "        'Paid_Cumulative': df_current.iloc[-1]['Paid_Cumulative'] if len(df_current) > 0 else 0,\n",
    "        'Deviation_Pct': current_deviation,\n",
    "        'Comment': deviation_comment,\n",
    "        'Arrow': arrow\n",
    "    }]))\n",
    "    \n",
    "    deviation_text = deviation_base.mark_text(\n",
    "        dx=50,\n",
    "        dy=-80,\n",
    "        fontSize=14,\n",
    "        fontWeight='bold',\n",
    "        color=deviation_color,\n",
    "        align='left'\n",
    "    ).encode(\n",
    "        x='Month:O',\n",
    "        y='Paid_Cumulative:Q',\n",
    "        text=alt.Text('Deviation_Pct:Q', format='.1%')\n",
    "    )\n",
    "    \n",
    "    deviation_comment_text = deviation_base.mark_text(\n",
    "        dx=50,\n",
    "        dy=-60,\n",
    "        fontSize=11,\n",
    "        fontWeight='bold',\n",
    "        color=deviation_color,\n",
    "        align='left'\n",
    "    ).encode(\n",
    "        x='Month:O',\n",
    "        y='Paid_Cumulative:Q',\n",
    "        text='Comment:N'\n",
    "    )\n",
    "    \n",
    "    # Add percentage text and deviation annotations\n",
    "    charts_to_combine.extend([percentage_text, deviation_text, deviation_comment_text])\n",
    "    \n",
    "    # Combine all chart elements\n",
    "    final_chart = alt.layer(*charts_to_combine)\n",
    "    \n",
    "    return final_chart\n",
    "\n",
    "def create_summary_table(df_merged, cutoff_month):\n",
    "    \"\"\"\n",
    "    Create the summary table below the chart - excludes budget rows when no budget data available\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter to current data\n",
    "    df_table = df_merged[df_merged['Month'] <= cutoff_month].copy()\n",
    "    \n",
    "    # Check if budget data is available\n",
    "    has_budget = df_merged['Has_Budget'].iloc[0] if len(df_merged) > 0 else False\n",
    "    \n",
    "    # Convert to millions for display\n",
    "    df_table = df_table.copy()\n",
    "    df_table['Paid_M'] = df_table['Paid_Cumulative'] / 1_000_000\n",
    "    df_table['Forecast_M'] = df_table['Forecast_Cumulative'] / 1_000_000\n",
    "    df_table['Deviation_M'] = df_table['Deviation_Amount'] / 1_000_000\n",
    "    \n",
    "    # Format numbers\n",
    "    df_table['Paid_Formatted'] = df_table['Paid_M'].map('{:,.3f}'.format)\n",
    "    df_table['Forecast_Formatted'] = df_table['Forecast_M'].map('{:,.3f}'.format)\n",
    "    df_table['Consumption_Pct_Formatted'] = df_table['Consumption_Pct'].map('{:.1%}'.format)\n",
    "    df_table['Forecast_Pct_Formatted'] = df_table['Forecast_Pct'].map('{:.1%}'.format)\n",
    "    df_table['Deviation_Pct_Formatted'] = df_table['Deviation_Pct'].map('{:.1%}'.format)\n",
    "    df_table['Deviation_M_Formatted'] = df_table['Deviation_M'].map('{:,.1f}'.format)\n",
    "    \n",
    "    # Define base columns for output table\n",
    "    output_cols = [\n",
    "        'Month', 'Paid_Formatted', 'Forecast_Formatted',\n",
    "        'Deviation_M_Formatted', 'Deviation_Pct_Formatted'\n",
    "    ]\n",
    "    \n",
    "    # Add budget-related columns only if budget data is available\n",
    "    if has_budget:\n",
    "        df_table['Budget_M'] = df_table['Appropriations'] / 1_000_000\n",
    "        df_table['Budget_Formatted'] = df_table['Budget_M'].map('{:,.1f}'.format)\n",
    "        df_table['Deviation_vs_Budget_Formatted'] = df_table['Deviation_vs_Budget_Pct'].map('{:.1%}'.format)\n",
    "        \n",
    "        # Insert budget column at the beginning and deviation vs budget at the end\n",
    "        output_cols.insert(1, 'Budget_Formatted')\n",
    "        output_cols.append('Deviation_vs_Budget_Formatted')\n",
    "    \n",
    "    # Create output table\n",
    "    table_output = df_table[output_cols].copy()\n",
    "    table_output.set_index('Month', inplace=True)\n",
    "    \n",
    "    # Transpose for month columns\n",
    "    table_transposed = table_output.T\n",
    "    table_transposed.reset_index(inplace=True)\n",
    "    table_transposed.rename(columns={'index': 'Metric'}, inplace=True)\n",
    "    \n",
    "    # Define metric names based on whether budget data is available\n",
    "    if has_budget:\n",
    "        metric_names = {\n",
    "            'Budget_Formatted': 'Current Inscribed Budget',\n",
    "            'Paid_Formatted': 'Cumulative Consumption (€ million)',\n",
    "            'Forecast_Formatted': 'Cumulative Forecast (€ million)',\n",
    "            'Deviation_M_Formatted': 'Deviation vs. Cumulative Forecast (€ million)',\n",
    "            'Deviation_Pct_Formatted': 'Deviation vs. Cumulative Forecast (%)',\n",
    "            'Deviation_vs_Budget_Formatted': 'Deviation vs. Budget (%)'\n",
    "        }\n",
    "    else:\n",
    "        metric_names = {\n",
    "            'Paid_Formatted': 'Cumulative Consumption (€ million)',\n",
    "            'Forecast_Formatted': 'Cumulative Forecast (€ million)',\n",
    "            'Deviation_M_Formatted': 'Deviation vs. Cumulative Forecast (€ million)',\n",
    "            'Deviation_Pct_Formatted': 'Deviation vs. Cumulative Forecast (%)'\n",
    "        }\n",
    "    \n",
    "    table_transposed['Metric'] = table_transposed['Metric'].map(metric_names)\n",
    "    \n",
    "    # Rename month columns\n",
    "    month_names = {\n",
    "        1: 'JAN', 2: 'FEB', 3: 'MAR', 4: 'APR', 5: 'MAY', 6: 'JUN',\n",
    "        7: 'JUL', 8: 'AUG', 9: 'SEP', 10: 'OCT', 11: 'NOV', 12: 'DEC'\n",
    "    }\n",
    "    \n",
    "    table_transposed.columns = ['Metric'] + [month_names.get(col, str(col)) for col in table_transposed.columns[1:]]\n",
    "    \n",
    "    return table_transposed\n",
    "\n",
    "def generate_payment_chart_and_table(df_paym, df_forecast, programme, call_type='all', \n",
    "                                   budget_amount=None, cutoff_date=None):\n",
    "    \"\"\"\n",
    "    Main function to generate both chart and table for a specific programme/call type\n",
    "    \n",
    "    Parameters:\n",
    "    - df_paym: Payment dataframe\n",
    "    - df_forecast: Forecast dataframe  \n",
    "    - programme: 'H2020' or 'HEU'\n",
    "    - call_type: Specific call type or 'all'\n",
    "    - budget_amount: Budget appropriation amount\n",
    "    - cutoff_date: Reporting cutoff date\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with 'chart' and 'table' keys\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Get cutoff date\n",
    "        if cutoff_date is None:\n",
    "            cutoff_date = get_current_reporting_date()\n",
    "        \n",
    "        # Ensure cutoff_date is a pandas Timestamp\n",
    "        if isinstance(cutoff_date, str):\n",
    "            cutoff_date = pd.to_datetime(cutoff_date)\n",
    "        elif not isinstance(cutoff_date, pd.Timestamp):\n",
    "            cutoff_date = pd.Timestamp(cutoff_date)\n",
    "        \n",
    "        # Use existing date utilities\n",
    "        reporting_year = determine_epoch_year(cutoff_date)\n",
    "        scope_start, scope_end = get_scope_start_end(cutoff_date)\n",
    "        months_list = months_in_scope(cutoff_date)\n",
    "        cutoff_month = len(months_list)  # Number of months in scope\n",
    "        \n",
    "        print(f\"\\n=== Generating chart for {programme} - {call_type} ===\")\n",
    "        print(f\"Cutoff date: {cutoff_date}\")\n",
    "        print(f\"Reporting year: {reporting_year}\")\n",
    "        print(f\"Scope: {scope_start} to {scope_end}\")\n",
    "        print(f\"Months in scope: {cutoff_month}\")\n",
    "        \n",
    "        # Prepare payment data\n",
    "        df_paid = prepare_payment_data(df_paym, programme, call_type, cutoff_date)\n",
    "        \n",
    "        # Prepare forecast data\n",
    "        df_forecast_prep = prepare_forecast_data(df_forecast, programme, call_type)\n",
    "        \n",
    "        # Merge and calculate\n",
    "        df_merged = merge_payment_and_forecast_data(df_paid, df_forecast_prep, programme, budget_amount)\n",
    "        \n",
    "        # Create chart\n",
    "        chart = create_payment_chart(df_merged, programme, call_type, reporting_year, cutoff_month)\n",
    "        \n",
    "        # Create table\n",
    "        table = create_summary_table(df_merged, cutoff_month)\n",
    "        \n",
    "        return {\n",
    "            'chart': chart,\n",
    "            'table': table,\n",
    "            'data': df_merged,\n",
    "            'success': True,\n",
    "            'metadata': {\n",
    "                'reporting_year': reporting_year,\n",
    "                'scope_start': scope_start,\n",
    "                'scope_end': scope_end,\n",
    "                'cutoff_month': cutoff_month,\n",
    "                'months_in_scope': months_list\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating chart for {programme} - {call_type}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {\n",
    "            'chart': None,\n",
    "            'table': None,\n",
    "            'data': None,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "#### \n",
    "vars_all = fetch_vars_for_report(report, db_path)\n",
    "vars_data = vars_all.get('table_2a_HE')\n",
    "h2020_vars_data = vars_all.get('table_2a_H2020')\n",
    "\n",
    "# Extract Total Available Payment Appropriations\n",
    "heu_total_appropriations = next(\n",
    "    (item['Available_Payment_Appropriations'] for item in vars_data \n",
    "     if item['Budget Address Type'] == 'Total'), \n",
    "    None\n",
    ")\n",
    "heu_total_appropriations_expt = next(\n",
    "    (item['Available_Payment_Appropriations'] for item in vars_data \n",
    "     if item['Budget Address Type'] == 'Experts'), \n",
    "    None\n",
    ")\n",
    "\n",
    "h2020_total_appropriations = next(\n",
    "    (item['Available_Payment_Appropriations'] for item in h2020_vars_data \n",
    "     if item['Budget Address Type'] == 'Total'), \n",
    "    None\n",
    ")\n",
    "\n",
    "\n",
    "# Budget configuration - Only available for specific cases\n",
    "AVAILABLE_BUDGET_CONFIG = {\n",
    "    'H2020': {\n",
    "        'all': h2020_total_appropriations  # Total H2020 budget - ONLY available for 'all' call types\n",
    "        # No individual call type budgets available (STG, ADG, COG, POC, SYG)\n",
    "    },\n",
    "    'HEU': {\n",
    "        'all': heu_total_appropriations,    # Total HEU budget - available for 'all' call types\n",
    "        'EXPERTS': heu_total_appropriations_expt   # HEU Experts budget - ONLY individual call type with budget\n",
    "        # No other individual call type budgets available (STG, ADG, COG, POC, SYG)\n",
    "    }\n",
    "}\n",
    "\n",
    "def check_budget_availability(programme, call_type):\n",
    "    \"\"\"\n",
    "    Check if budget appropriations are available for the given programme/call_type combination\n",
    "    \n",
    "    Returns:\n",
    "    - True if budget is available\n",
    "    - False if no budget appropriations exist for this combination\n",
    "    \"\"\"\n",
    "    \n",
    "    if programme == 'H2020':\n",
    "        return call_type == 'all'\n",
    "    elif programme == 'HEU':\n",
    "        return call_type in ['all', 'EXPERTS']\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_budget_amount(programme, call_type, budget_config=None):\n",
    "    \"\"\"\n",
    "    Get budget amount for programme/call_type if available\n",
    "    \n",
    "    Returns:\n",
    "    - Budget amount if available\n",
    "    - None if no budget appropriations exist\n",
    "    \"\"\"\n",
    "    \n",
    "    if budget_config is None:\n",
    "        budget_config = AVAILABLE_BUDGET_CONFIG\n",
    "    \n",
    "    if not check_budget_availability(programme, call_type):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        return budget_config[programme][call_type]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def generate_all_charts(df_paym, df_forecast, programme_budgets=None, cutoff_date=None):\n",
    "    \"\"\"\n",
    "    Generate charts for all available call types in both programmes\n",
    "    Only applies budget appropriations where available (H2020 'all', HEU 'all' and 'EXPERTS')\n",
    "    \n",
    "    Parameters:\n",
    "    - df_paym: Payment dataframe\n",
    "    - df_forecast: Forecast dataframe\n",
    "    - programme_budgets: Dict with budget amounts for available combinations only\n",
    "    - cutoff_date: Reporting cutoff date\n",
    "    \"\"\"\n",
    "    \n",
    "    if programme_budgets is None:\n",
    "        programme_budgets = AVAILABLE_BUDGET_CONFIG\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Get available call types\n",
    "    call_type_col = get_call_type_column(df_paym)\n",
    "    \n",
    "    if call_type_col:\n",
    "        # Get unique call types per programme\n",
    "        programmes = ['H2020', 'HEU']\n",
    "        \n",
    "        for programme in programmes:\n",
    "            prog_data = df_paym[df_paym['Programme'] == programme]\n",
    "            call_types = prog_data[call_type_col].dropna().unique().tolist()\n",
    "            call_types.append('all')  # Add overall summary\n",
    "            \n",
    "            results[programme] = {}\n",
    "            \n",
    "            for call_type in call_types:\n",
    "                # Get budget only if available for this combination\n",
    "                budget = get_budget_amount(programme, call_type, programme_budgets)\n",
    "                \n",
    "                # Log budget availability\n",
    "                if budget:\n",
    "                    print(f\"Budget available for {programme} {call_type}: €{budget:,.0f}\")\n",
    "                else:\n",
    "                    print(f\"No budget appropriations for {programme} {call_type} - skipping budget elements\")\n",
    "                \n",
    "                result = generate_payment_chart_and_table(\n",
    "                    df_paym, df_forecast, programme, call_type, budget, cutoff_date\n",
    "                )\n",
    "                \n",
    "                results[programme][call_type] = result\n",
    "                \n",
    "                if result['success']:\n",
    "                    budget_status = \"with budget\" if budget else \"without budget\"\n",
    "                    print(f\"✓ Generated: {programme} - {call_type} ({budget_status})\")\n",
    "                else:\n",
    "                    print(f\"✗ Failed: {programme} - {call_type}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_charts_to_files(results, output_dir='./'):\n",
    "    \"\"\"\n",
    "    Save generated charts to PNG files\n",
    "    \"\"\"\n",
    "    \n",
    "    for programme, prog_results in results.items():\n",
    "        for call_type, result in prog_results.items():\n",
    "            if result['success'] and result['chart'] is not None:\n",
    "                filename = f\"chart_{programme}_{call_type}.png\"\n",
    "                filepath = f\"{output_dir}{filename}\"\n",
    "                \n",
    "                try:\n",
    "                    result['chart'].save(filepath)\n",
    "                    print(f\"Saved: {filepath}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving {filepath}: {str(e)}\")\n",
    "\n",
    "def display_results_summary(results):\n",
    "    \"\"\"\n",
    "    Display a summary of generated results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CHART GENERATION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for programme, prog_results in results.items():\n",
    "        print(f\"\\n{programme} Programme:\")\n",
    "        \n",
    "        for call_type, result in prog_results.items():\n",
    "            if result['success']:\n",
    "                # Get key metrics from the data\n",
    "                data = result['data']\n",
    "                if data is not None and len(data) > 0:\n",
    "                    total_paid = data['Paid_Cumulative'].max()\n",
    "                    total_forecast = data['Forecast_Cumulative'].max()\n",
    "                    final_deviation = data['Deviation_Pct'].iloc[-1] if len(data) > 0 else 0\n",
    "                    has_budget = data['Has_Budget'].iloc[0] if len(data) > 0 else False\n",
    "                    budget_status = \"with budget\" if has_budget else \"no budget\"\n",
    "                    \n",
    "                    print(f\"  ✓ {call_type}: €{total_paid:,.0f} paid vs €{total_forecast:,.0f} forecast ({final_deviation:.1%} deviation) [{budget_status}]\")\n",
    "                else:\n",
    "                    print(f\"  ✓ {call_type}: Generated successfully\")\n",
    "            else:\n",
    "                print(f\"  ✗ {call_type}: {result.get('error', 'Unknown error')}\")\n",
    "\n",
    "# Main execution example\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Payment Charts and Tables Generator\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"This script requires df_paym and df_forecast to be loaded\")\n",
    "    print(\"\\nIMPORTANT: Budget appropriations are only available for:\")\n",
    "    print(\"  H2020: 'all' call types combined\")\n",
    "    print(\"  HEU: 'all' call types combined and 'EXPERTS'\")\n",
    "    print(\"  Individual call types (STG, ADG, COG, POC, SYG) have NO budget data\")\n",
    "    print(\"\\nExample usage:\")\n",
    "    print(\"# Generate all charts (budget applied where available)\")\n",
    "    print(\"results = generate_all_charts(df_paym, df_forecast, AVAILABLE_BUDGET_CONFIG)\")\n",
    "    print(\"display_results_summary(results)\")\n",
    "    print(\"save_charts_to_files(results)\")\n",
    "    print(\"\\nOr generate individual charts:\")\n",
    "    print(\"# Individual call type (no budget elements)\")\n",
    "    print(\"result = generate_payment_chart_and_table(df_paym, df_forecast, 'HEU', 'STG', None)\")\n",
    "    print(\"# Programme total (with budget elements)\")\n",
    "    print(\"result = generate_payment_chart_and_table(df_paym, df_forecast, 'HEU', 'all', 1_532_500_000)\")\n",
    "    print(\"result['chart'].show()  # Display chart\")\n",
    "    print(\"print(result['table'])  # Display table\")\n",
    "    print(\"\\nCheck budget availability:\")\n",
    "    print(\"print(check_budget_availability('HEU', 'STG'))     # False - no budget\")\n",
    "    print(\"print(check_budget_availability('HEU', 'all'))     # True - budget available\")\n",
    "    print(\"print(check_budget_availability('HEU', 'EXPERTS')) # True - budget available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "edea233d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing fixed chart generation...\n",
      "\n",
      "=== Generating chart for HEU - STG ===\n",
      "Cutoff date: 2025-06-04 18:38:12.458901\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5\n",
      "Preparing data for HEU - STG - Cutoff: 2025-06-04 18:38:12.458901\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5 months\n",
      "Filtered by call_type = STG: 417 rows\n",
      "Monthly payments aggregated: 6 months\n",
      "Forecast data columns detected:\n",
      "  Programme: SCRS_FMWK\n",
      "  Call Type: SCRS_CALL_TYPE\n",
      "  Amount: Sum(SCRS_C1_MNT)\n",
      "  Month: Month_Num\n",
      "Filtered forecast by SCRS_FMWK = HEU: 72 rows\n",
      "Filtered forecast by SCRS_CALL_TYPE = STG: 12 rows\n",
      "Forecast monthly data prepared: 12 months, total: 630,836,891\n",
      "✅ SUCCESS! Chart generated successfully\n",
      "Metadata: {'reporting_year': 2025, 'scope_start': Timestamp('2025-01-01 00:00:00'), 'scope_end': Timestamp('2025-06-30 00:00:00'), 'cutoff_month': 5, 'months_in_scope': ['January', 'February', 'March', 'April', 'May']}\n"
     ]
    }
   ],
   "source": [
    "# Test the fixed chart generation\n",
    "print(\"Testing fixed chart generation...\")\n",
    "\n",
    "# Test individual chart\n",
    "result = generate_payment_chart_and_table(df_paym, df_forecast, 'HEU', 'STG')\n",
    "\n",
    "if result['success']:\n",
    "    print(\"✅ SUCCESS! Chart generated successfully\")\n",
    "    print(f\"Metadata: {result['metadata']}\")\n",
    "    \n",
    "    # Display the chart\n",
    "    result['chart']\n",
    "    \n",
    "else:\n",
    "    print(f\"❌ Error: {result['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "23d8c92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing batch generation...\n",
      "No budget appropriations for H2020 COG - skipping budget elements\n",
      "\n",
      "=== Generating chart for H2020 - COG ===\n",
      "Cutoff date: 2025-06-04 18:38:17.812674\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5\n",
      "Preparing data for H2020 - COG - Cutoff: 2025-06-04 18:38:17.812674\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5 months\n",
      "Filtered by call_type = COG: 334 rows\n",
      "Monthly payments aggregated: 6 months\n",
      "Forecast data columns detected:\n",
      "  Programme: SCRS_FMWK\n",
      "  Call Type: SCRS_CALL_TYPE\n",
      "  Amount: Sum(SCRS_C1_MNT)\n",
      "  Month: Month_Num\n",
      "Filtered forecast by SCRS_FMWK = H2020: 51 rows\n",
      "Filtered forecast by SCRS_CALL_TYPE = COG: 12 rows\n",
      "Forecast monthly data prepared: 12 months, total: 142,923,264\n",
      "✓ Generated: H2020 - COG (without budget)\n",
      "No budget appropriations for H2020 STG - skipping budget elements\n",
      "\n",
      "=== Generating chart for H2020 - STG ===\n",
      "Cutoff date: 2025-06-04 18:38:17.869750\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5\n",
      "Preparing data for H2020 - STG - Cutoff: 2025-06-04 18:38:17.869750\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5 months\n",
      "Filtered by call_type = STG: 388 rows\n",
      "Monthly payments aggregated: 5 months\n",
      "Forecast data columns detected:\n",
      "  Programme: SCRS_FMWK\n",
      "  Call Type: SCRS_CALL_TYPE\n",
      "  Amount: Sum(SCRS_C1_MNT)\n",
      "  Month: Month_Num\n",
      "Filtered forecast by SCRS_FMWK = H2020: 51 rows\n",
      "Filtered forecast by SCRS_CALL_TYPE = STG: 12 rows\n",
      "Forecast monthly data prepared: 12 months, total: 92,509,961\n",
      "✓ Generated: H2020 - STG (without budget)\n",
      "No budget appropriations for H2020 ADG - skipping budget elements\n",
      "\n",
      "=== Generating chart for H2020 - ADG ===\n",
      "Cutoff date: 2025-06-04 18:38:17.930253\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5\n",
      "Preparing data for H2020 - ADG - Cutoff: 2025-06-04 18:38:17.930253\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5 months\n",
      "Filtered by call_type = ADG: 309 rows\n",
      "Monthly payments aggregated: 5 months\n",
      "Forecast data columns detected:\n",
      "  Programme: SCRS_FMWK\n",
      "  Call Type: SCRS_CALL_TYPE\n",
      "  Amount: Sum(SCRS_C1_MNT)\n",
      "  Month: Month_Num\n",
      "Filtered forecast by SCRS_FMWK = H2020: 51 rows\n",
      "Filtered forecast by SCRS_CALL_TYPE = ADG: 12 rows\n",
      "Forecast monthly data prepared: 12 months, total: 153,936,633\n",
      "✓ Generated: H2020 - ADG (without budget)\n",
      "No budget appropriations for H2020 SYG - skipping budget elements\n",
      "\n",
      "=== Generating chart for H2020 - SYG ===\n",
      "Cutoff date: 2025-06-04 18:38:17.988654\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5\n",
      "Preparing data for H2020 - SYG - Cutoff: 2025-06-04 18:38:17.988654\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5 months\n",
      "Filtered by call_type = SYG: 26 rows\n",
      "Monthly payments aggregated: 5 months\n",
      "Forecast data columns detected:\n",
      "  Programme: SCRS_FMWK\n",
      "  Call Type: SCRS_CALL_TYPE\n",
      "  Amount: Sum(SCRS_C1_MNT)\n",
      "  Month: Month_Num\n",
      "Filtered forecast by SCRS_FMWK = H2020: 51 rows\n",
      "Filtered forecast by SCRS_CALL_TYPE = SYG: 12 rows\n",
      "Forecast monthly data prepared: 12 months, total: 59,484,653\n",
      "✓ Generated: H2020 - SYG (without budget)\n",
      "Budget available for H2020 all: €435,678,293\n",
      "\n",
      "=== Generating chart for H2020 - all ===\n",
      "Cutoff date: 2025-06-04 18:38:18.048170\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5\n",
      "Preparing data for H2020 - all - Cutoff: 2025-06-04 18:38:18.048170\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5 months\n",
      "Monthly payments aggregated: 6 months\n",
      "Forecast data columns detected:\n",
      "  Programme: SCRS_FMWK\n",
      "  Call Type: SCRS_CALL_TYPE\n",
      "  Amount: Sum(SCRS_C1_MNT)\n",
      "  Month: Month_Num\n",
      "Filtered forecast by SCRS_FMWK = H2020: 51 rows\n",
      "Forecast monthly data prepared: 12 months, total: 448,873,969\n",
      "✓ Generated: H2020 - all (with budget)\n",
      "No budget appropriations for HEU ADG - skipping budget elements\n",
      "\n",
      "=== Generating chart for HEU - ADG ===\n",
      "Cutoff date: 2025-06-04 18:38:18.121153\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5\n",
      "Preparing data for HEU - ADG - Cutoff: 2025-06-04 18:38:18.121153\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5 months\n",
      "Filtered by call_type = ADG: 76 rows\n",
      "Monthly payments aggregated: 6 months\n",
      "Forecast data columns detected:\n",
      "  Programme: SCRS_FMWK\n",
      "  Call Type: SCRS_CALL_TYPE\n",
      "  Amount: Sum(SCRS_C1_MNT)\n",
      "  Month: Month_Num\n",
      "Filtered forecast by SCRS_FMWK = HEU: 72 rows\n",
      "Filtered forecast by SCRS_CALL_TYPE = ADG: 12 rows\n",
      "Forecast monthly data prepared: 12 months, total: 634,363,149\n",
      "✓ Generated: HEU - ADG (without budget)\n",
      "No budget appropriations for HEU POC - skipping budget elements\n",
      "\n",
      "=== Generating chart for HEU - POC ===\n",
      "Cutoff date: 2025-06-04 18:38:18.186291\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5\n",
      "Preparing data for HEU - POC - Cutoff: 2025-06-04 18:38:18.186291\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5 months\n",
      "Filtered by call_type = POC: 223 rows\n",
      "Monthly payments aggregated: 6 months\n",
      "Forecast data columns detected:\n",
      "  Programme: SCRS_FMWK\n",
      "  Call Type: SCRS_CALL_TYPE\n",
      "  Amount: Sum(SCRS_C1_MNT)\n",
      "  Month: Month_Num\n",
      "Filtered forecast by SCRS_FMWK = HEU: 72 rows\n",
      "Filtered forecast by SCRS_CALL_TYPE = POC: 12 rows\n",
      "Forecast monthly data prepared: 12 months, total: 16,023,579\n",
      "✓ Generated: HEU - POC (without budget)\n",
      "No budget appropriations for HEU STG - skipping budget elements\n",
      "\n",
      "=== Generating chart for HEU - STG ===\n",
      "Cutoff date: 2025-06-04 18:38:18.252883\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5\n",
      "Preparing data for HEU - STG - Cutoff: 2025-06-04 18:38:18.252883\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5 months\n",
      "Filtered by call_type = STG: 417 rows\n",
      "Monthly payments aggregated: 6 months\n",
      "Forecast data columns detected:\n",
      "  Programme: SCRS_FMWK\n",
      "  Call Type: SCRS_CALL_TYPE\n",
      "  Amount: Sum(SCRS_C1_MNT)\n",
      "  Month: Month_Num\n",
      "Filtered forecast by SCRS_FMWK = HEU: 72 rows\n",
      "Filtered forecast by SCRS_CALL_TYPE = STG: 12 rows\n",
      "Forecast monthly data prepared: 12 months, total: 630,836,891\n",
      "✓ Generated: HEU - STG (without budget)\n",
      "No budget appropriations for HEU COG - skipping budget elements\n",
      "\n",
      "=== Generating chart for HEU - COG ===\n",
      "Cutoff date: 2025-06-04 18:38:18.315957\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5\n",
      "Preparing data for HEU - COG - Cutoff: 2025-06-04 18:38:18.315957\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5 months\n",
      "Filtered by call_type = COG: 252 rows\n",
      "Monthly payments aggregated: 6 months\n",
      "Forecast data columns detected:\n",
      "  Programme: SCRS_FMWK\n",
      "  Call Type: SCRS_CALL_TYPE\n",
      "  Amount: Sum(SCRS_C1_MNT)\n",
      "  Month: Month_Num\n",
      "Filtered forecast by SCRS_FMWK = HEU: 72 rows\n",
      "Filtered forecast by SCRS_CALL_TYPE = COG: 12 rows\n",
      "Forecast monthly data prepared: 12 months, total: 572,645,097\n",
      "✓ Generated: HEU - COG (without budget)\n",
      "No budget appropriations for HEU SYG - skipping budget elements\n",
      "\n",
      "=== Generating chart for HEU - SYG ===\n",
      "Cutoff date: 2025-06-04 18:38:18.380656\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5\n",
      "Preparing data for HEU - SYG - Cutoff: 2025-06-04 18:38:18.380656\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5 months\n",
      "Filtered by call_type = SYG: 59 rows\n",
      "Monthly payments aggregated: 5 months\n",
      "Forecast data columns detected:\n",
      "  Programme: SCRS_FMWK\n",
      "  Call Type: SCRS_CALL_TYPE\n",
      "  Amount: Sum(SCRS_C1_MNT)\n",
      "  Month: Month_Num\n",
      "Filtered forecast by SCRS_FMWK = HEU: 72 rows\n",
      "Filtered forecast by SCRS_CALL_TYPE = SYG: 12 rows\n",
      "Forecast monthly data prepared: 12 months, total: 284,011,206\n",
      "✓ Generated: HEU - SYG (without budget)\n",
      "Budget available for HEU EXPERTS: €20,000,000\n",
      "\n",
      "=== Generating chart for HEU - EXPERTS ===\n",
      "Cutoff date: 2025-06-04 18:38:18.444698\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5\n",
      "Preparing data for HEU - EXPERTS - Cutoff: 2025-06-04 18:38:18.444698\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5 months\n",
      "Filtered by call_type = EXPERTS: 2806 rows\n",
      "Monthly payments aggregated: 6 months\n",
      "Forecast data columns detected:\n",
      "  Programme: SCRS_FMWK\n",
      "  Call Type: SCRS_CALL_TYPE\n",
      "  Amount: Sum(SCRS_C1_MNT)\n",
      "  Month: Month_Num\n",
      "Filtered forecast by SCRS_FMWK = HEU: 72 rows\n",
      "Filtered forecast by SCRS_CALL_TYPE = EXPERTS: 12 rows\n",
      "Forecast monthly data prepared: 12 months, total: 20,000,000\n",
      "✓ Generated: HEU - EXPERTS (with budget)\n",
      "Budget available for HEU all: €2,066,470,779\n",
      "\n",
      "=== Generating chart for HEU - all ===\n",
      "Cutoff date: 2025-06-04 18:38:18.529192\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5\n",
      "Preparing data for HEU - all - Cutoff: 2025-06-04 18:38:18.529192\n",
      "Reporting year: 2025\n",
      "Scope: 2025-01-01 00:00:00 to 2025-06-30 00:00:00\n",
      "Months in scope: 5 months\n",
      "Monthly payments aggregated: 6 months\n",
      "Forecast data columns detected:\n",
      "  Programme: SCRS_FMWK\n",
      "  Call Type: SCRS_CALL_TYPE\n",
      "  Amount: Sum(SCRS_C1_MNT)\n",
      "  Month: Month_Num\n",
      "Filtered forecast by SCRS_FMWK = HEU: 72 rows\n",
      "Forecast monthly data prepared: 12 months, total: 2,157,879,922\n",
      "✓ Generated: HEU - all (with budget)\n",
      "✅ Batch generation successful!\n",
      "\n",
      "============================================================\n",
      "CHART GENERATION SUMMARY\n",
      "============================================================\n",
      "\n",
      "H2020 Programme:\n",
      "  ✓ COG: €76,825,462 paid vs €142,923,264 forecast (-46.2% deviation) [no budget]\n",
      "  ✓ STG: €45,283,279 paid vs €92,509,961 forecast (-51.1% deviation) [no budget]\n",
      "  ✓ ADG: €101,721,891 paid vs €153,936,633 forecast (-33.9% deviation) [no budget]\n",
      "  ✓ SYG: €43,209,606 paid vs €59,484,653 forecast (-27.4% deviation) [no budget]\n",
      "  ✓ all: €267,040,237 paid vs €448,873,969 forecast (-40.5% deviation) [with budget]\n",
      "\n",
      "HEU Programme:\n",
      "  ✓ ADG: €86,629,523 paid vs €634,363,149 forecast (-86.3% deviation) [no budget]\n",
      "  ✓ POC: €13,797,000 paid vs €16,023,579 forecast (-13.9% deviation) [no budget]\n",
      "  ✓ STG: €217,918,558 paid vs €630,836,891 forecast (-65.5% deviation) [no budget]\n",
      "  ✓ COG: €255,424,085 paid vs €572,645,097 forecast (-55.4% deviation) [no budget]\n",
      "  ✓ SYG: €156,347,972 paid vs €284,011,206 forecast (-45.0% deviation) [no budget]\n",
      "  ✓ EXPERTS: €7,960,314 paid vs €20,000,000 forecast (-60.2% deviation) [with budget]\n",
      "  ✓ all: €738,077,452 paid vs €2,157,879,922 forecast (-65.8% deviation) [with budget]\n"
     ]
    }
   ],
   "source": [
    "# Test batch generation if individual tests work\n",
    "if result['success']:\n",
    "    print(\"\\n\" + \"=\"*50)  \n",
    "    print(\"Testing batch generation...\")\n",
    "    \n",
    "    try:\n",
    "        results = generate_all_charts(df_paym, df_forecast)\n",
    "        print(\"✅ Batch generation successful!\")\n",
    "        display_results_summary(results)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Batch generation failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "25a5bb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DISPLAYING CHARTS ===\n",
      "HEU STG Chart:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-5c84204b0cf94938b972e1eb291cc7d1\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-5c84204b0cf94938b972e1eb291cc7d1\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-5c84204b0cf94938b972e1eb291cc7d1\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousHeight\": 350, \"continuousWidth\": 550}, \"range\": {\"category\": {\"scheme\": [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\"]}}, \"title\": {\"fontSize\": 18, \"font\": \"Lato\", \"anchor\": \"center\", \"color\": \"#333333\", \"fontWeight\": \"bold\"}}, \"layer\": [{\"data\": {\"name\": \"data-90360e1d7c467335b51539de045be71b\"}, \"mark\": {\"type\": \"bar\", \"color\": \"#1f77b4\", \"opacity\": 0.7, \"size\": 45}, \"encoding\": {\"x\": {\"field\": \"Month\", \"title\": \"Month\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Paid_Cumulative\", \"scale\": {\"zero\": true}, \"title\": \"Amount (\\u20ac)\", \"type\": \"quantitative\"}}, \"height\": 350, \"title\": \"HEU - Consumption STG 2025\", \"width\": 550}, {\"data\": {\"name\": \"data-090fb7baf515194ff801c1a4c604ff79\"}, \"mark\": {\"type\": \"line\", \"color\": \"#ff7f0e\", \"opacity\": 0.8, \"strokeWidth\": 3}, \"encoding\": {\"x\": {\"field\": \"Month\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Forecast_Cumulative\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-90360e1d7c467335b51539de045be71b\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"color\": \"#8a2003\", \"dx\": 0, \"dy\": -5, \"fontSize\": 12, \"fontWeight\": \"bold\"}, \"encoding\": {\"text\": {\"field\": \"Consumption_Pct\", \"format\": \".1%\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"Month\", \"title\": \"Month\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Paid_Cumulative\", \"scale\": {\"zero\": true}, \"title\": \"Amount (\\u20ac)\", \"type\": \"quantitative\"}}, \"height\": 350, \"title\": \"HEU - Consumption STG 2025\", \"width\": 550}, {\"data\": {\"name\": \"data-0ffcd99352e8a493044715b20e53ee77\"}, \"mark\": {\"type\": \"text\", \"align\": \"left\", \"color\": \"red\", \"dx\": 50, \"dy\": -80, \"fontSize\": 14, \"fontWeight\": \"bold\"}, \"encoding\": {\"text\": {\"field\": \"Deviation_Pct\", \"format\": \".1%\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"Month\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Paid_Cumulative\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-0ffcd99352e8a493044715b20e53ee77\"}, \"mark\": {\"type\": \"text\", \"align\": \"left\", \"color\": \"red\", \"dx\": 50, \"dy\": -60, \"fontSize\": 11, \"fontWeight\": \"bold\"}, \"encoding\": {\"text\": {\"field\": \"Comment\", \"type\": \"nominal\"}, \"x\": {\"field\": \"Month\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Paid_Cumulative\", \"type\": \"quantitative\"}}}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-90360e1d7c467335b51539de045be71b\": [{\"Month\": 1, \"Paid\": 40625060.89, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 56526267.13, \"Paid_Cumulative\": 40625060.89, \"Forecast_Cumulative\": 56526267.13, \"Has_Budget\": false, \"Appropriations\": null, \"Consumption_Pct\": 0.06439867651583531, \"Forecast_Pct\": 0.08960520210441374, \"Deviation_Pct\": -0.02520652558857843, \"Deviation_Amount\": -15901206.240000002, \"Deviation_vs_Budget_Pct\": null}, {\"Month\": 2, \"Paid\": 60665549.910000004, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 54167227.27999999, \"Paid_Cumulative\": 101290610.80000001, \"Forecast_Cumulative\": 110693494.41, \"Has_Budget\": false, \"Appropriations\": null, \"Consumption_Pct\": 0.16056545236111214, \"Forecast_Pct\": 0.17547086411067317, \"Deviation_Pct\": -0.014905411749561032, \"Deviation_Amount\": -9402883.609999985, \"Deviation_vs_Budget_Pct\": null}, {\"Month\": 3, \"Paid\": 54106720.88, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 84287244.95999996, \"Paid_Cumulative\": 155397331.68, \"Forecast_Cumulative\": 194980739.36999995, \"Has_Budget\": false, \"Appropriations\": null, \"Consumption_Pct\": 0.24633519987529762, \"Forecast_Pct\": 0.30908265209758357, \"Deviation_Pct\": -0.06274745222228595, \"Deviation_Amount\": -39583407.68999994, \"Deviation_vs_Budget_Pct\": null}, {\"Month\": 4, \"Paid\": 24397353.47, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 27764468.22999999, \"Paid_Cumulative\": 179794685.15, \"Forecast_Cumulative\": 222745207.59999993, \"Has_Budget\": false, \"Appropriations\": null, \"Consumption_Pct\": 0.2850097824983545, \"Forecast_Pct\": 0.35309477094755376, \"Deviation_Pct\": -0.06808498844919925, \"Deviation_Amount\": -42950522.44999993, \"Deviation_vs_Budget_Pct\": null}, {\"Month\": 5, \"Paid\": 36458079.35, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 43490360.11000001, \"Paid_Cumulative\": 216252764.5, \"Forecast_Cumulative\": 266235567.70999995, \"Has_Budget\": false, \"Appropriations\": null, \"Consumption_Pct\": 0.34280297731488796, \"Forecast_Pct\": 0.4220355077962827, \"Deviation_Pct\": -0.07923253048139473, \"Deviation_Amount\": -49982803.20999995, \"Deviation_vs_Budget_Pct\": null}], \"data-090fb7baf515194ff801c1a4c604ff79\": [{\"Month\": 1, \"Paid\": 40625060.89, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 56526267.13, \"Paid_Cumulative\": 40625060.89, \"Forecast_Cumulative\": 56526267.13, \"Has_Budget\": false, \"Appropriations\": null, \"Consumption_Pct\": 0.06439867651583531, \"Forecast_Pct\": 0.08960520210441374, \"Deviation_Pct\": -0.02520652558857843, \"Deviation_Amount\": -15901206.240000002, \"Deviation_vs_Budget_Pct\": null}, {\"Month\": 2, \"Paid\": 60665549.910000004, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 54167227.27999999, \"Paid_Cumulative\": 101290610.80000001, \"Forecast_Cumulative\": 110693494.41, \"Has_Budget\": false, \"Appropriations\": null, \"Consumption_Pct\": 0.16056545236111214, \"Forecast_Pct\": 0.17547086411067317, \"Deviation_Pct\": -0.014905411749561032, \"Deviation_Amount\": -9402883.609999985, \"Deviation_vs_Budget_Pct\": null}, {\"Month\": 3, \"Paid\": 54106720.88, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 84287244.95999996, \"Paid_Cumulative\": 155397331.68, \"Forecast_Cumulative\": 194980739.36999995, \"Has_Budget\": false, \"Appropriations\": null, \"Consumption_Pct\": 0.24633519987529762, \"Forecast_Pct\": 0.30908265209758357, \"Deviation_Pct\": -0.06274745222228595, \"Deviation_Amount\": -39583407.68999994, \"Deviation_vs_Budget_Pct\": null}, {\"Month\": 4, \"Paid\": 24397353.47, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 27764468.22999999, \"Paid_Cumulative\": 179794685.15, \"Forecast_Cumulative\": 222745207.59999993, \"Has_Budget\": false, \"Appropriations\": null, \"Consumption_Pct\": 0.2850097824983545, \"Forecast_Pct\": 0.35309477094755376, \"Deviation_Pct\": -0.06808498844919925, \"Deviation_Amount\": -42950522.44999993, \"Deviation_vs_Budget_Pct\": null}, {\"Month\": 5, \"Paid\": 36458079.35, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 43490360.11000001, \"Paid_Cumulative\": 216252764.5, \"Forecast_Cumulative\": 266235567.70999995, \"Has_Budget\": false, \"Appropriations\": null, \"Consumption_Pct\": 0.34280297731488796, \"Forecast_Pct\": 0.4220355077962827, \"Deviation_Pct\": -0.07923253048139473, \"Deviation_Amount\": -49982803.20999995, \"Deviation_vs_Budget_Pct\": null}, {\"Month\": 6, \"Paid\": 1665793.5, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 37429691.09000003, \"Paid_Cumulative\": 217918558.0, \"Forecast_Cumulative\": 303665258.79999995, \"Has_Budget\": false, \"Appropriations\": null, \"Consumption_Pct\": 0.34544358620010657, \"Forecast_Pct\": 0.48136889747708156, \"Deviation_Pct\": -0.135925311276975, \"Deviation_Amount\": -85746700.79999995, \"Deviation_vs_Budget_Pct\": null}, {\"Month\": 7, \"Paid\": 0.0, \"v_1_Program\": \"HEU\", \"Year\": 0.0, \"Forecast\": 31468377.73000001, \"Paid_Cumulative\": 217918558.0, \"Forecast_Cumulative\": 335133636.53, \"Has_Budget\": false, \"Appropriations\": null, \"Consumption_Pct\": 0.34544358620010657, \"Forecast_Pct\": 0.5312524381664009, \"Deviation_Pct\": -0.18580885196629432, \"Deviation_Amount\": -117215078.52999997, \"Deviation_vs_Budget_Pct\": null}, {\"Month\": 8, \"Paid\": 0.0, \"v_1_Program\": \"HEU\", \"Year\": 0.0, \"Forecast\": 34749051.24999999, \"Paid_Cumulative\": 217918558.0, \"Forecast_Cumulative\": 369882687.78, \"Has_Budget\": false, \"Appropriations\": null, \"Consumption_Pct\": 0.34544358620010657, \"Forecast_Pct\": 0.5863364887907231, \"Deviation_Pct\": -0.24089290259061652, \"Deviation_Amount\": -151964129.77999997, \"Deviation_vs_Budget_Pct\": null}, {\"Month\": 9, \"Paid\": 0.0, \"v_1_Program\": \"HEU\", \"Year\": 0.0, \"Forecast\": 46418244.26999999, \"Paid_Cumulative\": 217918558.0, \"Forecast_Cumulative\": 416300932.04999995, \"Has_Budget\": false, \"Appropriations\": null, \"Consumption_Pct\": 0.34544358620010657, \"Forecast_Pct\": 0.6599184953573292, \"Deviation_Pct\": -0.3144749091572226, \"Deviation_Amount\": -198382374.04999995, \"Deviation_vs_Budget_Pct\": null}, {\"Month\": 10, \"Paid\": 0.0, \"v_1_Program\": \"HEU\", \"Year\": 0.0, \"Forecast\": 50044546.00000004, \"Paid_Cumulative\": 217918558.0, \"Forecast_Cumulative\": 466345478.05, \"Has_Budget\": false, \"Appropriations\": null, \"Consumption_Pct\": 0.34544358620010657, \"Forecast_Pct\": 0.739248900251052, \"Deviation_Pct\": -0.3938053140509455, \"Deviation_Amount\": -248426920.05, \"Deviation_vs_Budget_Pct\": null}, {\"Month\": 11, \"Paid\": 0.0, \"v_1_Program\": \"HEU\", \"Year\": 0.0, \"Forecast\": 23719949.33999999, \"Paid_Cumulative\": 217918558.0, \"Forecast_Cumulative\": 490065427.39, \"Has_Budget\": false, \"Appropriations\": null, \"Consumption_Pct\": 0.34544358620010657, \"Forecast_Pct\": 0.776849664682021, \"Deviation_Pct\": -0.4314060784819144, \"Deviation_Amount\": -272146869.39, \"Deviation_vs_Budget_Pct\": null}, {\"Month\": 12, \"Paid\": 0.0, \"v_1_Program\": \"HEU\", \"Year\": 0.0, \"Forecast\": 140771463.7999999, \"Paid_Cumulative\": 217918558.0, \"Forecast_Cumulative\": 630836891.1899998, \"Has_Budget\": false, \"Appropriations\": null, \"Consumption_Pct\": 0.34544358620010657, \"Forecast_Pct\": 0.9999999999999998, \"Deviation_Pct\": -0.6545564137998932, \"Deviation_Amount\": -412918333.1899998, \"Deviation_vs_Budget_Pct\": null}], \"data-0ffcd99352e8a493044715b20e53ee77\": [{\"Month\": 5, \"Paid_Cumulative\": 216252764.5, \"Deviation_Pct\": -0.07923253048139473, \"Comment\": \"Underconsumption\", \"Arrow\": \"\\u2193\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. DISPLAY INDIVIDUAL CHARTS\n",
    "print(\"=== DISPLAYING CHARTS ===\")\n",
    "\n",
    "# HEU STG Chart (no budget)\n",
    "print(\"HEU STG Chart:\")\n",
    "results['HEU']['STG']['chart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e5b60060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>JAN</th>\n",
       "      <th>FEB</th>\n",
       "      <th>MAR</th>\n",
       "      <th>APR</th>\n",
       "      <th>MAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cumulative Consumption (€ million)</td>\n",
       "      <td>40.625</td>\n",
       "      <td>101.291</td>\n",
       "      <td>155.397</td>\n",
       "      <td>179.795</td>\n",
       "      <td>216.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cumulative Forecast (€ million)</td>\n",
       "      <td>56.526</td>\n",
       "      <td>110.693</td>\n",
       "      <td>194.981</td>\n",
       "      <td>222.745</td>\n",
       "      <td>266.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deviation vs. Cumulative Forecast (€ million)</td>\n",
       "      <td>-15.9</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>-39.6</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deviation vs. Cumulative Forecast (%)</td>\n",
       "      <td>-2.5%</td>\n",
       "      <td>-1.5%</td>\n",
       "      <td>-6.3%</td>\n",
       "      <td>-6.8%</td>\n",
       "      <td>-7.9%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Metric     JAN      FEB      MAR  \\\n",
       "0             Cumulative Consumption (€ million)  40.625  101.291  155.397   \n",
       "1                Cumulative Forecast (€ million)  56.526  110.693  194.981   \n",
       "2  Deviation vs. Cumulative Forecast (€ million)   -15.9     -9.4    -39.6   \n",
       "3          Deviation vs. Cumulative Forecast (%)   -2.5%    -1.5%    -6.3%   \n",
       "\n",
       "       APR      MAY  \n",
       "0  179.795  216.253  \n",
       "1  222.745  266.236  \n",
       "2    -43.0    -50.0  \n",
       "3    -6.8%    -7.9%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Show its table  \n",
    "display(results['HEU']['STG']['table'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "02c1e570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-45a57d327c2b433ab33423a76e527d95\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-45a57d327c2b433ab33423a76e527d95\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-45a57d327c2b433ab33423a76e527d95\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousHeight\": 350, \"continuousWidth\": 550}, \"range\": {\"category\": {\"scheme\": [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\"]}}, \"title\": {\"fontSize\": 18, \"font\": \"Lato\", \"anchor\": \"center\", \"color\": \"#333333\", \"fontWeight\": \"bold\"}}, \"layer\": [{\"data\": {\"name\": \"data-83fa7205798faa1a6be06eda69f06f69\"}, \"mark\": {\"type\": \"bar\", \"color\": \"#1f77b4\", \"opacity\": 0.7, \"size\": 45}, \"encoding\": {\"x\": {\"field\": \"Month\", \"title\": \"Month\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Paid_Cumulative\", \"scale\": {\"zero\": true}, \"title\": \"Amount (\\u20ac)\", \"type\": \"quantitative\"}}, \"height\": 350, \"title\": \"HEU - Consumption All Calls 2025\", \"width\": 550}, {\"data\": {\"name\": \"data-a16d10d9a1de9008d420ac9f7b865b75\"}, \"mark\": {\"type\": \"line\", \"color\": \"#ff7f0e\", \"opacity\": 0.8, \"strokeWidth\": 3}, \"encoding\": {\"x\": {\"field\": \"Month\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Forecast_Cumulative\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-a16d10d9a1de9008d420ac9f7b865b75\"}, \"mark\": {\"type\": \"line\", \"color\": \"#2ca02c\", \"opacity\": 0.8, \"strokeWidth\": 3}, \"encoding\": {\"x\": {\"field\": \"Month\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Appropriations\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-83fa7205798faa1a6be06eda69f06f69\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"color\": \"#8a2003\", \"dx\": 0, \"dy\": -5, \"fontSize\": 12, \"fontWeight\": \"bold\"}, \"encoding\": {\"text\": {\"field\": \"Consumption_Pct\", \"format\": \".1%\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"Month\", \"title\": \"Month\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Paid_Cumulative\", \"scale\": {\"zero\": true}, \"title\": \"Amount (\\u20ac)\", \"type\": \"quantitative\"}}, \"height\": 350, \"title\": \"HEU - Consumption All Calls 2025\", \"width\": 550}, {\"data\": {\"name\": \"data-6ce3722d3ff0c29017ba176907f93958\"}, \"mark\": {\"type\": \"text\", \"align\": \"left\", \"color\": \"green\", \"dx\": 50, \"dy\": -80, \"fontSize\": 14, \"fontWeight\": \"bold\"}, \"encoding\": {\"text\": {\"field\": \"Deviation_Pct\", \"format\": \".1%\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"Month\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Paid_Cumulative\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-6ce3722d3ff0c29017ba176907f93958\"}, \"mark\": {\"type\": \"text\", \"align\": \"left\", \"color\": \"green\", \"dx\": 50, \"dy\": -60, \"fontSize\": 11, \"fontWeight\": \"bold\"}, \"encoding\": {\"text\": {\"field\": \"Comment\", \"type\": \"nominal\"}, \"x\": {\"field\": \"Month\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Paid_Cumulative\", \"type\": \"quantitative\"}}}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-83fa7205798faa1a6be06eda69f06f69\": [{\"Month\": 1, \"Paid\": 102517999.29, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 109950361.97, \"Paid_Cumulative\": 102517999.29, \"Forecast_Cumulative\": 109950361.97, \"Has_Budget\": true, \"Appropriations\": 2066470779.0, \"Consumption_Pct\": 0.047508667301310155, \"Forecast_Pct\": 0.050952956579995254, \"Deviation_Pct\": -0.003444289278685099, \"Deviation_Amount\": -7432362.679999992, \"Deviation_vs_Budget_Pct\": -0.0035966454282971463}, {\"Month\": 2, \"Paid\": 142571706.85, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 125560325.85, \"Paid_Cumulative\": 245089706.14, \"Forecast_Cumulative\": 235510687.82, \"Has_Budget\": true, \"Appropriations\": 2066470779.0, \"Consumption_Pct\": 0.11357893627091999, \"Forecast_Pct\": 0.10913984852447754, \"Deviation_Pct\": 0.004439087746442444, \"Deviation_Amount\": 9579018.319999993, \"Deviation_vs_Budget_Pct\": 0.00463544823248623}, {\"Month\": 3, \"Paid\": 182053342.56, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 188352007.24999997, \"Paid_Cumulative\": 427143048.7, \"Forecast_Cumulative\": 423862695.06999993, \"Has_Budget\": true, \"Appropriations\": 2066470779.0, \"Consumption_Pct\": 0.19794569862167682, \"Forecast_Pct\": 0.1964255243077257, \"Deviation_Pct\": 0.0015201743139511281, \"Deviation_Amount\": 3280353.630000055, \"Deviation_vs_Budget_Pct\": 0.001587418347907863}, {\"Month\": 4, \"Paid\": 141107612.32, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 137580768.76999998, \"Paid_Cumulative\": 568250661.02, \"Forecast_Cumulative\": 561443463.8399999, \"Has_Budget\": true, \"Appropriations\": 2066470779.0, \"Consumption_Pct\": 0.26333748010221, \"Forecast_Pct\": 0.26018290365398833, \"Deviation_Pct\": 0.0031545764482216465, \"Deviation_Amount\": 6807197.180000067, \"Deviation_vs_Budget_Pct\": 0.003294117317881545}, {\"Month\": 5, \"Paid\": 165441445.18, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 144464551.93, \"Paid_Cumulative\": 733692106.2, \"Forecast_Cumulative\": 705908015.77, \"Has_Budget\": true, \"Appropriations\": 2066470779.0, \"Consumption_Pct\": 0.3400059932544292, \"Forecast_Pct\": 0.32713035075603775, \"Deviation_Pct\": 0.01287564249839146, \"Deviation_Amount\": 27784090.430000067, \"Deviation_vs_Budget_Pct\": 0.013445189117769794}], \"data-a16d10d9a1de9008d420ac9f7b865b75\": [{\"Month\": 1, \"Paid\": 102517999.29, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 109950361.97, \"Paid_Cumulative\": 102517999.29, \"Forecast_Cumulative\": 109950361.97, \"Has_Budget\": true, \"Appropriations\": 2066470779.0, \"Consumption_Pct\": 0.047508667301310155, \"Forecast_Pct\": 0.050952956579995254, \"Deviation_Pct\": -0.003444289278685099, \"Deviation_Amount\": -7432362.679999992, \"Deviation_vs_Budget_Pct\": -0.0035966454282971463}, {\"Month\": 2, \"Paid\": 142571706.85, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 125560325.85, \"Paid_Cumulative\": 245089706.14, \"Forecast_Cumulative\": 235510687.82, \"Has_Budget\": true, \"Appropriations\": 2066470779.0, \"Consumption_Pct\": 0.11357893627091999, \"Forecast_Pct\": 0.10913984852447754, \"Deviation_Pct\": 0.004439087746442444, \"Deviation_Amount\": 9579018.319999993, \"Deviation_vs_Budget_Pct\": 0.00463544823248623}, {\"Month\": 3, \"Paid\": 182053342.56, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 188352007.24999997, \"Paid_Cumulative\": 427143048.7, \"Forecast_Cumulative\": 423862695.06999993, \"Has_Budget\": true, \"Appropriations\": 2066470779.0, \"Consumption_Pct\": 0.19794569862167682, \"Forecast_Pct\": 0.1964255243077257, \"Deviation_Pct\": 0.0015201743139511281, \"Deviation_Amount\": 3280353.630000055, \"Deviation_vs_Budget_Pct\": 0.001587418347907863}, {\"Month\": 4, \"Paid\": 141107612.32, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 137580768.76999998, \"Paid_Cumulative\": 568250661.02, \"Forecast_Cumulative\": 561443463.8399999, \"Has_Budget\": true, \"Appropriations\": 2066470779.0, \"Consumption_Pct\": 0.26333748010221, \"Forecast_Pct\": 0.26018290365398833, \"Deviation_Pct\": 0.0031545764482216465, \"Deviation_Amount\": 6807197.180000067, \"Deviation_vs_Budget_Pct\": 0.003294117317881545}, {\"Month\": 5, \"Paid\": 165441445.18, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 144464551.93, \"Paid_Cumulative\": 733692106.2, \"Forecast_Cumulative\": 705908015.77, \"Has_Budget\": true, \"Appropriations\": 2066470779.0, \"Consumption_Pct\": 0.3400059932544292, \"Forecast_Pct\": 0.32713035075603775, \"Deviation_Pct\": 0.01287564249839146, \"Deviation_Amount\": 27784090.430000067, \"Deviation_vs_Budget_Pct\": 0.013445189117769794}, {\"Month\": 6, \"Paid\": 4385346.12, \"v_1_Program\": \"HEU\", \"Year\": 2025.0, \"Forecast\": 165322427.8185715, \"Paid_Cumulative\": 738077452.32, \"Forecast_Cumulative\": 871230443.5885715, \"Has_Budget\": true, \"Appropriations\": 2066470779.0, \"Consumption_Pct\": 0.3420382407744654, \"Forecast_Pct\": 0.4037437091425929, \"Deviation_Pct\": -0.061705468368127514, \"Deviation_Amount\": -133152991.2685715, \"Deviation_vs_Budget_Pct\": -0.06443497417031296}, {\"Month\": 7, \"Paid\": 0.0, \"v_1_Program\": \"HEU\", \"Year\": 0.0, \"Forecast\": 121624173.16857143, \"Paid_Cumulative\": 738077452.32, \"Forecast_Cumulative\": 992854616.757143, \"Has_Budget\": true, \"Appropriations\": 2066470779.0, \"Consumption_Pct\": 0.3420382407744654, \"Forecast_Pct\": 0.4601065178091704, \"Deviation_Pct\": -0.11806827703470502, \"Deviation_Amount\": -254777164.43714297, \"Deviation_vs_Budget_Pct\": -0.12329095916876885}, {\"Month\": 8, \"Paid\": 0.0, \"v_1_Program\": \"HEU\", \"Year\": 0.0, \"Forecast\": 325676147.89857125, \"Paid_Cumulative\": 738077452.32, \"Forecast_Cumulative\": 1318530764.6557143, \"Has_Budget\": true, \"Appropriations\": 2066470779.0, \"Consumption_Pct\": 0.3420382407744654, \"Forecast_Pct\": 0.6110306468952005, \"Deviation_Pct\": -0.2689924061207351, \"Deviation_Amount\": -580453312.3357142, \"Deviation_vs_Budget_Pct\": -0.280891130053436}, {\"Month\": 9, \"Paid\": 0.0, \"v_1_Program\": \"HEU\", \"Year\": 0.0, \"Forecast\": 192106381.79857144, \"Paid_Cumulative\": 738077452.32, \"Forecast_Cumulative\": 1510637146.4542856, \"Has_Budget\": true, \"Appropriations\": 2066470779.0, \"Consumption_Pct\": 0.3420382407744654, \"Forecast_Pct\": 0.7000561667310821, \"Deviation_Pct\": -0.3580179259566167, \"Deviation_Amount\": -772559694.1342856, \"Deviation_vs_Budget_Pct\": -0.37385464241025473}, {\"Month\": 10, \"Paid\": 0.0, \"v_1_Program\": \"HEU\", \"Year\": 0.0, \"Forecast\": 179321499.3485715, \"Paid_Cumulative\": 738077452.32, \"Forecast_Cumulative\": 1689958645.8028572, \"Has_Budget\": true, \"Appropriations\": 2066470779.0, \"Consumption_Pct\": 0.3420382407744654, \"Forecast_Pct\": 0.783156944267953, \"Deviation_Pct\": -0.44111870349348764, \"Deviation_Amount\": -951881193.4828571, \"Deviation_vs_Budget_Pct\": -0.4606313349097965}, {\"Month\": 11, \"Paid\": 0.0, \"v_1_Program\": \"HEU\", \"Year\": 0.0, \"Forecast\": 134744516.4085714, \"Paid_Cumulative\": 738077452.32, \"Forecast_Cumulative\": 1824703162.2114286, \"Has_Budget\": true, \"Appropriations\": 2066470779.0, \"Consumption_Pct\": 0.3420382407744654, \"Forecast_Pct\": 0.8455999537400973, \"Deviation_Pct\": -0.503561712965632, \"Deviation_Amount\": -1086625709.8914285, \"Deviation_vs_Budget_Pct\": -0.5258364748894562}, {\"Month\": 12, \"Paid\": 0.0, \"v_1_Program\": \"HEU\", \"Year\": 0.0, \"Forecast\": 333176759.77857125, \"Paid_Cumulative\": 738077452.32, \"Forecast_Cumulative\": 2157879921.99, \"Has_Budget\": true, \"Appropriations\": 2066470779.0, \"Consumption_Pct\": 0.3420382407744654, \"Forecast_Pct\": 1.0, \"Deviation_Pct\": -0.6579617592255347, \"Deviation_Amount\": -1419802469.6699996, \"Deviation_vs_Budget_Pct\": -0.687066318139309}], \"data-6ce3722d3ff0c29017ba176907f93958\": [{\"Month\": 5, \"Paid_Cumulative\": 733692106.2, \"Deviation_Pct\": 0.01287564249839146, \"Comment\": \"Overconsumption\", \"Arrow\": \"\\u2191\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Show HEU All chart (with budget line)\n",
    "results['HEU']['all']['chart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1460fbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>JAN</th>\n",
       "      <th>FEB</th>\n",
       "      <th>MAR</th>\n",
       "      <th>APR</th>\n",
       "      <th>MAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Current Inscribed Budget</td>\n",
       "      <td>2,066.5</td>\n",
       "      <td>2,066.5</td>\n",
       "      <td>2,066.5</td>\n",
       "      <td>2,066.5</td>\n",
       "      <td>2,066.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cumulative Consumption (€ million)</td>\n",
       "      <td>102.518</td>\n",
       "      <td>245.090</td>\n",
       "      <td>427.143</td>\n",
       "      <td>568.251</td>\n",
       "      <td>733.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cumulative Forecast (€ million)</td>\n",
       "      <td>109.950</td>\n",
       "      <td>235.511</td>\n",
       "      <td>423.863</td>\n",
       "      <td>561.443</td>\n",
       "      <td>705.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deviation vs. Cumulative Forecast (€ million)</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>9.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>27.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deviation vs. Cumulative Forecast (%)</td>\n",
       "      <td>-0.3%</td>\n",
       "      <td>0.4%</td>\n",
       "      <td>0.2%</td>\n",
       "      <td>0.3%</td>\n",
       "      <td>1.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deviation vs. Budget (%)</td>\n",
       "      <td>-0.4%</td>\n",
       "      <td>0.5%</td>\n",
       "      <td>0.2%</td>\n",
       "      <td>0.3%</td>\n",
       "      <td>1.3%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Metric      JAN      FEB      MAR  \\\n",
       "0                       Current Inscribed Budget  2,066.5  2,066.5  2,066.5   \n",
       "1             Cumulative Consumption (€ million)  102.518  245.090  427.143   \n",
       "2                Cumulative Forecast (€ million)  109.950  235.511  423.863   \n",
       "3  Deviation vs. Cumulative Forecast (€ million)     -7.4      9.6      3.3   \n",
       "4          Deviation vs. Cumulative Forecast (%)    -0.3%     0.4%     0.2%   \n",
       "5                       Deviation vs. Budget (%)    -0.4%     0.5%     0.2%   \n",
       "\n",
       "       APR      MAY  \n",
       "0  2,066.5  2,066.5  \n",
       "1  568.251  733.692  \n",
       "2  561.443  705.908  \n",
       "3      6.8     27.8  \n",
       "4     0.3%     1.3%  \n",
       "5     0.3%     1.3%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 4. Show HEU All table (with budget rows)\n",
    "display(results['HEU']['all']['table'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
